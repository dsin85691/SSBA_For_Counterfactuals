{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=4, n_informative=4, n_redundant=0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp \n",
    "\n",
    "class LogisticRegressionGPU:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + cp.exp(-z))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.weights = cp.zeros(n_features)\n",
    "        self.bias = cp.float64(0)\n",
    "        \n",
    "        # Gradient descent\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Forward pass\n",
    "            linear_model = cp.dot(X, self.weights) + self.bias\n",
    "            y_predicted = self.sigmoid(linear_model)\n",
    "            \n",
    "            # Compute gradients\n",
    "            dw = (1 / n_samples) * cp.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / n_samples) * cp.sum(y_predicted - y)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "    \n",
    "    def predict(self, X):\n",
    "        linear_model = cp.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.sigmoid(linear_model)\n",
    "        return cp.where(y_predicted >= 0.5, 1, 0)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        linear_model = cp.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.sigmoid(linear_model)\n",
    "        y_predicted = cp.column_stack((y_predicted, 1-y_predicted))\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Costs with GPU \n",
    "\n",
    "GPU: $\\textbf{Nvidia Geforce RTX 4070}$\n",
    "\n",
    "- 25 Resolution (R = 25) \n",
    "-  13+ minute runtime\n",
    "\n",
    "- 20 Resolution (R = 20) \n",
    "- 3 minutes 5 seconds runtime\n",
    "\n",
    "- 18 Resolution (R = 18) \n",
    "- 54 second runtime\n",
    "\n",
    "- 15 Resolution (R = 15) \n",
    "- 18.4 second runtime \n",
    "\n",
    "- 10 Resolution (R = 10) \n",
    "- 1 second runtime \n",
    "\n",
    "Runtime: O($R^f$) in the worst case. Broadcasting will be $O(1)$ operation due to parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50625, 4)\n",
      "Decision Boundary Points (All Features):\n",
      "[[-0.58048122 -0.32611143 -0.31108194  0.26922399]\n",
      " [-0.58037814 -0.32600951 -0.31097154  0.26933998]\n",
      " [-0.58027506 -0.32590759 -0.31086114  0.26945598]\n",
      " ...\n",
      " [-0.53327077 -0.27943078 -0.26051991  0.32234895]\n",
      " [-0.53316769 -0.27932886 -0.26040951  0.32246494]\n",
      " [-0.53306461 -0.27922694 -0.26029911  0.32258093]]\n",
      "(53592, 4)\n"
     ]
    }
   ],
   "source": [
    "model2 = LogisticRegressionGPU(learning_rate=0.01, n_iterations=3000)\n",
    "model2.fit(cp.array(X), cp.array(y))\n",
    "\n",
    "\n",
    "def compute_decision_boundary_points_gpu(model, X, resolution=100, epsilon=0.01):\n",
    "    n_features = X.shape[1]\n",
    "    boundary_points = cp.zeros((1,n_features))\n",
    "    \n",
    "    grid = cp.zeros((resolution ** n_features, n_features))\n",
    "    for i, feature in enumerate(range(n_features)):\n",
    "        cp_array = cp.linspace(X[:, feature].min() - 1, X[:, feature].max() + 1, resolution ** (n_features)).reshape(-1)\n",
    "        grid[:, i] = cp_array\n",
    "\n",
    "    print(grid.shape)\n",
    "    Z = cp.asarray(model.predict(grid))\n",
    "\n",
    "    for i in range(len(grid) - 1):\n",
    "        # Compute broadcasted points (difference between grid[i,:] and all other points)\n",
    "        broadcasted_pts = grid[i, :] - grid  # This creates a matrix of differences\n",
    "\n",
    "        # Compute the row-wise norm of broadcasted points\n",
    "        norm_broadcasted_pts = cp.linalg.norm(broadcasted_pts, axis=1)\n",
    "\n",
    "        # Compute the difference in predictions\n",
    "        Z_vec = Z[i] - Z\n",
    "\n",
    "        # Create a mask where the norm is less than epsilon and Z_vec equals -1\n",
    "        mask = (norm_broadcasted_pts < epsilon) & Z_vec != 0\n",
    "\n",
    "        # Find the indices where the mask is true\n",
    "        masked_indices = cp.where(mask)[0]  # Use [0] to extract the array of indices from the tuple\n",
    "\n",
    "        # Compute new points as the midpoint between grid[i,:] and the masked points\n",
    "        new_pts = (grid[i, :] + grid[masked_indices]) / 2\n",
    "\n",
    "        # Append new points to the boundary_points array\n",
    "        boundary_points = cp.append(boundary_points, new_pts, axis=0)\n",
    "    \n",
    "    boundary_points = boundary_points[1:,:]\n",
    "    return boundary_points\n",
    "\n",
    "n_features = X.shape[1]\n",
    "total_boundary_pts = cp.zeros((1,n_features))\n",
    "\n",
    "# Compute decision boundary points considering all features\n",
    "boundary_points = compute_decision_boundary_points_gpu(model2, X, resolution=15, epsilon=0.1)\n",
    "\n",
    "# Print the decision boundary points\n",
    "print(\"Decision Boundary Points (All Features):\")\n",
    "print(boundary_points)\n",
    "print(boundary_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49357089, 0.50642911],\n",
       "       [0.49359889, 0.50640111],\n",
       "       [0.49362689, 0.50637311],\n",
       "       ...,\n",
       "       [0.50639736, 0.49360264],\n",
       "       [0.50642536, 0.49357464],\n",
       "       [0.50645337, 0.49354663]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict_proba(boundary_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53592, 4)\n",
      "(53592, 1)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "(unable to allocate 18446744072287115536 bytes)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m X_vals, y_vals \u001b[38;5;241m=\u001b[39m boundary_points[:,\u001b[38;5;241m0\u001b[39m:n_features\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], cp\u001b[38;5;241m.\u001b[39mreshape(boundary_points[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)) \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_vals\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 6\u001b[0m interpolator \u001b[38;5;241m=\u001b[39m RBFInterpolator(X_vals\u001b[38;5;241m.\u001b[39mget(), y_vals\u001b[38;5;241m.\u001b[39mget(), kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcubic\u001b[39m\u001b[38;5;124m'\u001b[39m, smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-12\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\scipy\\interpolate\\_rbfinterp.py:373\u001b[0m, in \u001b[0;36mRBFInterpolator.__init__\u001b[1;34m(self, y, d, neighbors, smoothing, kernel, epsilon, degree)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpowers\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data points are required when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    369\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`degree` is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdegree\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and the number of dimensions is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    370\u001b[0m         )\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neighbors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 373\u001b[0m     shift, scale, coeffs \u001b[38;5;241m=\u001b[39m _build_and_solve_system(\n\u001b[0;32m    374\u001b[0m         y, d, smoothing, kernel, epsilon, powers\n\u001b[0;32m    375\u001b[0m         )\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# Make these attributes private since they do not always exist.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shift \u001b[38;5;241m=\u001b[39m shift\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\scipy\\interpolate\\_rbfinterp.py:110\u001b[0m, in \u001b[0;36m_build_and_solve_system\u001b[1;34m(y, d, smoothing, kernel, epsilon, powers)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_and_solve_system\u001b[39m(y, d, smoothing, kernel, epsilon, powers):\n\u001b[0;32m     83\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build and solve the RBF interpolation system of equations.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     lhs, rhs, shift, scale \u001b[38;5;241m=\u001b[39m _build_system(\n\u001b[0;32m    111\u001b[0m         y, d, smoothing, kernel, epsilon, powers\n\u001b[0;32m    112\u001b[0m         )\n\u001b[0;32m    113\u001b[0m     _, _, coeffs, info \u001b[38;5;241m=\u001b[39m dgesv(lhs, rhs, overwrite_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, overwrite_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: (unable to allocate 18446744072287115536 bytes)"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import RBFInterpolator \n",
    "print(boundary_points.shape)\n",
    "n_features = X.shape[1]\n",
    "X_vals, y_vals = boundary_points[:,0:n_features-1], cp.reshape(boundary_points[:,-1], (-1,1)) \n",
    "print(y_vals.shape)\n",
    "interpolator = RBFInterpolator(X_vals.get(), y_vals.get(), kernel='cubic', smoothing=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 20\n",
    "grid_points = cp.zeros((resolution ** n_features, n_features))\n",
    "for i, feature in enumerate(range(n_features)):\n",
    "        np_array = cp.linspace(boundary_points[:, feature].min(), boundary_points[:, feature].max(), resolution ** (n_features)).reshape(-1)\n",
    "        grid_points[:, i] = np_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 3)\n",
      "(160000, 3)\n",
      "(160000, 1)\n",
      "(160000, 4)\n"
     ]
    }
   ],
   "source": [
    "eval_coords = grid_points[:,0:n_features-1]\n",
    "print(eval_coords.shape)\n",
    "eval_values = interpolator(eval_coords.get())\n",
    "add_boundary_pts = cp.hstack((eval_coords, eval_values))\n",
    "print(eval_coords.shape)\n",
    "print(eval_values.shape)\n",
    "print(add_boundary_pts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = model2.predict_proba(add_boundary_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference: -2.164031962484323e-05\n"
     ]
    }
   ],
   "source": [
    "average_diff = cp.mean(arr[:, 0] - arr[:, 1])\n",
    "print(\"Average difference:\", average_diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numba\n",
    "from numba import cuda\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from scipy.linalg import norm\n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=5, n_redundant=0, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model (or any other classifier)\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the dataset\n",
    "df=pd.read_csv('SVM_Dataset2.csv')\n",
    "\n",
    "# svm_classifier.fit(df[['x1', 'x2']], df[['y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_compute(Z, grid, epsilon): \n",
    "    for i in range(len(grid) - 1):\n",
    "        # Compute broadcasted points (difference between grid[i,:] and all other points)\n",
    "        broadcasted_pts = grid[i, :] - grid  # This creates a matrix of differences\n",
    "\n",
    "        # Compute the row-wise norm of broadcasted points\n",
    "        norm_broadcasted_pts = np.linalg.norm(broadcasted_pts, axis=1)\n",
    "\n",
    "        # Compute the difference in predictions\n",
    "        Z_vec = Z[i] - Z\n",
    "\n",
    "        # Create a mask where the norm is less than epsilon and Z_vec equals -1\n",
    "        mask = (norm_broadcasted_pts < epsilon) & Z_vec != 0\n",
    "\n",
    "        # Find the indices where the mask is true\n",
    "        masked_indices = np.where(mask)[0]  # Use [0] to extract the array of indices from the tuple\n",
    "\n",
    "        # Compute new points as the midpoint between grid[i,:] and the masked points\n",
    "        new_pts = (grid[i, :] + grid[masked_indices]) / 2\n",
    "\n",
    "        # Append new points to the boundary_points array\n",
    "        boundary_points = np.append(boundary_points, new_pts, axis=0)\n",
    "    \n",
    "    boundary_points = boundary_points[1:,:]\n",
    "    return boundary_points\n",
    "\n",
    "def compute_decision_boundary_points_gpu(model, X, resolution=100, epsilon=0.01):\n",
    "    n_features = X.shape[1]    \n",
    "    grid = np.zeros((resolution ** n_features, n_features))\n",
    "    for i, feature in enumerate(range(n_features)):\n",
    "        cp_array = np.linspace(X[:, feature].min() - 1, X[:, feature].max() + 1, resolution ** (n_features)).reshape(-1)\n",
    "        grid[:, i] = cp_array\n",
    "    Z = np.asarray(model.predict(grid))\n",
    "    return broadcast_compute(Z, grid, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "import cupy as cp\n",
    "\n",
    "def find_boundary_kdtree(grid, Z, epsilon):\n",
    "    boundary_points = []\n",
    "    grid = np.asarray(grid)\n",
    "    Z = np.asarray(Z)\n",
    "\n",
    "    # Step 1: Group points by label\n",
    "    unique_labels = np.unique(Z)\n",
    "    label_to_points = {label: grid[Z == label] for label in unique_labels}\n",
    "\n",
    "    # Step 2: Check all unordered label pairs\n",
    "    for i in range(len(unique_labels)):\n",
    "        for j in range(i + 1, len(unique_labels)):\n",
    "            label_a, label_b = unique_labels[i], unique_labels[j]\n",
    "            cluster_a = label_to_points[label_a]\n",
    "            cluster_b = label_to_points[label_b]\n",
    "\n",
    "            # Build KDTree on cluster_b\n",
    "            tree_b = KDTree(cluster_b)\n",
    "\n",
    "            for point in cluster_a:\n",
    "                # Query for neighbors in cluster_b within epsilon\n",
    "                idxs = tree_b.query_radius([point], r=epsilon)[0]\n",
    "                for idx in idxs:\n",
    "                    match_point = cluster_b[idx]\n",
    "                    midpoint = (point + match_point) / 2\n",
    "                    boundary_points.append(midpoint)\n",
    "\n",
    "    return np.array(boundary_points)\n",
    "\n",
    "@numba.njit\n",
    "def cartesian_product_numba(arrays, out):\n",
    "    n_arrays = len(arrays)\n",
    "    shape = [len(a) for a in arrays]\n",
    "    for idx in range(out.shape[0]):\n",
    "        remainder = idx\n",
    "        for dim in range(n_arrays - 1, -1, -1):\n",
    "            size = shape[dim]\n",
    "            out[idx, dim] = arrays[dim][remainder % size]\n",
    "            remainder = remainder // size\n",
    "\n",
    "@cuda.jit\n",
    "def cartesian_product_cuda(input_2d, n_arrays, out):\n",
    "    idx = cuda.grid(1)\n",
    "    out_size = out.shape[0]\n",
    "    \n",
    "    if idx >= out_size:\n",
    "        return\n",
    "\n",
    "    stride = 1\n",
    "    for i in range(n_arrays - 1, -1, -1):\n",
    "        arr_len = input_2d.shape[1]\n",
    "        pos = (idx // stride) % arr_len\n",
    "        out[idx, i] = input_2d[i, pos]\n",
    "        stride *= arr_len\n",
    "\n",
    "\n",
    "def compute_cartesian_product_cuda(arrays):\n",
    "    # Ensure uniform lengths (or pad if necessary)\n",
    "    max_len = max(len(a) for a in arrays)\n",
    "    padded = np.array([np.pad(a, (0, max_len - len(a)), constant_values=0) for a in arrays], dtype=np.float32)\n",
    "    \n",
    "    n_arrays = len(arrays)\n",
    "    out_size = np.prod([len(a) for a in arrays])\n",
    "    \n",
    "    out = cuda.device_array((out_size, n_arrays), dtype=np.float32)\n",
    "    \n",
    "    d_input = cuda.to_device(padded)\n",
    "    \n",
    "    threads_per_block = 128\n",
    "    blocks_per_grid = (out_size + threads_per_block - 1) // threads_per_block\n",
    "    \n",
    "    cartesian_product_cuda[blocks_per_grid, threads_per_block](d_input, n_arrays, out)\n",
    "    \n",
    "    result = out.copy_to_host()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "@cuda.jit \n",
    "def find_boundary_gpu(grid, Z, epsilon, boundary_points, count):\n",
    "    i = cuda.grid(1)\n",
    "    n = grid.shape[0]\n",
    "\n",
    "    if i < n:\n",
    "        for j in range(i + 1, n):\n",
    "            dist = 0.0\n",
    "            for k in range(grid.shape[1]):\n",
    "                diff = grid[i, k] - grid[j, k]\n",
    "                dist += diff * diff\n",
    "            dist = dist ** 0.5\n",
    "\n",
    "            if dist < epsilon and Z[i] != Z[j]:\n",
    "                idx = cuda.atomic.add(count, 0, 1)\n",
    "                for d in range(grid.shape[1]):\n",
    "                    boundary_points[idx, d] = (grid[i, d] + grid[j, d]) / 2\n",
    "\n",
    "\n",
    "def compute_decision_boundary_points_cpu(model, X, resolution=100, epsilon=0.01):\n",
    "    \"\"\"\n",
    "    Compute decision boundary points in the high-dimensional feature space.\n",
    "    Args:\n",
    "        model: Trained classifier.\n",
    "        X: Input data (n_samples, n_features).\n",
    "        resolution: Number of points to sample along each feature axis.\n",
    "        epsilon: Small step size to detect class changes.\n",
    "    Returns:\n",
    "        boundary_points: Array of points near the decision boundary.\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    linspaces = [] \n",
    "    \n",
    "    for i in range(n_features):\n",
    "        dim =  np.linspace(X.iloc[:, i].min(), X.iloc[:, i].max(), resolution)\n",
    "        linspaces.append(dim) \n",
    "\n",
    "    total_size = np.prod([len(arr) for arr in linspaces], dtype=np.int64)\n",
    "\n",
    "    out = np.empty((total_size, len(linspaces)), dtype=np.float64)\n",
    "    arrays = tuple(np.asarray(arr) for arr in linspaces)\n",
    "    cartesian_product_numba(arrays, out)\n",
    "    \n",
    "    Z = model.predict(out)\n",
    "    boundary_points = find_boundary_kdtree(out, Z, epsilon)\n",
    "    boundary_df = pd.DataFrame(boundary_points, columns=X.columns)\n",
    "    return boundary_df\n",
    "\n",
    "def find_boundary_kdtree_cuda(grid, Z, epsilon):\n",
    "    boundary_points = []\n",
    "    grid = cp.asarray(grid)  # Move grid to GPU\n",
    "    Z = cp.asarray(Z)  # Move labels to GPU\n",
    "    \n",
    "    # Step 1: Group points by label\n",
    "    unique_labels = cp.unique(Z)\n",
    "    label_to_points = {label.item(): grid[Z == label] for label in unique_labels}\n",
    "    \n",
    "    # Step 2: Check all unordered label pairs\n",
    "    for i in range(len(unique_labels)):\n",
    "        for j in range(i + 1, len(unique_labels)):\n",
    "            label_a, label_b = unique_labels[i], unique_labels[j]\n",
    "            cluster_a = label_to_points[label_a.item()]\n",
    "            cluster_b = label_to_points[label_b.item()]\n",
    "\n",
    "            # Step 3: Compute distances between points in cluster_a and cluster_b\n",
    "            # Broadcasting for pairwise distance computation\n",
    "            diff = cp.expand_dims(cluster_a, 1) - cp.expand_dims(cluster_b, 0)\n",
    "            distances = cp.linalg.norm(diff, axis=-1)  # Compute Euclidean distance\n",
    "            \n",
    "            # Step 4: Get the points that are within the epsilon radius\n",
    "            indices = cp.where(distances <= epsilon)\n",
    "            \n",
    "            # Step 5: Compute the midpoints of the boundary points\n",
    "            for idx in zip(*indices):\n",
    "                point_a = cluster_a[idx[0]]\n",
    "                point_b = cluster_b[idx[1]]\n",
    "                midpoint = (point_a + point_b) / 2\n",
    "                boundary_points.append(midpoint.get())  # Move result back to CPU\n",
    "\n",
    "    return np.array(boundary_points)\n",
    "\n",
    "def compute_decision_boundary_points_gpu(model, X, resolution=100, epsilon=0.01):\n",
    "    \"\"\"\n",
    "    Compute decision boundary points in the high-dimensional feature space.\n",
    "    Args:\n",
    "        model: Trained classifier.\n",
    "        X: Input data (n_samples, n_features).\n",
    "        resolution: Number of points to sample along each feature axis.\n",
    "        epsilon: Small step size to detect class changes.\n",
    "    Returns:\n",
    "        boundary_points: Array of points near the decision boundary.\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    linspaces = [] \n",
    "    \n",
    "    for i in range(n_features):\n",
    "        dim =  np.linspace(X.iloc[:, i].min(), X.iloc[:, i].max(), resolution)\n",
    "        linspaces.append(dim) \n",
    "\n",
    "    total_size = np.prod([len(arr) for arr in linspaces], dtype=np.int64)\n",
    "\n",
    "    out = np.empty((total_size, len(linspaces)), dtype=np.float64)\n",
    "    arrays = tuple(np.asarray(arr) for arr in linspaces)\n",
    "    cartesian_product_numba(arrays, out)\n",
    "    \n",
    "    Z = model.predict(out)\n",
    "    boundary_points = find_boundary_kdtree_cuda(out, Z, epsilon)\n",
    "    boundary_df = pd.DataFrame(boundary_points, columns=X.columns)\n",
    "    return boundary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments of the Computation Costs for CPU only (SVM classifier)\n",
    "\n",
    "$\\textbf{ CPU used: AMD Ryzen 9 7950X 16-Core processor}$\n",
    "\n",
    "- 50 Resolution (R = 50) with CPU only \n",
    "- 47 minutes - Does not finish \n",
    "\n",
    "- 25 Resolution (R = 25) with CPU only \n",
    "- 23 minutes - Does not finish \n",
    "\n",
    "- 20 Resolution (R = 20) with CPU only \n",
    "- 20 minutes - Does not finish\n",
    "\n",
    "- 15 Resolution (R = 15) with CPU only \n",
    "- 26 minutes - Does not finish \n",
    "\n",
    "- 12 Resolution (R = 12) with CPU only \n",
    "- 6 minute runtime Done\n",
    "\n",
    "- 10 Resolution (R = 10) with CPU only \n",
    "- 85 seconds Done\n",
    "\n",
    "- 7 Resolution (R = 7) with CPU only\n",
    "- 5 seconds Done\n",
    "\n",
    "- 5 Resolution (R = 5) with CPU only \n",
    "- 0.3 second runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with CPU only (with Numba) -- 4 features\n",
    "\n",
    "- 20 Resolution (R = 20) with CPU \n",
    "- Over 10 minutes - NOT DONE\n",
    "\n",
    "- 17 Resolution (R = 17) with CPU \n",
    "- 6 minute runtime\n",
    "\n",
    "- 15 Resolution (R = 15) with CPU \n",
    "- 2 minute runtime\n",
    "\n",
    "- 10 Resolution (R = 10) with CPU \n",
    "- 6 second runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250,)\n",
      "(250,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = svm.SVC(kernel='poly',C=10, degree=2, probability=True)\n",
    "svm_classifier.fit(df[['x1', 'x2']], df['y'].values)\n",
    "\n",
    "# Compute decision boundary points considering all features\n",
    "boundary_points = compute_decision_boundary_points_cpu(svm_classifier, df[['x1','x2']], resolution=250, epsilon=0.1)\n",
    " \n",
    "# Print the decision boundary points\n",
    "print(\"Decision Boundary Points (All Features):\")\n",
    "print(boundary_points)\n",
    "print(boundary_points.shape)\n",
    "\n",
    "boundary_points = boundary_points.drop_duplicates(subset='x1')\n",
    "bound_x, bound_y = boundary_points.iloc[:,0], boundary_points.iloc[:, 1]\n",
    "\n",
    "N = 1000000\n",
    "lower_boundx, upper_boundx = np.min(bound_x), np.max(bound_x)\n",
    "f = interp1d(bound_x, bound_y, kind='cubic')\n",
    "X_pred = np.linspace(lower_boundx, upper_boundx, N)[:, np.newaxis]\n",
    "Y_pred = f(X_pred)\n",
    "lower_boundy, upper_boundy = np.min(bound_y), np.max(bound_y)\n",
    "x_min, x_max = bound_x.min(), bound_x.max()\n",
    "y_min, y_max = bound_y.min(), bound_y.max()\n",
    "\n",
    "X_pred = np.clip(X_pred, x_min, x_max)\n",
    "Y_pred = np.clip(Y_pred, y_min, y_max)\n",
    "plt.plot(X_pred, Y_pred, color='black')\n",
    "\n",
    "# undesired_datapt = np.array([undesired_coords[0], undesired_coords[1]])\n",
    "# optimal_datapt = closest_point(undesired_datapt, contour=contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Boundary Points (Probability Across Both classes):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.30758487, 0.69241513],\n",
       "       [0.30778302, 0.69221698],\n",
       "       [0.31262566, 0.68737434],\n",
       "       ...,\n",
       "       [0.31226139, 0.68773861],\n",
       "       [0.31102366, 0.68897634],\n",
       "       [0.30978129, 0.69021871]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Decision Boundary Points (Probability Across Both classes):\")\n",
    "svm_classifier.predict_proba(boundary_points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with GPU (with Numba) \n",
    "\n",
    "- 20 Resolution (R = 20) with GPU \n",
    "- 5.9 second runtime\n",
    "\n",
    "- 15 Resolution (R = 15) with GPU \n",
    "- 1.0 second runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.          4.0240481   4.04809619 ... 15.95190381 15.9759519\n",
      " 16.        ]\n",
      "[ 5.          5.03006012  5.06012024 ... 19.93987976 19.96993988\n",
      " 20.        ]\n",
      "(250000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Boundary Points (All Features):\n",
      "[[ 4.577154  15.17535  ]\n",
      " [ 4.3366733 15.836674 ]\n",
      " [ 4.264529  16.047094 ]\n",
      " ...\n",
      " [15.987976  11.102204 ]\n",
      " [15.987976  11.087173 ]\n",
      " [15.987976  11.117235 ]]\n",
      "(19452, 2)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bound_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(boundary_points\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     11\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000000\u001b[39m\n\u001b[1;32m---> 12\u001b[0m lower_boundx, upper_boundx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(bound_x), np\u001b[38;5;241m.\u001b[39mmax(bound_x)\n\u001b[0;32m     13\u001b[0m f \u001b[38;5;241m=\u001b[39m interp1d(bound_x, bound_y, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcubic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m X_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(lower_boundx, upper_boundx, N)[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bound_x' is not defined"
     ]
    }
   ],
   "source": [
    "svm_classifier = svm.SVC(kernel='poly',C=10, degree=2, probability=True)\n",
    "svm_classifier.fit(df[['x1', 'x2']], df['y'].values)\n",
    "# Compute decision boundary points considering all features\n",
    "boundary_points = compute_decision_boundary_points_gpu(svm_classifier, df[['x1','x2']], resolution=500, epsilon=0.1)\n",
    " \n",
    "# Print the decision boundary points\n",
    "print(\"Decision Boundary Points (All Features):\")\n",
    "print(boundary_points)\n",
    "print(boundary_points.shape)\n",
    "\n",
    "N = 1000000\n",
    "lower_boundx, upper_boundx = np.min(bound_x), np.max(bound_x)\n",
    "f = interp1d(bound_x, bound_y, kind='cubic')\n",
    "X_pred = np.linspace(lower_boundx, upper_boundx, N)[:, np.newaxis]\n",
    "Y_pred = f(X_pred)\n",
    "lower_boundy, upper_boundy = np.min(bound_y), np.max(bound_y)\n",
    "x_min, x_max = bound_x.min(), bound_x.max()\n",
    "y_min, y_max = bound_y.min(), bound_y.max()\n",
    "\n",
    "X_pred = np.clip(X_pred, x_min, x_max)\n",
    "Y_pred = np.clip(Y_pred, y_min, y_max)\n",
    "plt.plot(X_pred, Y_pred, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Boundary Points (Probability Across Both classes):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.31208524, 0.68791476],\n",
       "       [0.311943  , 0.688057  ],\n",
       "       [0.31250777, 0.68749223],\n",
       "       ...,\n",
       "       [0.31224754, 0.68775246],\n",
       "       [0.31326464, 0.68673536],\n",
       "       [0.31326464, 0.68673536]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Decision Boundary Points (Probability Across Both classes):\")\n",
    "svm_classifier.predict_proba(boundary_points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU only for logistic regression \n",
    "\n",
    "4 features, 15 resolution - CPU \n",
    "- 2.5 minute runtime -> 1.2 seconds\n",
    "\n",
    "5 features, 20 resolution - CPU\n",
    "- Hour + -> 1 minute 55 second runtime O(n log n) solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Compute decision boundary points considering all features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m boundary_points \u001b[38;5;241m=\u001b[39m compute_decision_boundary_points_cpu(model, pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mX, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]), resolution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print the decision boundary points\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Boundary Points (All Features):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 126\u001b[0m, in \u001b[0;36mcompute_decision_boundary_points_cpu\u001b[1;34m(model, X, resolution, epsilon)\u001b[0m\n\u001b[0;32m    123\u001b[0m cartesian_product_numba(arrays, out)\n\u001b[0;32m    125\u001b[0m Z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(out)\n\u001b[1;32m--> 126\u001b[0m boundary_points \u001b[38;5;241m=\u001b[39m find_boundary_kdtree(out, Z, epsilon)\n\u001b[0;32m    127\u001b[0m boundary_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(boundary_points, columns\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m boundary_df\n",
      "Cell \u001b[1;32mIn[27], line 25\u001b[0m, in \u001b[0;36mfind_boundary_kdtree\u001b[1;34m(grid, Z, epsilon)\u001b[0m\n\u001b[0;32m     21\u001b[0m tree_b \u001b[38;5;241m=\u001b[39m KDTree(cluster_b)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m point \u001b[38;5;129;01min\u001b[39;00m cluster_a:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Query for neighbors in cluster_b within epsilon\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     idxs \u001b[38;5;241m=\u001b[39m tree_b\u001b[38;5;241m.\u001b[39mquery_radius([point], r\u001b[38;5;241m=\u001b[39mepsilon)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m idxs:\n\u001b[0;32m     27\u001b[0m         match_point \u001b[38;5;241m=\u001b[39m cluster_b[idx]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute decision boundary points considering all features\n",
    "boundary_points = compute_decision_boundary_points_cpu(model, pd.DataFrame(data=X, columns=[\"x\"+str(i) for i in range(X.shape[1])]), resolution=25, epsilon=0.5)\n",
    " \n",
    "# Print the decision boundary points\n",
    "print(\"Decision Boundary Points (All Features):\")\n",
    "print(boundary_points)\n",
    "print(boundary_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "Out of memory allocating 48,924,628,392,713,728 bytes (allocated so far: 10,096,605,696 bytes).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Compute decision boundary points considering all features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m boundary_points \u001b[38;5;241m=\u001b[39m compute_decision_boundary_points_gpu(model, pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mX, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]), resolution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print the decision boundary points\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Boundary Points (All Features):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[25], line 188\u001b[0m, in \u001b[0;36mcompute_decision_boundary_points_gpu\u001b[1;34m(model, X, resolution, epsilon)\u001b[0m\n\u001b[0;32m    185\u001b[0m cartesian_product_numba(arrays, out)\n\u001b[0;32m    187\u001b[0m Z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(out)\n\u001b[1;32m--> 188\u001b[0m boundary_points \u001b[38;5;241m=\u001b[39m find_boundary_kdtree_cuda(out, Z, epsilon)\n\u001b[0;32m    189\u001b[0m boundary_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(boundary_points, columns\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m boundary_df\n",
      "Cell \u001b[1;32mIn[25], line 148\u001b[0m, in \u001b[0;36mfind_boundary_kdtree_cuda\u001b[1;34m(grid, Z, epsilon)\u001b[0m\n\u001b[0;32m    144\u001b[0m cluster_b \u001b[38;5;241m=\u001b[39m label_to_points[label_b\u001b[38;5;241m.\u001b[39mitem()]\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Step 3: Compute distances between points in cluster_a and cluster_b\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Broadcasting for pairwise distance computation\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m diff \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mexpand_dims(cluster_a, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m cp\u001b[38;5;241m.\u001b[39mexpand_dims(cluster_b, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    149\u001b[0m distances \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(diff, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Compute Euclidean distance\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Step 4: Get the points that are within the epsilon radius\u001b[39;00m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\core.pyx:1326\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.__sub__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\_kernel.pyx:1349\u001b[0m, in \u001b[0;36mcupy._core._kernel.ufunc.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\_kernel.pyx:645\u001b[0m, in \u001b[0;36mcupy._core._kernel._get_out_args_from_optionals\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\core.pyx:2884\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_init\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\_core\\\\core.pyx:257\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base._init_fast\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\cuda\\\\memory.pyx:738\u001b[0m, in \u001b[0;36mcupy.cuda.memory.alloc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\cuda\\\\memory.pyx:1424\u001b[0m, in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\cuda\\\\memory.pyx:1445\u001b[0m, in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\cuda\\\\memory.pyx:1116\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool.malloc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\cuda\\\\memory.pyx:1137\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._malloc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\cuda\\\\memory.pyx:1382\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._try_malloc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\\\cuda\\\\memory.pyx:1385\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._try_malloc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: Out of memory allocating 48,924,628,392,713,728 bytes (allocated so far: 10,096,605,696 bytes)."
     ]
    }
   ],
   "source": [
    "# Compute decision boundary points considering all features\n",
    "boundary_points = compute_decision_boundary_points_gpu(model, pd.DataFrame(data=X, columns=[\"x\"+str(i) for i in range(X.shape[1])]), resolution=20, epsilon=0.1)\n",
    " \n",
    "# Print the decision boundary points\n",
    "print(\"Decision Boundary Points (All Features):\")\n",
    "print(boundary_points)\n",
    "print(boundary_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5111058 , 0.4888942 ],\n",
       "       [0.49046014, 0.50953986],\n",
       "       [0.48753307, 0.51246693],\n",
       "       ...,\n",
       "       [0.47453406, 0.52546594],\n",
       "       [0.47745585, 0.52254415],\n",
       "       [0.5068743 , 0.4931257 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(boundary_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), slice(0, 3, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:173\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), slice(0, 3, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m grids \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(\u001b[38;5;241m*\u001b[39mranges)\n\u001b[0;32m      7\u001b[0m new_points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1000\u001b[39m, n_features\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m X_vals, y_vals \u001b[38;5;241m=\u001b[39m boundary_points[:,\u001b[38;5;241m0\u001b[39m:n_features\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], boundary_points[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \n\u001b[0;32m     10\u001b[0m interpolated_values \u001b[38;5;241m=\u001b[39m griddata(X_vals, y_vals, new_points, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcubic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3817\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m   3818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6059\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   6055\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   6056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   6057\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   6058\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 6059\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), slice(0, 3, None))"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import griddata\n",
    "\n",
    "n_features = X.shape[1]\n",
    "print(n_features)\n",
    "ranges = [np.linspace(X[:, j].min() - 1, X[:, j].max() + 1, 100) for j in range(n_features)]\n",
    "grids = np.meshgrid(*ranges)\n",
    "new_points = np.random.rand(1000, n_features-1)\n",
    "X_vals, y_vals = boundary_points[:,0:n_features-1], boundary_points[:,-1] \n",
    "\n",
    "interpolated_values = griddata(X_vals, y_vals, new_points, method='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 4)\n",
      "(160000, 1)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "(unable to allocate 18446744073541027856 bytes)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m X_vals, y_vals \u001b[38;5;241m=\u001b[39m boundary_points[:,\u001b[38;5;241m0\u001b[39m:n_features\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], np\u001b[38;5;241m.\u001b[39mreshape(boundary_points[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)) \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_vals\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 6\u001b[0m interpolator \u001b[38;5;241m=\u001b[39m RBFInterpolator(X_vals, y_vals, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcubic\u001b[39m\u001b[38;5;124m'\u001b[39m, smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-12\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\scipy\\interpolate\\_rbfinterp.py:373\u001b[0m, in \u001b[0;36mRBFInterpolator.__init__\u001b[1;34m(self, y, d, neighbors, smoothing, kernel, epsilon, degree)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpowers\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data points are required when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    369\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`degree` is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdegree\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and the number of dimensions is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    370\u001b[0m         )\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neighbors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 373\u001b[0m     shift, scale, coeffs \u001b[38;5;241m=\u001b[39m _build_and_solve_system(\n\u001b[0;32m    374\u001b[0m         y, d, smoothing, kernel, epsilon, powers\n\u001b[0;32m    375\u001b[0m         )\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# Make these attributes private since they do not always exist.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shift \u001b[38;5;241m=\u001b[39m shift\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\scipy\\interpolate\\_rbfinterp.py:110\u001b[0m, in \u001b[0;36m_build_and_solve_system\u001b[1;34m(y, d, smoothing, kernel, epsilon, powers)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_and_solve_system\u001b[39m(y, d, smoothing, kernel, epsilon, powers):\n\u001b[0;32m     83\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build and solve the RBF interpolation system of equations.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     lhs, rhs, shift, scale \u001b[38;5;241m=\u001b[39m _build_system(\n\u001b[0;32m    111\u001b[0m         y, d, smoothing, kernel, epsilon, powers\n\u001b[0;32m    112\u001b[0m         )\n\u001b[0;32m    113\u001b[0m     _, _, coeffs, info \u001b[38;5;241m=\u001b[39m dgesv(lhs, rhs, overwrite_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, overwrite_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: (unable to allocate 18446744073541027856 bytes)"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import RBFInterpolator \n",
    "print(boundary_points.shape)\n",
    "n_features = X.shape[1]\n",
    "X_vals, y_vals = boundary_points[:,0:n_features-1], np.reshape(boundary_points[:,-1], (-1,1)) \n",
    "print(y_vals.shape)\n",
    "interpolator = RBFInterpolator(X_vals, y_vals, kernel='cubic', smoothing=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390625, 4)\n"
     ]
    }
   ],
   "source": [
    "n_features = X.shape[1]\n",
    "ranges = [np.linspace(boundary_points[:, j].min(), boundary_points[:, j].max(), 25) for j in range(n_features)]\n",
    "grids = np.meshgrid(*ranges) \n",
    "\n",
    "grid_points = np.vstack([g.ravel() for g in grids]).T\n",
    "print(grid_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390625, 4)\n"
     ]
    }
   ],
   "source": [
    "print(grid_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390625, 3)\n",
      "(390625, 3)\n",
      "(390625, 1)\n",
      "(390625, 4)\n"
     ]
    }
   ],
   "source": [
    "eval_coords = grid_points[:,0:n_features-1]\n",
    "print(eval_coords.shape)\n",
    "eval_values = interpolator(eval_coords)\n",
    "add_boundary_pts = np.hstack((eval_coords, eval_values))\n",
    "print(eval_coords.shape)\n",
    "print(eval_values.shape)\n",
    "print(add_boundary_pts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolating Additional Boundary points Using N-1 data point coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = model.predict_proba(add_boundary_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference: -3.008925147444152e-06\n"
     ]
    }
   ],
   "source": [
    "average_diff = np.mean(arr[:, 0] - arr[:, 1])\n",
    "print(\"Average difference:\", average_diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

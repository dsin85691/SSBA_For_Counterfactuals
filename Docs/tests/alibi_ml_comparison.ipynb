{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7ce602",
   "metadata": {},
   "source": [
    "# Alibi ML Comparison with Optimal Point method \n",
    "\n",
    "We compare the DiCE Model-agnostic methods with the optimal point method in this notebook. \n",
    "\n",
    "1. First, we import tensorflow, alibi, and other relevant libraries.\n",
    "2. Second, we import the packaged files needed to run the \"Optimal Point\" Methodology.\n",
    "3. Third, we run the experiments and compare the results at the end. Here, we use a two-layer MLP to perform comparisons since the alibi applies a gradient-based optimization technique.\n",
    "4. Finally, we compare the runtimes of DiCE and the Optimal Point methodology.\n",
    "\n",
    "Note: Running large experiments, particularly $100$ data points, can take a few hours for completion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951aba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.14.1\n",
      "Eager execution enabled:  False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(40) # suppress deprecation messages\n",
    "tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "%matplotlib inline\n",
    "\n",
    "from alibi.explainers import Counterfactual\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # False\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "from dice_ml.utils import helpers \n",
    "from sklearn.utils import resample\n",
    "import random\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2caf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "from files.common_functions import euclidean_distance, closest_border_point, closest_point, move_from_A_to_B_with_x1_displacement\n",
    "from files.common_functions import get_multi_dim_border_points, det_constraints, real_world_constraints, constraint_bounds\n",
    "from files.common_functions import balance_dataset, check_class_balance, convert_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13674c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../toy_dataset.csv')\n",
    "\n",
    "# Step 2: Separate features and labels\n",
    "X = df[['x1', 'x2']].astype('float32')  # features\n",
    "y = df['y'].values.astype('int32')            # labels\n",
    "y = (y + 1) // 2 \n",
    "df['y'] = y.astype('int32')\n",
    "df[['x1', 'x2']] = df[['x1', 'x2']].astype('float32')\n",
    "\n",
    "X_train, y_train = X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd88613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    x_in = Input(shape=(2,))\n",
    "\n",
    "    x = Flatten()(x_in)\n",
    "    x = Dense(2, activation='relu')(x)\n",
    "    x = Dense(10, activation='relu')(x) \n",
    "    probs = Dense(2, activation='softmax')(x)\n",
    "    nn = Model(inputs=x_in, outputs=probs)\n",
    "    nn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c737528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                30        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58 (232.00 Byte)\n",
      "Trainable params: 58 (232.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "nn = nn_model()\n",
    "nn.summary()\n",
    "nn.fit(X_train, y_train, batch_size=10, epochs=1000, verbose=0, steps_per_epoch=5)\n",
    "nn.save('toy_dataset_nn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9469a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset():\n",
    "    X1=df['x1']\n",
    "    X2=df['x2']\n",
    "    X_train=np.array(list(zip(X1,X2)))\n",
    "    y_train=df['y'].values\n",
    "\n",
    "    color_ls = []\n",
    "    for k in y_train:\n",
    "        if k == 1:\n",
    "            color_ls.append('b')\n",
    "        else:\n",
    "            color_ls.append('r')\n",
    "    color_ls\n",
    "    label = []\n",
    "    for k in y_train:\n",
    "        if k == 1:\n",
    "            label.append('H')\n",
    "        else:\n",
    "            label.append('NH')\n",
    "\n",
    "    for k, (i,j) in enumerate(X_train):\n",
    "        plt.scatter(i, j, c = color_ls[k])\n",
    "        plt.text(i+0.02, j+0.02, label[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4af64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_binary_search(model, point, opp_point, point_target, epsilon=1e-3, max_iter=100):\n",
    "    \"\"\"\n",
    "    Perform a binary search along the line segment between two points to find the\n",
    "    approximate alpha value where the model's prediction changes from one target\n",
    "    label to another. This is useful for approximating decision boundaries in\n",
    "    binary classification by finding the transition point along a segment connecting\n",
    "    points from opposite classes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : object\n",
    "        A trained machine learning model with a `predict` method that takes a list\n",
    "        or array of input points and returns predictions as an array. The model\n",
    "        should be a binary classifier (e.g., from scikit-learn, PyTorch, etc.).\n",
    "        Example: sklearn.linear_model.LogisticRegression instance.\n",
    "    \n",
    "    point : numpy.ndarray\n",
    "        A 1D array representing the starting point (feature vector) in the feature\n",
    "        space, typically from one class. Must have the same shape as `opp_point`.\n",
    "    \n",
    "    opp_point : numpy.ndarray\n",
    "        A 1D array representing the opposing point (feature vector) in the feature\n",
    "        space, typically from the opposite class. Must have the same shape as `point`.\n",
    "    \n",
    "    point_target : int or str\n",
    "        The expected prediction label for the `point`. This is used to initialize\n",
    "        the search and compare against the model's prediction at interpolated points.\n",
    "        Should match the model's output format (e.g., 0 or 1 for binary classes).\n",
    "    \n",
    "    epsilon: float \n",
    "        The difference between starting and ending alpha values should be less than epsilon defined in the arguments of the call.\n",
    "\n",
    "    max_iter : int \n",
    "        The number of iterations needed to find an appropriate alpha. This is the limit for the number of iterations for binary search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The approximate alpha value (between 0 and 1) where the model's prediction\n",
    "        transitions. A value closer to 0 means the boundary is nearer to `point`,\n",
    "        while closer to 1 means nearer to `opp_point`.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    None explicitly, but may raise exceptions from `model.predict` if the input\n",
    "    shapes are incompatible or if the model is not properly trained.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - This function assumes the decision boundary is crossed exactly once along the\n",
    "      line segment; multiple crossings (e.g., in non-linear models) may lead to\n",
    "      approximate or incorrect results.\n",
    "    - The binary search updates bounds based on prediction matches, but if no flip\n",
    "      occurs (e.g., both points predicted the same), it will converge to a midpoint\n",
    "      without a true boundary.\n",
    "    - Usage: Typically called within a loop over pairs of points from different\n",
    "      classes to sample multiple boundary points.\n",
    "    \"\"\"\n",
    "    start, end = 0, 1  \n",
    "\n",
    "    for j in range(max_iter): \n",
    "\n",
    "        mid = (start + end) / 2 \n",
    "        mid_point = (1 - mid) * point + mid * opp_point         \n",
    "        pred = model.predict(mid_point.reshape(1, -1))\n",
    "        pred = np.argmax(pred, axis=1).item()\n",
    "\n",
    "        if pred == point_target: \n",
    "            start = mid \n",
    "        else: \n",
    "            end = mid \n",
    "        \n",
    "        if j % 4 == 0:\n",
    "            if abs(start - end) < epsilon: \n",
    "                break \n",
    "    \n",
    "    return (start + end) / 2\n",
    "\n",
    "\n",
    "def find_decision_boundary(model, X, y, epsilon=1e-3, threshold=10000):\n",
    "    \"\"\"\n",
    "    Approximate the decision boundary of a binary classification model by sampling\n",
    "    points along line segments between correctly classified points from opposite\n",
    "    classes. Uses binary search to find transition points and collects them into\n",
    "    a DataFrame. Handles categorical features by rounding them to integers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : object\n",
    "        A trained binary classification model with a `predict` method that takes\n",
    "        a list or array of input points and returns predictions as an array.\n",
    "        Example: sklearn.svm.SVC instance.\n",
    "    \n",
    "    X : pandas.DataFrame\n",
    "        The feature dataset, where rows are samples and columns are features.\n",
    "        Supports mixed types, including integer categoricals.\n",
    "    \n",
    "    y : pandas.Series or numpy.ndarray\n",
    "        The target labels corresponding to X. Must contain exactly two unique\n",
    "        binary labels (e.g., 0 and 1).\n",
    "    \n",
    "    epsilon : float, optional\n",
    "        The precision for the binary search in `alpha_binary_search`. Smaller\n",
    "        values increase accuracy but computation time. Default is 1e-3.\n",
    "    \n",
    "    threshold : int, optional\n",
    "        The maximum number of boundary points to generate. Stops early if reached\n",
    "        to prevent excessive computation on large datasets. Default is 10000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the approximated boundary points, with the same\n",
    "        columns as X. Categorical columns (detected as int types) are converted\n",
    "        to integers.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If y does not contain exactly two unique labels (non-binary classification).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - This function clusters points by true labels (y), then filters pairs where\n",
    "      the model correctly predicts them (to ensure opposite sides of the boundary).\n",
    "    - It may miss boundaries if the model has high error rates (few correct pairs).\n",
    "    - Computational complexity is O(n*m) where n and m are cluster sizes, capped\n",
    "      by threshold. For large datasets, reduce threshold or sample clusters.\n",
    "    - A `bool_vec` is created but unused; it may be a remnant for future masking\n",
    "      (e.g., to ignore categoricals in interpolation).\n",
    "    - Categorical features are auto-detected as int columns and rounded to int\n",
    "      in the output for interpretability.\n",
    "    - Usage: Call after training a model to visualize or analyze its boundary,\n",
    "      e.g., plot the points in 2D or use for explanations.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> import pandas as pd\n",
    "    >>> from sklearn.svm import SVC\n",
    "    >>> X = pd.DataFrame({'feat1': [0, 1, 2], 'feat2': [0, 1, 0]})\n",
    "    >>> y = np.array([0, 1, 0])\n",
    "    >>> model = SVC(kernel='linear').fit(X, y)\n",
    "    >>> boundary = find_decision_boundary(model, X, y, epsilon=0.001, threshold=5)\n",
    "    >>> print(boundary.shape)  # e.g., (number_of_points, 2)\n",
    "    (2, 2)\n",
    "    \"\"\"\n",
    "    # Detect categorical features (assumed as int columns)\n",
    "    categorical_features = X.select_dtypes(include='int32').columns.tolist()\n",
    "    print(categorical_features)\n",
    "\n",
    "    X_np = X.to_numpy()  # Convert features to NumPy for efficient ops\n",
    "    y_np = y.to_numpy() if not isinstance(y, np.ndarray) else y  # Ensure y is NumPy\n",
    "    boundary_points = []  # List to collect boundary point arrays\n",
    "    unique_labels = np.unique(y_np)  # Get unique class labels\n",
    "\n",
    "    if len(unique_labels) != 2:\n",
    "        raise ValueError(\"Only supports binary classification.\")\n",
    "    \n",
    "    label_a, label_b = unique_labels[0], unique_labels[1]  # Assign labels\n",
    "\n",
    "    # Cluster points by true labels\n",
    "    cluster_a = X_np[y_np == label_a]\n",
    "    cluster_b = X_np[y_np == label_b]\n",
    "\n",
    "    # After creating cluster_a and cluster_b\n",
    "    preds_a = model.predict(cluster_a)\n",
    "    preds_b = model.predict(cluster_b)\n",
    "\n",
    "    if isinstance(preds_a, np.ndarray) and len(preds_a.shape) > 1: \n",
    "        preds_a = np.argmax(preds_a, axis=1) \n",
    "        preds_b = np.argmax(preds_b, axis=1)\n",
    "\n",
    "    correct_a = cluster_a[preds_a == label_a]\n",
    "    correct_b = cluster_b[preds_b == label_b]\n",
    "\n",
    "    num_pairs = min(threshold, correct_a.shape[0] * correct_b.shape[0])  # Avoid overflow\n",
    "    a_indices = np.random.choice(correct_a.shape[0], num_pairs, replace=True)\n",
    "    b_indices = np.random.choice(correct_b.shape[0], num_pairs, replace=True)\n",
    "\n",
    "    boundary_points = []\n",
    "    for idx in range(num_pairs):\n",
    "        point = correct_a[a_indices[idx]]\n",
    "        match_point = correct_b[b_indices[idx]]\n",
    "        alpha = alpha_binary_search(model, point, match_point, label_a, epsilon=epsilon)\n",
    "        boundary = (1 - alpha) * point + alpha * match_point\n",
    "        boundary_points.append(boundary)\n",
    "\n",
    "    # Convert list to DataFrame with original columns\n",
    "    boundary_pts = pd.DataFrame(data=boundary_points, columns=X.columns)\n",
    "    \n",
    "    # Round categoricals to int for discrete values\n",
    "    for col in categorical_features: \n",
    "        boundary_pts[col] = boundary_pts[col].astype(int)\n",
    "\n",
    "    return boundary_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1c68f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_point(dataset, model, desired_class, original_class, chosen_row=-1, threshold=10000, point_epsilon=0.1, epsilon=0.01, constraints=[], deltas=[], plot=False): \n",
    "    \"\"\"\n",
    "    Finds the closest point to the decision boundary from an undesired point,\n",
    "    optionally constrained by real-world conditions.\n",
    "    This essentially finds the counterfactual explanation for a given point by minimizing the distance to the given boundary.\n",
    "    This method is important because it addresses a key problem with the original optimal_point() function where we generated an R^n dimensional grid that we would then have to iterate over. \n",
    "    The problem with iterating over such a grid is eventually that we will hit a memory error for high-dimensional features such as 20, 30 or 40 features. This will cause the function to crash. \n",
    "    Additionally, due to the exponential increase of the number of features to search, the grid will become infeasible to search (curse of dimensionality). \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : pd.DataFrame\n",
    "        Full dataset containing features and a final column with class labels.\n",
    "    \n",
    "    model : sklearn-like classifier\n",
    "        A binary classification model with a `.fit()` and `.predict()` method.\n",
    "    \n",
    "    desired_class : int or label\n",
    "        The target class we want the corrected point to belong to.\n",
    "    \n",
    "    original_class : int or label\n",
    "        The actual class label of the undesired point.\n",
    "    \n",
    "    chosen_row :  int \n",
    "        The selected row of the dataset to find the counterfactual explanation for\n",
    "    \n",
    "    threshold : int, optional\n",
    "        Max number of decision boundary points to sample. Default is 10000.\n",
    "    \n",
    "    point_epsilon : float, optional\n",
    "        Precision used to estimate decision boundary points. Default is 0.1.\n",
    "    \n",
    "    epsilon : float, optional\n",
    "        Step size used when displacing a point toward the decision boundary. Default is 0.01.\n",
    "    \n",
    "    constraints : list, optional\n",
    "        A list of real-world constraints on the features (e.g., ranges, logic constraints). Default is [].\n",
    "    \n",
    "    deltas : list, optional\n",
    "        Tolerances or maximum displacements for each feature. Default is [].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A corrected point that satisfies the class change and real-world constraints.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    Exception\n",
    "        If the number of constraints exceeds the number of features.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - This function trains the model on the provided dataset, generates boundary points using\n",
    "      `find_decision_boundary`, applies constraints, and finds the closest optimal point.\n",
    "    - Assumes binary classification and relies on external functions like `real_world_constraints`,\n",
    "      `closest_point`, `move_from_A_to_B_with_x1_displacement`, etc., which must be defined elsewhere.\n",
    "    - Includes plotting for visualization (e.g., boundary contours, points), which requires matplotlib.\n",
    "    - The function blends boundary approximation with counterfactual generation, useful for explainable AI.\n",
    "    - Print statements are for progress tracking; plotting is partially commented out but can be enabled.\n",
    "    - Usage: Call with a dataset and model to generate counterfactuals, e.g., for model interpretation or optimization.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> from sklearn.linear_model import LogisticRegression\n",
    "    >>> dataset = pd.DataFrame({'feat1': [0, 1, 2], 'feat2': [0, 1, 0], 'label': [0, 1, 0]})\n",
    "    >>> model = LogisticRegression()\n",
    "    >>> undesired_coords = [2, 0]  # Example point from class 0\n",
    "    >>> optimal = optimal_point(dataset, model, desired_class=1, original_class=0, undesired_coords=undesired_coords)\n",
    "    >>> print(optimal)  # e.g., array([[1.5, 0.5]])\n",
    "    \"\"\"\n",
    "    # Convert categorical columns if needed (before balancing)\n",
    "    inv_col_map = convert_columns(dataset)\n",
    "\n",
    "    # Extract features and labels before balancing\n",
    "    X_orig = dataset.iloc[:, :-1]\n",
    "    \n",
    "    # Save the original row's feature values\n",
    "    undesired_coords = X_orig.iloc[chosen_row, :].copy()\n",
    "\n",
    "    # Balance the dataset\n",
    "    dataset = balance_dataset(df=dataset, target=dataset.columns[-1])\n",
    "    \n",
    "    if not check_class_balance(dataset, target=dataset.columns[-1]):\n",
    "        raise RuntimeError(\"Failed to balance classes for binary classification\")\n",
    "    \n",
    "    sampled_dataset = dataset.sample(n=min(dataset.shape[0], 10000))\n",
    "\n",
    "    # Extract new training features/labels after balancing\n",
    "    X_train = sampled_dataset.iloc[:, :-1]\n",
    "    y_train = sampled_dataset.iloc[:, -1]\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Fitting model...\")\n",
    "    model.fit(X_train, y_train, epochs=100)\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # STEP 2: Find decision boundary\n",
    "    # -------------------------------\n",
    "    print(\"boundary points started generation...\")\n",
    "\n",
    "    # This step uses binary interpolation to get points close to the decision boundary\n",
    "    boundary_points = find_decision_boundary(model, X_train, y_train,\n",
    "                                             threshold=threshold, epsilon=point_epsilon)\n",
    "    print(\"boundary points finished.\")\n",
    "    print(boundary_points.shape)\n",
    "\n",
    "    # -------------------------------\n",
    "    # STEP 3: Apply real-world constraints (optional)\n",
    "    # -------------------------------\n",
    "    # Reduce boundary points based on external rules (e.g., cost limits, physics constraints)\n",
    "    contours = real_world_constraints(points=boundary_points,\n",
    "                                      undesired_coords=undesired_coords,\n",
    "                                      constraints=constraints)\n",
    "    contours = np.unique(contours.to_numpy(), axis=0)  # Remove duplicates from constrained points\n",
    "    undesired_datapt = np.reshape(undesired_coords, (1, -1))  # Reshape undesired point to 2D array\n",
    "\n",
    "    # -------------------------------\n",
    "    # STEP 4: Find closest point on constrained boundary\n",
    "    # -------------------------------\n",
    "    print(\"Finding the closest point from the contour line to the point...\")\n",
    "    optimal_datapt = closest_point(undesired_datapt, contour=contours)\n",
    "    print(\"Finding the closest point from the contour line to the point.\")  # Note: Duplicate print, possibly a typo\n",
    "    if plot:\n",
    "        plt.scatter(contours[:,0], contours[:,1], lw=1, color='red')  # Commented: Plot contours for visualization\n",
    "\n",
    "    # -------------------------------\n",
    "    # STEP 5: Post-process based on class flip requirement\n",
    "    # -------------------------------\n",
    "\n",
    "    # If we want to *flip* the class of the point...\n",
    "    if desired_class != original_class: \n",
    "         # Move in the direction of the boundary, slightly overshooting\n",
    "        D = optimal_datapt - undesired_datapt  # Compute direction vector\n",
    "        deltas = D * (1+epsilon)  # Scale by (1 + epsilon) to overshoot\n",
    "        optimal_datapt = move_from_A_to_B_with_x1_displacement(undesired_datapt, optimal_datapt, deltas=deltas)\n",
    "    else:\n",
    "        # If we want to *stay within* the same class (more constrained)\n",
    "        closest_boundedpt = None\n",
    "        deltas, len_constr = det_constraints(datapt=undesired_datapt[0], deltas=deltas)  # Determine constraints\n",
    "\n",
    "        if len_constr > X_train.shape[1]:\n",
    "            raise Exception(\"There cannot be more constraints than features\")\n",
    "\n",
    "        elif len_constr == X_train.shape[1]:\n",
    "            # All n dimensions are constrained, so generate an exact grid of boundary candidates\n",
    "            bounded_contour_pts = get_multi_dim_border_points(center=undesired_datapt[0],\n",
    "                                                              extents=deltas,\n",
    "                                                              step=0.05)\n",
    "            np_bounded_contour = np.array(bounded_contour_pts)  # Convert to NumPy array\n",
    "            x_values, y_values = np_bounded_contour[:, 0], np_bounded_contour[:, 1]  # Extract x/y for plotting\n",
    "            #plt.scatter(x_values, y_values, marker='o')  # Plot bounded points\n",
    "            closest_boundedpt = closest_border_point(bounded_contour_pts, contour=contours)  # Find closest on border\n",
    "\n",
    "        else:\n",
    "            # Partially constrained - less than n dimensions are constrained\n",
    "            bounded_contour_pts = constraint_bounds(contours, undesired_datapt, deltas)  # Apply partial bounds\n",
    "            closest_boundedpt = closest_point(point=undesired_datapt, contour=bounded_contour_pts)  # Find closest\n",
    "        \n",
    "        D = closest_boundedpt - undesired_datapt  # Compute direction\n",
    "        optimal_datapt = move_from_A_to_B_with_x1_displacement(undesired_datapt, closest_boundedpt, deltas=D)  # Move point\n",
    "    \n",
    "    # Plot original and optimal points with connecting line\n",
    "    if plot:\n",
    "        plt.scatter(undesired_datapt[0][0], undesired_datapt[0][1], c = 'r')  # Plot undesired point\n",
    "        plt.text(undesired_datapt[0][0]+0.002, undesired_datapt[0][1]+0.002, 'NH')  # Label 'NH' (e.g., Non-Healthy)\n",
    "        plt.scatter(optimal_datapt[0][0], optimal_datapt[0][1], c = 'g')  # Plot optimal point (changed to green for distinction)\n",
    "        plt.text(optimal_datapt[0][0]+0.002, optimal_datapt[0][1]+0.002, 'NH')  # Label 'H' (e.g., Healthy; adjusted from duplicate 'NH')\n",
    "        plt.plot([undesired_datapt[0][0], optimal_datapt[0][0]], [undesired_datapt[0][1],optimal_datapt[0][1]], linestyle='--')  # Dashed line between points\n",
    "    \n",
    "    categorical_features = [col for col in inv_col_map.keys()]\n",
    "    final_optimal_datapt = [] \n",
    "\n",
    "    for col in X_train.columns:\n",
    "        if col in categorical_features: \n",
    "            idx = optimal_datapt[0,X_train.columns.get_loc(col)].astype(int)\n",
    "            final_optimal_datapt.append(inv_col_map[col][idx])\n",
    "        else: \n",
    "            final_optimal_datapt.append(optimal_datapt[0,X_train.columns.get_loc(col)])\n",
    "\n",
    "    return model, optimal_datapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d42d0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y):\n",
    "    \"\"\"\n",
    "    Plots the decision boundary for a TensorFlow model in 2D feature space.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained TensorFlow Keras model (binary or multi-class classifier).\n",
    "    - X: numpy array of shape (n_samples, 2) - the input features.\n",
    "    - y: numpy array of shape (n_samples,) - the target labels.\n",
    "\n",
    "    The function assumes the model has a .predict() method that returns probabilities.\n",
    "    For binary classification, it thresholds at 0.5.\n",
    "    For multi-class, it uses argmax on the predictions.\n",
    "    \"\"\"\n",
    "    if X.shape[1] != 2:\n",
    "        raise ValueError(\"X must have exactly 2 features for 2D plotting.\")\n",
    "\n",
    "    # Determine number of classes for colormap\n",
    "    num_classes = len(np.unique(y))\n",
    "    if num_classes == 2:\n",
    "        cmap = plt.cm.RdYlBu\n",
    "    else:\n",
    "        cmap = plt.cm.Set1  # Suitable for multi-class\n",
    "\n",
    "    # Create a mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 1000), np.linspace(y_min, y_max, 1000))\n",
    "\n",
    "    # Prepare grid points for prediction\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = model.predict(grid_points, verbose=0)\n",
    "\n",
    "    # Handle binary vs multi-class\n",
    "    if predictions.shape[1] == 1:  # Binary classification (sigmoid output)\n",
    "        pred_labels = (predictions > 0.5).astype(int).reshape(xx.shape)\n",
    "    else:  # Multi-class (softmax output)\n",
    "        pred_labels = np.argmax(predictions, axis=1).reshape(xx.shape)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    plt.contourf(xx, yy, pred_labels, cmap=cmap, alpha=0.3)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, edgecolors='k')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title('Decision Boundary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c96fb6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_func(points):\n",
    "    for point, cf_point in points: \n",
    "        point = np.squeeze(point)\n",
    "        cf_point = np.squeeze(cf_point)\n",
    "        x, y = point[0], point[1]\n",
    "        cf_x, cf_y = cf_point[0], cf_point[1]\n",
    "\n",
    "        plt.scatter(cf_x, cf_y, c='yellow')\n",
    "        plt.text(cf_x + 0.002, cf_y + 0.002, 'H')\n",
    "        plt.plot([x, cf_x], [y, cf_y], linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e56467f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1,) + X_train.shape[1:]\n",
    "target_proba = 0.5\n",
    "tol = 0.0001 # want counterfactuals with p(class)>0.99\n",
    "target_class = 'other' # any class other than 7 will do\n",
    "max_iter = 1000\n",
    "lam_init = 1e-1\n",
    "max_lam_steps = 10\n",
    "learning_rate_init = 0.1\n",
    "feature_range = (X_train.min(),X_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6315419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b024f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " y\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 20 samples\n",
      "Epoch 1/1000\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0476 - acc: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\drexel_research_2024_2025\\Docs\\files\\common_functions.py:422: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/sample - loss: 1.0476 - acc: 0.5000\n",
      "Epoch 2/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.0243 - acc: 0.5000\n",
      "Epoch 3/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.0023 - acc: 0.5000\n",
      "Epoch 4/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.9808 - acc: 0.5000\n",
      "Epoch 5/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.9597 - acc: 0.5000\n",
      "Epoch 6/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.9393 - acc: 0.5000\n",
      "Epoch 7/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.9195 - acc: 0.5000\n",
      "Epoch 8/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.9005 - acc: 0.5000\n",
      "Epoch 9/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.8822 - acc: 0.5000\n",
      "Epoch 10/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.8647 - acc: 0.5000\n",
      "Epoch 11/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.8479 - acc: 0.5000\n",
      "Epoch 12/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.8318 - acc: 0.5000\n",
      "Epoch 13/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.8164 - acc: 0.5000\n",
      "Epoch 14/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.8017 - acc: 0.5000\n",
      "Epoch 15/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7877 - acc: 0.5000\n",
      "Epoch 16/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7747 - acc: 0.5000\n",
      "Epoch 17/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.7628 - acc: 0.5000\n",
      "Epoch 18/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7516 - acc: 0.5000\n",
      "Epoch 19/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7413 - acc: 0.5000\n",
      "Epoch 20/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7315 - acc: 0.4500\n",
      "Epoch 21/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.7223 - acc: 0.4500\n",
      "Epoch 22/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.7138 - acc: 0.4500\n",
      "Epoch 23/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7060 - acc: 0.4500\n",
      "Epoch 24/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6988 - acc: 0.6000\n",
      "Epoch 25/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6921 - acc: 0.5500\n",
      "Epoch 26/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6859 - acc: 0.5500\n",
      "Epoch 27/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6802 - acc: 0.5500\n",
      "Epoch 28/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6749 - acc: 0.5500\n",
      "Epoch 29/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6699 - acc: 0.6000\n",
      "Epoch 30/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6650 - acc: 0.6000\n",
      "Epoch 31/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6606 - acc: 0.6500\n",
      "Epoch 32/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6564 - acc: 0.6000\n",
      "Epoch 33/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6524 - acc: 0.6000\n",
      "Epoch 34/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6486 - acc: 0.6000\n",
      "Epoch 35/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6451 - acc: 0.7000\n",
      "Epoch 36/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6419 - acc: 0.7000\n",
      "Epoch 37/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6388 - acc: 0.6500\n",
      "Epoch 38/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6358 - acc: 0.7000\n",
      "Epoch 39/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6329 - acc: 0.7000\n",
      "Epoch 40/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6300 - acc: 0.7000\n",
      "Epoch 41/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6273 - acc: 0.7500\n",
      "Epoch 42/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6245 - acc: 0.7500\n",
      "Epoch 43/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6219 - acc: 0.7500\n",
      "Epoch 44/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6193 - acc: 0.7500\n",
      "Epoch 45/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6168 - acc: 0.7500\n",
      "Epoch 46/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6144 - acc: 0.7500\n",
      "Epoch 47/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6124 - acc: 0.7500\n",
      "Epoch 48/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6104 - acc: 0.7500\n",
      "Epoch 49/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6084 - acc: 0.7500\n",
      "Epoch 50/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6064 - acc: 0.7500\n",
      "Epoch 51/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6045 - acc: 0.7500\n",
      "Epoch 52/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6027 - acc: 0.7500\n",
      "Epoch 53/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6009 - acc: 0.7500\n",
      "Epoch 54/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5993 - acc: 0.7000\n",
      "Epoch 55/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5977 - acc: 0.7000\n",
      "Epoch 56/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5962 - acc: 0.7000\n",
      "Epoch 57/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5947 - acc: 0.7000\n",
      "Epoch 58/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5934 - acc: 0.7000\n",
      "Epoch 59/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5920 - acc: 0.7000\n",
      "Epoch 60/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5907 - acc: 0.7000\n",
      "Epoch 61/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5894 - acc: 0.7000\n",
      "Epoch 62/1000\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.5881 - acc: 0.7000\n",
      "Epoch 63/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5869 - acc: 0.7000\n",
      "Epoch 64/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5857 - acc: 0.7000\n",
      "Epoch 65/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5844 - acc: 0.7000\n",
      "Epoch 66/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5832 - acc: 0.7000\n",
      "Epoch 67/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5819 - acc: 0.7000\n",
      "Epoch 68/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5807 - acc: 0.7000\n",
      "Epoch 69/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5795 - acc: 0.7000\n",
      "Epoch 70/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5783 - acc: 0.7000\n",
      "Epoch 71/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5771 - acc: 0.7000\n",
      "Epoch 72/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5759 - acc: 0.7000\n",
      "Epoch 73/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5747 - acc: 0.7000\n",
      "Epoch 74/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5735 - acc: 0.7000\n",
      "Epoch 75/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5723 - acc: 0.7000\n",
      "Epoch 76/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5711 - acc: 0.7000\n",
      "Epoch 77/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5699 - acc: 0.7000\n",
      "Epoch 78/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5688 - acc: 0.7000\n",
      "Epoch 79/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5676 - acc: 0.7000\n",
      "Epoch 80/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5664 - acc: 0.7000\n",
      "Epoch 81/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5653 - acc: 0.7000\n",
      "Epoch 82/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5641 - acc: 0.7000\n",
      "Epoch 83/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5630 - acc: 0.7000\n",
      "Epoch 84/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5618 - acc: 0.7000\n",
      "Epoch 85/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5608 - acc: 0.7000\n",
      "Epoch 86/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5597 - acc: 0.7000\n",
      "Epoch 87/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5586 - acc: 0.7000\n",
      "Epoch 88/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5575 - acc: 0.7000\n",
      "Epoch 89/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5565 - acc: 0.7000\n",
      "Epoch 90/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5554 - acc: 0.7000\n",
      "Epoch 91/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5543 - acc: 0.7000\n",
      "Epoch 92/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5530 - acc: 0.7000\n",
      "Epoch 93/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5516 - acc: 0.7000\n",
      "Epoch 94/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5502 - acc: 0.7000\n",
      "Epoch 95/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5488 - acc: 0.7000\n",
      "Epoch 96/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5477 - acc: 0.7000\n",
      "Epoch 97/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5466 - acc: 0.7000\n",
      "Epoch 98/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5454 - acc: 0.7000\n",
      "Epoch 99/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.5443 - acc: 0.7000\n",
      "Epoch 100/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5431 - acc: 0.7000\n",
      "Epoch 101/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5420 - acc: 0.7000\n",
      "Epoch 102/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5409 - acc: 0.7000\n",
      "Epoch 103/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5397 - acc: 0.7000\n",
      "Epoch 104/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5386 - acc: 0.7000\n",
      "Epoch 105/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5375 - acc: 0.7000\n",
      "Epoch 106/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5364 - acc: 0.7000\n",
      "Epoch 107/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5353 - acc: 0.7000\n",
      "Epoch 108/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5342 - acc: 0.7000\n",
      "Epoch 109/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.5332 - acc: 0.7000\n",
      "Epoch 110/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5321 - acc: 0.7000\n",
      "Epoch 111/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5311 - acc: 0.7000\n",
      "Epoch 112/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5300 - acc: 0.7000\n",
      "Epoch 113/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5289 - acc: 0.7000\n",
      "Epoch 114/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5279 - acc: 0.7000\n",
      "Epoch 115/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5268 - acc: 0.7000\n",
      "Epoch 116/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5257 - acc: 0.7000\n",
      "Epoch 117/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5247 - acc: 0.7000\n",
      "Epoch 118/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5236 - acc: 0.7000\n",
      "Epoch 119/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5226 - acc: 0.7000\n",
      "Epoch 120/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5215 - acc: 0.7000\n",
      "Epoch 121/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5204 - acc: 0.7000\n",
      "Epoch 122/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5195 - acc: 0.7000\n",
      "Epoch 123/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.5185 - acc: 0.7000\n",
      "Epoch 124/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5175 - acc: 0.7000\n",
      "Epoch 125/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5165 - acc: 0.7000\n",
      "Epoch 126/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5156 - acc: 0.7000\n",
      "Epoch 127/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5147 - acc: 0.7000\n",
      "Epoch 128/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5137 - acc: 0.7000\n",
      "Epoch 129/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5128 - acc: 0.7000\n",
      "Epoch 130/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5119 - acc: 0.7000\n",
      "Epoch 131/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5110 - acc: 0.7000\n",
      "Epoch 132/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5101 - acc: 0.7000\n",
      "Epoch 133/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5092 - acc: 0.7000\n",
      "Epoch 134/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5083 - acc: 0.7000\n",
      "Epoch 135/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5074 - acc: 0.7000\n",
      "Epoch 136/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5065 - acc: 0.7000\n",
      "Epoch 137/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5057 - acc: 0.7000\n",
      "Epoch 138/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5048 - acc: 0.7000\n",
      "Epoch 139/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5039 - acc: 0.7000\n",
      "Epoch 140/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5031 - acc: 0.7500\n",
      "Epoch 141/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5023 - acc: 0.7500\n",
      "Epoch 142/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5014 - acc: 0.7500\n",
      "Epoch 143/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5006 - acc: 0.7500\n",
      "Epoch 144/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4998 - acc: 0.7500\n",
      "Epoch 145/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4990 - acc: 0.7500\n",
      "Epoch 146/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4982 - acc: 0.7500\n",
      "Epoch 147/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.4974 - acc: 0.7500\n",
      "Epoch 148/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4967 - acc: 0.7500\n",
      "Epoch 149/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4960 - acc: 0.7500\n",
      "Epoch 150/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4953 - acc: 0.7500\n",
      "Epoch 151/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4946 - acc: 0.7500\n",
      "Epoch 152/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4939 - acc: 0.7500\n",
      "Epoch 153/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4932 - acc: 0.7500\n",
      "Epoch 154/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4925 - acc: 0.7500\n",
      "Epoch 155/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4918 - acc: 0.7500\n",
      "Epoch 156/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4911 - acc: 0.7500\n",
      "Epoch 157/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4904 - acc: 0.7500\n",
      "Epoch 158/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4897 - acc: 0.7500\n",
      "Epoch 159/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4890 - acc: 0.7500\n",
      "Epoch 160/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4884 - acc: 0.7500\n",
      "Epoch 161/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4877 - acc: 0.7500\n",
      "Epoch 162/1000\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.4871 - acc: 0.7500\n",
      "Epoch 163/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4864 - acc: 0.7500\n",
      "Epoch 164/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4858 - acc: 0.7500\n",
      "Epoch 165/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4851 - acc: 0.7500\n",
      "Epoch 166/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4845 - acc: 0.7500\n",
      "Epoch 167/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4839 - acc: 0.7500\n",
      "Epoch 168/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4832 - acc: 0.7500\n",
      "Epoch 169/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4826 - acc: 0.7500\n",
      "Epoch 170/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4820 - acc: 0.7500\n",
      "Epoch 171/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4814 - acc: 0.7500\n",
      "Epoch 172/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4807 - acc: 0.7500\n",
      "Epoch 173/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4801 - acc: 0.7500\n",
      "Epoch 174/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.4795 - acc: 0.7500\n",
      "Epoch 175/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4789 - acc: 0.7500\n",
      "Epoch 176/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4783 - acc: 0.7500\n",
      "Epoch 177/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4777 - acc: 0.7500\n",
      "Epoch 178/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4771 - acc: 0.7500\n",
      "Epoch 179/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4765 - acc: 0.7500\n",
      "Epoch 180/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4759 - acc: 0.7500\n",
      "Epoch 181/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4753 - acc: 0.7500\n",
      "Epoch 182/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4747 - acc: 0.7500\n",
      "Epoch 183/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4741 - acc: 0.7500\n",
      "Epoch 184/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4735 - acc: 0.7500\n",
      "Epoch 185/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4730 - acc: 0.7500\n",
      "Epoch 186/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4724 - acc: 0.7500\n",
      "Epoch 187/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4718 - acc: 0.7500\n",
      "Epoch 188/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4712 - acc: 0.7500\n",
      "Epoch 189/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4707 - acc: 0.7500\n",
      "Epoch 190/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4701 - acc: 0.7500\n",
      "Epoch 191/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4695 - acc: 0.7500\n",
      "Epoch 192/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4690 - acc: 0.7500\n",
      "Epoch 193/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4684 - acc: 0.7500\n",
      "Epoch 194/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4679 - acc: 0.7500\n",
      "Epoch 195/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.4673 - acc: 0.7500\n",
      "Epoch 196/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.4668 - acc: 0.7500\n",
      "Epoch 197/1000\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 0.4662 - acc: 0.7500\n",
      "Epoch 198/1000\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 0.4657 - acc: 0.7500\n",
      "Epoch 199/1000\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 0.4651 - acc: 0.7500\n",
      "Epoch 200/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4646 - acc: 0.7500\n",
      "Epoch 201/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4641 - acc: 0.7500\n",
      "Epoch 202/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4635 - acc: 0.7500\n",
      "Epoch 203/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4630 - acc: 0.7500\n",
      "Epoch 204/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4624 - acc: 0.7500\n",
      "Epoch 205/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4619 - acc: 0.7500\n",
      "Epoch 206/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4614 - acc: 0.7500\n",
      "Epoch 207/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4609 - acc: 0.7500\n",
      "Epoch 208/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4603 - acc: 0.7500\n",
      "Epoch 209/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4598 - acc: 0.7500\n",
      "Epoch 210/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4593 - acc: 0.7500\n",
      "Epoch 211/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4588 - acc: 0.7500\n",
      "Epoch 212/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4583 - acc: 0.7500\n",
      "Epoch 213/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4578 - acc: 0.7500\n",
      "Epoch 214/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4573 - acc: 0.7500\n",
      "Epoch 215/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4568 - acc: 0.7500\n",
      "Epoch 216/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4563 - acc: 0.7500\n",
      "Epoch 217/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4558 - acc: 0.7500\n",
      "Epoch 218/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4553 - acc: 0.7500\n",
      "Epoch 219/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4548 - acc: 0.7500\n",
      "Epoch 220/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4543 - acc: 0.7500\n",
      "Epoch 221/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4538 - acc: 0.7500\n",
      "Epoch 222/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4533 - acc: 0.7500\n",
      "Epoch 223/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4528 - acc: 0.7500\n",
      "Epoch 224/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4523 - acc: 0.7500\n",
      "Epoch 225/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4519 - acc: 0.7500\n",
      "Epoch 226/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4514 - acc: 0.7500\n",
      "Epoch 227/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4509 - acc: 0.7500\n",
      "Epoch 228/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4504 - acc: 0.7500\n",
      "Epoch 229/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4500 - acc: 0.7500\n",
      "Epoch 230/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4495 - acc: 0.7500\n",
      "Epoch 231/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4490 - acc: 0.7500\n",
      "Epoch 232/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4485 - acc: 0.7500\n",
      "Epoch 233/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4481 - acc: 0.7500\n",
      "Epoch 234/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4476 - acc: 0.7500\n",
      "Epoch 235/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4472 - acc: 0.7500\n",
      "Epoch 236/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4467 - acc: 0.7500\n",
      "Epoch 237/1000\n",
      "20/20 [==============================] - 0s 65us/sample - loss: 0.4462 - acc: 0.7500\n",
      "Epoch 238/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4458 - acc: 0.8000\n",
      "Epoch 239/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4453 - acc: 0.8000\n",
      "Epoch 240/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4449 - acc: 0.8000\n",
      "Epoch 241/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4444 - acc: 0.8000\n",
      "Epoch 242/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4440 - acc: 0.8000\n",
      "Epoch 243/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4435 - acc: 0.8000\n",
      "Epoch 244/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4431 - acc: 0.8000\n",
      "Epoch 245/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4426 - acc: 0.8000\n",
      "Epoch 246/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4422 - acc: 0.8000\n",
      "Epoch 247/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4418 - acc: 0.8000\n",
      "Epoch 248/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4413 - acc: 0.8000\n",
      "Epoch 249/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4409 - acc: 0.8000\n",
      "Epoch 250/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4405 - acc: 0.8000\n",
      "Epoch 251/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4400 - acc: 0.8000\n",
      "Epoch 252/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4396 - acc: 0.8000\n",
      "Epoch 253/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4392 - acc: 0.8000\n",
      "Epoch 254/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4387 - acc: 0.8000\n",
      "Epoch 255/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4383 - acc: 0.8000\n",
      "Epoch 256/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4379 - acc: 0.8000\n",
      "Epoch 257/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4374 - acc: 0.8000\n",
      "Epoch 258/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4370 - acc: 0.8000\n",
      "Epoch 259/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4366 - acc: 0.8000\n",
      "Epoch 260/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4362 - acc: 0.8000\n",
      "Epoch 261/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4358 - acc: 0.8000\n",
      "Epoch 262/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4353 - acc: 0.8000\n",
      "Epoch 263/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4349 - acc: 0.8000\n",
      "Epoch 264/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4345 - acc: 0.8000\n",
      "Epoch 265/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4341 - acc: 0.8000\n",
      "Epoch 266/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.4337 - acc: 0.8000\n",
      "Epoch 267/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4333 - acc: 0.8000\n",
      "Epoch 268/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4329 - acc: 0.8000\n",
      "Epoch 269/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4324 - acc: 0.8000\n",
      "Epoch 270/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4320 - acc: 0.8000\n",
      "Epoch 271/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4316 - acc: 0.8000\n",
      "Epoch 272/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4312 - acc: 0.8000\n",
      "Epoch 273/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4308 - acc: 0.8000\n",
      "Epoch 274/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4304 - acc: 0.8000\n",
      "Epoch 275/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4300 - acc: 0.8000\n",
      "Epoch 276/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4296 - acc: 0.8000\n",
      "Epoch 277/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4292 - acc: 0.8000\n",
      "Epoch 278/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4288 - acc: 0.8000\n",
      "Epoch 279/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4284 - acc: 0.8000\n",
      "Epoch 280/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4280 - acc: 0.8000\n",
      "Epoch 281/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4276 - acc: 0.8000\n",
      "Epoch 282/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4272 - acc: 0.8000\n",
      "Epoch 283/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4268 - acc: 0.8000\n",
      "Epoch 284/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4264 - acc: 0.8000\n",
      "Epoch 285/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4260 - acc: 0.8000\n",
      "Epoch 286/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4256 - acc: 0.8000\n",
      "Epoch 287/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4253 - acc: 0.8000\n",
      "Epoch 288/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4249 - acc: 0.8000\n",
      "Epoch 289/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4245 - acc: 0.8000\n",
      "Epoch 290/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4241 - acc: 0.8000\n",
      "Epoch 291/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4237 - acc: 0.8000\n",
      "Epoch 292/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4233 - acc: 0.8000\n",
      "Epoch 293/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4229 - acc: 0.8000\n",
      "Epoch 294/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4225 - acc: 0.8000\n",
      "Epoch 295/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4222 - acc: 0.8000\n",
      "Epoch 296/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4218 - acc: 0.8000\n",
      "Epoch 297/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4214 - acc: 0.8000\n",
      "Epoch 298/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4210 - acc: 0.8000\n",
      "Epoch 299/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4206 - acc: 0.8000\n",
      "Epoch 300/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4203 - acc: 0.8000\n",
      "Epoch 301/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4199 - acc: 0.8000\n",
      "Epoch 302/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4195 - acc: 0.8000\n",
      "Epoch 303/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4191 - acc: 0.8000\n",
      "Epoch 304/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4187 - acc: 0.8000\n",
      "Epoch 305/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4184 - acc: 0.8000\n",
      "Epoch 306/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4180 - acc: 0.8000\n",
      "Epoch 307/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4176 - acc: 0.8000\n",
      "Epoch 308/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4172 - acc: 0.8000\n",
      "Epoch 309/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4169 - acc: 0.8000\n",
      "Epoch 310/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4165 - acc: 0.8000\n",
      "Epoch 311/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4162 - acc: 0.8000\n",
      "Epoch 312/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4158 - acc: 0.8000\n",
      "Epoch 313/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4154 - acc: 0.8000\n",
      "Epoch 314/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4151 - acc: 0.8000\n",
      "Epoch 315/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4147 - acc: 0.8000\n",
      "Epoch 316/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4144 - acc: 0.8000\n",
      "Epoch 317/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4140 - acc: 0.8000\n",
      "Epoch 318/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4136 - acc: 0.8000\n",
      "Epoch 319/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4133 - acc: 0.8000\n",
      "Epoch 320/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4129 - acc: 0.8000\n",
      "Epoch 321/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.4126 - acc: 0.8000\n",
      "Epoch 322/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4122 - acc: 0.8000\n",
      "Epoch 323/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4119 - acc: 0.8000\n",
      "Epoch 324/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4115 - acc: 0.8000\n",
      "Epoch 325/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4111 - acc: 0.8000\n",
      "Epoch 326/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4108 - acc: 0.8000\n",
      "Epoch 327/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4105 - acc: 0.8000\n",
      "Epoch 328/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4101 - acc: 0.8000\n",
      "Epoch 329/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4098 - acc: 0.8000\n",
      "Epoch 330/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4094 - acc: 0.8000\n",
      "Epoch 331/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4091 - acc: 0.8000\n",
      "Epoch 332/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.4087 - acc: 0.8000\n",
      "Epoch 333/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4083 - acc: 0.8000\n",
      "Epoch 334/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.4080 - acc: 0.8000\n",
      "Epoch 335/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4077 - acc: 0.8000\n",
      "Epoch 336/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.4073 - acc: 0.8000\n",
      "Epoch 337/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4070 - acc: 0.8000\n",
      "Epoch 338/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4067 - acc: 0.8000\n",
      "Epoch 339/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4063 - acc: 0.8000\n",
      "Epoch 340/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4060 - acc: 0.8000\n",
      "Epoch 341/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4057 - acc: 0.8000\n",
      "Epoch 342/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4053 - acc: 0.8000\n",
      "Epoch 343/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4050 - acc: 0.8000\n",
      "Epoch 344/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4047 - acc: 0.8000\n",
      "Epoch 345/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4043 - acc: 0.8000\n",
      "Epoch 346/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4040 - acc: 0.8000\n",
      "Epoch 347/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.4037 - acc: 0.8000\n",
      "Epoch 348/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4033 - acc: 0.8000\n",
      "Epoch 349/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4030 - acc: 0.8000\n",
      "Epoch 350/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4027 - acc: 0.8000\n",
      "Epoch 351/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4023 - acc: 0.8000\n",
      "Epoch 352/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4020 - acc: 0.8000\n",
      "Epoch 353/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4017 - acc: 0.8000\n",
      "Epoch 354/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4014 - acc: 0.8000\n",
      "Epoch 355/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4010 - acc: 0.8000\n",
      "Epoch 356/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4007 - acc: 0.8000\n",
      "Epoch 357/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4004 - acc: 0.8000\n",
      "Epoch 358/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.4000 - acc: 0.8000\n",
      "Epoch 359/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3997 - acc: 0.8000\n",
      "Epoch 360/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3993 - acc: 0.8000\n",
      "Epoch 361/1000\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.3990 - acc: 0.8000\n",
      "Epoch 362/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3987 - acc: 0.8000\n",
      "Epoch 363/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3983 - acc: 0.8000\n",
      "Epoch 364/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3979 - acc: 0.8000\n",
      "Epoch 365/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3975 - acc: 0.8000\n",
      "Epoch 366/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3972 - acc: 0.8000\n",
      "Epoch 367/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3967 - acc: 0.8000\n",
      "Epoch 368/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3963 - acc: 0.8000\n",
      "Epoch 369/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3959 - acc: 0.8000\n",
      "Epoch 370/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3956 - acc: 0.8000\n",
      "Epoch 371/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3952 - acc: 0.8000\n",
      "Epoch 372/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3948 - acc: 0.8000\n",
      "Epoch 373/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3945 - acc: 0.8000\n",
      "Epoch 374/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3941 - acc: 0.8000\n",
      "Epoch 375/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3938 - acc: 0.8000\n",
      "Epoch 376/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3934 - acc: 0.8000\n",
      "Epoch 377/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3930 - acc: 0.8000\n",
      "Epoch 378/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3927 - acc: 0.8000\n",
      "Epoch 379/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3923 - acc: 0.8000\n",
      "Epoch 380/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3919 - acc: 0.8000\n",
      "Epoch 381/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3916 - acc: 0.8000\n",
      "Epoch 382/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3912 - acc: 0.8000\n",
      "Epoch 383/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3909 - acc: 0.8000\n",
      "Epoch 384/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3905 - acc: 0.8000\n",
      "Epoch 385/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3901 - acc: 0.8000\n",
      "Epoch 386/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3898 - acc: 0.8000\n",
      "Epoch 387/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3894 - acc: 0.8000\n",
      "Epoch 388/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3891 - acc: 0.8000\n",
      "Epoch 389/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3887 - acc: 0.8000\n",
      "Epoch 390/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3883 - acc: 0.8000\n",
      "Epoch 391/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3880 - acc: 0.8000\n",
      "Epoch 392/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3876 - acc: 0.8000\n",
      "Epoch 393/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3873 - acc: 0.8000\n",
      "Epoch 394/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3869 - acc: 0.8000\n",
      "Epoch 395/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3866 - acc: 0.8000\n",
      "Epoch 396/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3862 - acc: 0.8000\n",
      "Epoch 397/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3859 - acc: 0.8000\n",
      "Epoch 398/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3855 - acc: 0.8000\n",
      "Epoch 399/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3852 - acc: 0.8000\n",
      "Epoch 400/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3848 - acc: 0.8000\n",
      "Epoch 401/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3845 - acc: 0.8000\n",
      "Epoch 402/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3841 - acc: 0.8000\n",
      "Epoch 403/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3838 - acc: 0.8000\n",
      "Epoch 404/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3834 - acc: 0.8000\n",
      "Epoch 405/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3830 - acc: 0.8000\n",
      "Epoch 406/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3827 - acc: 0.8000\n",
      "Epoch 407/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3823 - acc: 0.8000\n",
      "Epoch 408/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3820 - acc: 0.8000\n",
      "Epoch 409/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3816 - acc: 0.8000\n",
      "Epoch 410/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3813 - acc: 0.8000\n",
      "Epoch 411/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.3809 - acc: 0.8000\n",
      "Epoch 412/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3806 - acc: 0.8000\n",
      "Epoch 413/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3802 - acc: 0.8000\n",
      "Epoch 414/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3799 - acc: 0.8000\n",
      "Epoch 415/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3796 - acc: 0.8000\n",
      "Epoch 416/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.3792 - acc: 0.8000\n",
      "Epoch 417/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3789 - acc: 0.8000\n",
      "Epoch 418/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3785 - acc: 0.8000\n",
      "Epoch 419/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3782 - acc: 0.8000\n",
      "Epoch 420/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3778 - acc: 0.8000\n",
      "Epoch 421/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3775 - acc: 0.8000\n",
      "Epoch 422/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3772 - acc: 0.8000\n",
      "Epoch 423/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3769 - acc: 0.8000\n",
      "Epoch 424/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3766 - acc: 0.8000\n",
      "Epoch 425/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3762 - acc: 0.8000\n",
      "Epoch 426/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.3759 - acc: 0.8000\n",
      "Epoch 427/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3756 - acc: 0.8000\n",
      "Epoch 428/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3753 - acc: 0.8000\n",
      "Epoch 429/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3750 - acc: 0.8000\n",
      "Epoch 430/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3746 - acc: 0.8000\n",
      "Epoch 431/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3743 - acc: 0.8000\n",
      "Epoch 432/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3740 - acc: 0.8000\n",
      "Epoch 433/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3737 - acc: 0.8000\n",
      "Epoch 434/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3734 - acc: 0.8000\n",
      "Epoch 435/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3731 - acc: 0.8000\n",
      "Epoch 436/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3727 - acc: 0.8000\n",
      "Epoch 437/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3724 - acc: 0.8000\n",
      "Epoch 438/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3721 - acc: 0.8000\n",
      "Epoch 439/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3718 - acc: 0.8000\n",
      "Epoch 440/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3715 - acc: 0.8000\n",
      "Epoch 441/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3711 - acc: 0.8000\n",
      "Epoch 442/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3709 - acc: 0.8000\n",
      "Epoch 443/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3705 - acc: 0.8000\n",
      "Epoch 444/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3702 - acc: 0.8000\n",
      "Epoch 445/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3699 - acc: 0.8000\n",
      "Epoch 446/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3696 - acc: 0.8000\n",
      "Epoch 447/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3693 - acc: 0.8000\n",
      "Epoch 448/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.3690 - acc: 0.8000\n",
      "Epoch 449/1000\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 0.3686 - acc: 0.8000\n",
      "Epoch 450/1000\n",
      "20/20 [==============================] - 0s 110us/sample - loss: 0.3683 - acc: 0.8000\n",
      "Epoch 451/1000\n",
      "20/20 [==============================] - 0s 25us/sample - loss: 0.3681 - acc: 0.8000\n",
      "Epoch 452/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3677 - acc: 0.8000\n",
      "Epoch 453/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3674 - acc: 0.8000\n",
      "Epoch 454/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3671 - acc: 0.8000\n",
      "Epoch 455/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3668 - acc: 0.8000\n",
      "Epoch 456/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3665 - acc: 0.8000\n",
      "Epoch 457/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3662 - acc: 0.8000\n",
      "Epoch 458/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3659 - acc: 0.8000\n",
      "Epoch 459/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3655 - acc: 0.8000\n",
      "Epoch 460/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3652 - acc: 0.8000\n",
      "Epoch 461/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3649 - acc: 0.8000\n",
      "Epoch 462/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3646 - acc: 0.8000\n",
      "Epoch 463/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3643 - acc: 0.8000\n",
      "Epoch 464/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3641 - acc: 0.8000\n",
      "Epoch 465/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3637 - acc: 0.8000\n",
      "Epoch 466/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3635 - acc: 0.8000\n",
      "Epoch 467/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3632 - acc: 0.8000\n",
      "Epoch 468/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3629 - acc: 0.8000\n",
      "Epoch 469/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3626 - acc: 0.8000\n",
      "Epoch 470/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3623 - acc: 0.8000\n",
      "Epoch 471/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3619 - acc: 0.8000\n",
      "Epoch 472/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3616 - acc: 0.8000\n",
      "Epoch 473/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3614 - acc: 0.8000\n",
      "Epoch 474/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3610 - acc: 0.8000\n",
      "Epoch 475/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3608 - acc: 0.8000\n",
      "Epoch 476/1000\n",
      "20/20 [==============================] - 0s 110us/sample - loss: 0.3605 - acc: 0.8000\n",
      "Epoch 477/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3602 - acc: 0.8000\n",
      "Epoch 478/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3599 - acc: 0.8000\n",
      "Epoch 479/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3596 - acc: 0.8000\n",
      "Epoch 480/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3593 - acc: 0.8000\n",
      "Epoch 481/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3590 - acc: 0.8000\n",
      "Epoch 482/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3588 - acc: 0.8000\n",
      "Epoch 483/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3585 - acc: 0.8000\n",
      "Epoch 484/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3581 - acc: 0.8000\n",
      "Epoch 485/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3578 - acc: 0.8000\n",
      "Epoch 486/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3576 - acc: 0.8000\n",
      "Epoch 487/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3574 - acc: 0.8000\n",
      "Epoch 488/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3569 - acc: 0.8000\n",
      "Epoch 489/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3567 - acc: 0.8000\n",
      "Epoch 490/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3565 - acc: 0.8000\n",
      "Epoch 491/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3562 - acc: 0.8000\n",
      "Epoch 492/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3559 - acc: 0.8000\n",
      "Epoch 493/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3556 - acc: 0.8000\n",
      "Epoch 494/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3554 - acc: 0.8000\n",
      "Epoch 495/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3551 - acc: 0.8000\n",
      "Epoch 496/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3547 - acc: 0.8000\n",
      "Epoch 497/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3544 - acc: 0.8000\n",
      "Epoch 498/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3541 - acc: 0.8000\n",
      "Epoch 499/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3538 - acc: 0.8000\n",
      "Epoch 500/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3535 - acc: 0.8000\n",
      "Epoch 501/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3533 - acc: 0.8000\n",
      "Epoch 502/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3531 - acc: 0.8000\n",
      "Epoch 503/1000\n",
      "20/20 [==============================] - 0s 94us/sample - loss: 0.3528 - acc: 0.8000\n",
      "Epoch 504/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.3524 - acc: 0.8000\n",
      "Epoch 505/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.3521 - acc: 0.8000\n",
      "Epoch 506/1000\n",
      "20/20 [==============================] - 0s 77us/sample - loss: 0.3519 - acc: 0.8000\n",
      "Epoch 507/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.3516 - acc: 0.8000\n",
      "Epoch 508/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.3514 - acc: 0.8000\n",
      "Epoch 509/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.3511 - acc: 0.8000\n",
      "Epoch 510/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.3508 - acc: 0.8000\n",
      "Epoch 511/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.3505 - acc: 0.8000\n",
      "Epoch 512/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.3502 - acc: 0.8000\n",
      "Epoch 513/1000\n",
      "20/20 [==============================] - 0s 77us/sample - loss: 0.3499 - acc: 0.8000\n",
      "Epoch 514/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.3496 - acc: 0.8000\n",
      "Epoch 515/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.3493 - acc: 0.8000\n",
      "Epoch 516/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.3490 - acc: 0.8000\n",
      "Epoch 517/1000\n",
      "20/20 [==============================] - 0s 53us/sample - loss: 0.3488 - acc: 0.8000\n",
      "Epoch 518/1000\n",
      "20/20 [==============================] - 0s 26us/sample - loss: 0.3486 - acc: 0.8000\n",
      "Epoch 519/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3483 - acc: 0.8000\n",
      "Epoch 520/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3479 - acc: 0.8000\n",
      "Epoch 521/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3476 - acc: 0.8000\n",
      "Epoch 522/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3474 - acc: 0.8000\n",
      "Epoch 523/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3470 - acc: 0.8000\n",
      "Epoch 524/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3469 - acc: 0.8000\n",
      "Epoch 525/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3467 - acc: 0.8000\n",
      "Epoch 526/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3463 - acc: 0.8000\n",
      "Epoch 527/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3459 - acc: 0.8000\n",
      "Epoch 528/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3457 - acc: 0.8000\n",
      "Epoch 529/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3455 - acc: 0.8000\n",
      "Epoch 530/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3452 - acc: 0.8000\n",
      "Epoch 531/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3450 - acc: 0.8000\n",
      "Epoch 532/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3448 - acc: 0.8000\n",
      "Epoch 533/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3445 - acc: 0.8000\n",
      "Epoch 534/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3441 - acc: 0.8000\n",
      "Epoch 535/1000\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.3437 - acc: 0.8000\n",
      "Epoch 536/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3434 - acc: 0.8000\n",
      "Epoch 537/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3433 - acc: 0.8000\n",
      "Epoch 538/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3431 - acc: 0.8000\n",
      "Epoch 539/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3428 - acc: 0.8000\n",
      "Epoch 540/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3425 - acc: 0.8000\n",
      "Epoch 541/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3422 - acc: 0.8000\n",
      "Epoch 542/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3419 - acc: 0.8000\n",
      "Epoch 543/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3416 - acc: 0.8000\n",
      "Epoch 544/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3413 - acc: 0.8000\n",
      "Epoch 545/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3409 - acc: 0.8000\n",
      "Epoch 546/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3407 - acc: 0.8000\n",
      "Epoch 547/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3405 - acc: 0.8000\n",
      "Epoch 548/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3402 - acc: 0.8000\n",
      "Epoch 549/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3400 - acc: 0.8000\n",
      "Epoch 550/1000\n",
      "20/20 [==============================] - 0s 27us/sample - loss: 0.3397 - acc: 0.8000\n",
      "Epoch 551/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3394 - acc: 0.8000\n",
      "Epoch 552/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3391 - acc: 0.8000\n",
      "Epoch 553/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3388 - acc: 0.8000\n",
      "Epoch 554/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3386 - acc: 0.8000\n",
      "Epoch 555/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3382 - acc: 0.8000\n",
      "Epoch 556/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3380 - acc: 0.8000\n",
      "Epoch 557/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3377 - acc: 0.8000\n",
      "Epoch 558/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3374 - acc: 0.8000\n",
      "Epoch 559/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3372 - acc: 0.8000\n",
      "Epoch 560/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3369 - acc: 0.8000\n",
      "Epoch 561/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3366 - acc: 0.8000\n",
      "Epoch 562/1000\n",
      "20/20 [==============================] - 0s 200us/sample - loss: 0.3363 - acc: 0.8000\n",
      "Epoch 563/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3361 - acc: 0.8000\n",
      "Epoch 564/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3358 - acc: 0.8000\n",
      "Epoch 565/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3355 - acc: 0.8000\n",
      "Epoch 566/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3352 - acc: 0.8000\n",
      "Epoch 567/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3349 - acc: 0.8000\n",
      "Epoch 568/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3346 - acc: 0.8000\n",
      "Epoch 569/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3344 - acc: 0.8000\n",
      "Epoch 570/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3341 - acc: 0.8000\n",
      "Epoch 571/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3338 - acc: 0.8000\n",
      "Epoch 572/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3336 - acc: 0.8000\n",
      "Epoch 573/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3333 - acc: 0.8000\n",
      "Epoch 574/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3330 - acc: 0.8000\n",
      "Epoch 575/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3327 - acc: 0.8000\n",
      "Epoch 576/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3325 - acc: 0.8000\n",
      "Epoch 577/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3322 - acc: 0.8000\n",
      "Epoch 578/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3320 - acc: 0.8000\n",
      "Epoch 579/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3317 - acc: 0.8000\n",
      "Epoch 580/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3314 - acc: 0.8000\n",
      "Epoch 581/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3313 - acc: 0.8000\n",
      "Epoch 582/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3310 - acc: 0.8000\n",
      "Epoch 583/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3306 - acc: 0.8000\n",
      "Epoch 584/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3305 - acc: 0.8000\n",
      "Epoch 585/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3304 - acc: 0.8000\n",
      "Epoch 586/1000\n",
      "20/20 [==============================] - 0s 29us/sample - loss: 0.3301 - acc: 0.8000\n",
      "Epoch 587/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3297 - acc: 0.8000\n",
      "Epoch 588/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3293 - acc: 0.8000\n",
      "Epoch 589/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3291 - acc: 0.8000\n",
      "Epoch 590/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3290 - acc: 0.8000\n",
      "Epoch 591/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3286 - acc: 0.8000\n",
      "Epoch 592/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3282 - acc: 0.8000\n",
      "Epoch 593/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3280 - acc: 0.8000\n",
      "Epoch 594/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3278 - acc: 0.8000\n",
      "Epoch 595/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3275 - acc: 0.8000\n",
      "Epoch 596/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3271 - acc: 0.8000\n",
      "Epoch 597/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3269 - acc: 0.8000\n",
      "Epoch 598/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3266 - acc: 0.8000\n",
      "Epoch 599/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3263 - acc: 0.8000\n",
      "Epoch 600/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3261 - acc: 0.8000\n",
      "Epoch 601/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3260 - acc: 0.8000\n",
      "Epoch 602/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3257 - acc: 0.8000\n",
      "Epoch 603/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3253 - acc: 0.8000\n",
      "Epoch 604/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3250 - acc: 0.8000\n",
      "Epoch 605/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3247 - acc: 0.8000\n",
      "Epoch 606/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3244 - acc: 0.8000\n",
      "Epoch 607/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3242 - acc: 0.8000\n",
      "Epoch 608/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3240 - acc: 0.8000\n",
      "Epoch 609/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3237 - acc: 0.8000\n",
      "Epoch 610/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3234 - acc: 0.8000\n",
      "Epoch 611/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3232 - acc: 0.8000\n",
      "Epoch 612/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3229 - acc: 0.8000\n",
      "Epoch 613/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3225 - acc: 0.8000\n",
      "Epoch 614/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.3223 - acc: 0.8000\n",
      "Epoch 615/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3221 - acc: 0.8000\n",
      "Epoch 616/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3219 - acc: 0.8000\n",
      "Epoch 617/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3215 - acc: 0.8000\n",
      "Epoch 618/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3212 - acc: 0.8000\n",
      "Epoch 619/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3210 - acc: 0.8000\n",
      "Epoch 620/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3207 - acc: 0.8000\n",
      "Epoch 621/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3204 - acc: 0.8000\n",
      "Epoch 622/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3202 - acc: 0.8000\n",
      "Epoch 623/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3200 - acc: 0.8000\n",
      "Epoch 624/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3197 - acc: 0.8000\n",
      "Epoch 625/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3193 - acc: 0.8000\n",
      "Epoch 626/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3191 - acc: 0.8000\n",
      "Epoch 627/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3188 - acc: 0.8000\n",
      "Epoch 628/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3185 - acc: 0.8000\n",
      "Epoch 629/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3182 - acc: 0.8000\n",
      "Epoch 630/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3179 - acc: 0.8000\n",
      "Epoch 631/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3177 - acc: 0.8000\n",
      "Epoch 632/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3173 - acc: 0.8000\n",
      "Epoch 633/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3171 - acc: 0.8000\n",
      "Epoch 634/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3168 - acc: 0.8000\n",
      "Epoch 635/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3166 - acc: 0.8000\n",
      "Epoch 636/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3163 - acc: 0.8000\n",
      "Epoch 637/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3160 - acc: 0.8000\n",
      "Epoch 638/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3158 - acc: 0.8000\n",
      "Epoch 639/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3155 - acc: 0.8000\n",
      "Epoch 640/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3153 - acc: 0.8000\n",
      "Epoch 641/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3150 - acc: 0.8000\n",
      "Epoch 642/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3148 - acc: 0.8000\n",
      "Epoch 643/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3146 - acc: 0.8000\n",
      "Epoch 644/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3142 - acc: 0.8000\n",
      "Epoch 645/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.3139 - acc: 0.8000\n",
      "Epoch 646/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3137 - acc: 0.8000\n",
      "Epoch 647/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3134 - acc: 0.8000\n",
      "Epoch 648/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3130 - acc: 0.8000\n",
      "Epoch 649/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3128 - acc: 0.8000\n",
      "Epoch 650/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3125 - acc: 0.8000\n",
      "Epoch 651/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3122 - acc: 0.8000\n",
      "Epoch 652/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3120 - acc: 0.8000\n",
      "Epoch 653/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3117 - acc: 0.8000\n",
      "Epoch 654/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3114 - acc: 0.8000\n",
      "Epoch 655/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3111 - acc: 0.8000\n",
      "Epoch 656/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3108 - acc: 0.8000\n",
      "Epoch 657/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3107 - acc: 0.8000\n",
      "Epoch 658/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3104 - acc: 0.8000\n",
      "Epoch 659/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3101 - acc: 0.8000\n",
      "Epoch 660/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3098 - acc: 0.8000\n",
      "Epoch 661/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3096 - acc: 0.8000\n",
      "Epoch 662/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3093 - acc: 0.8000\n",
      "Epoch 663/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3090 - acc: 0.8000\n",
      "Epoch 664/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3088 - acc: 0.8000\n",
      "Epoch 665/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3086 - acc: 0.8000\n",
      "Epoch 666/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3082 - acc: 0.8000\n",
      "Epoch 667/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3080 - acc: 0.8000\n",
      "Epoch 668/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3078 - acc: 0.8000\n",
      "Epoch 669/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3074 - acc: 0.8000\n",
      "Epoch 670/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3072 - acc: 0.8000\n",
      "Epoch 671/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3069 - acc: 0.8000\n",
      "Epoch 672/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3067 - acc: 0.8000\n",
      "Epoch 673/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3064 - acc: 0.8000\n",
      "Epoch 674/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3061 - acc: 0.8000\n",
      "Epoch 675/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3060 - acc: 0.8000\n",
      "Epoch 676/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3057 - acc: 0.8000\n",
      "Epoch 677/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3054 - acc: 0.8000\n",
      "Epoch 678/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3051 - acc: 0.8000\n",
      "Epoch 679/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3050 - acc: 0.8000\n",
      "Epoch 680/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3047 - acc: 0.8000\n",
      "Epoch 681/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3043 - acc: 0.8000\n",
      "Epoch 682/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3042 - acc: 0.8000\n",
      "Epoch 683/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3040 - acc: 0.8000\n",
      "Epoch 684/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3037 - acc: 0.8000\n",
      "Epoch 685/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3032 - acc: 0.8000\n",
      "Epoch 686/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3030 - acc: 0.8000\n",
      "Epoch 687/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3028 - acc: 0.8000\n",
      "Epoch 688/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3024 - acc: 0.8000\n",
      "Epoch 689/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3022 - acc: 0.8000\n",
      "Epoch 690/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3019 - acc: 0.8000\n",
      "Epoch 691/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3016 - acc: 0.8000\n",
      "Epoch 692/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3014 - acc: 0.8000\n",
      "Epoch 693/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3012 - acc: 0.8000\n",
      "Epoch 694/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3008 - acc: 0.8000\n",
      "Epoch 695/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3006 - acc: 0.8000\n",
      "Epoch 696/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3003 - acc: 0.8000\n",
      "Epoch 697/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.3000 - acc: 0.8000\n",
      "Epoch 698/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2998 - acc: 0.8000\n",
      "Epoch 699/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2995 - acc: 0.8000\n",
      "Epoch 700/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2992 - acc: 0.8000\n",
      "Epoch 701/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2990 - acc: 0.8000\n",
      "Epoch 702/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2987 - acc: 0.8000\n",
      "Epoch 703/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2985 - acc: 0.8000\n",
      "Epoch 704/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2982 - acc: 0.8000\n",
      "Epoch 705/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2979 - acc: 0.8000\n",
      "Epoch 706/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2977 - acc: 0.8000\n",
      "Epoch 707/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2974 - acc: 0.8000\n",
      "Epoch 708/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2972 - acc: 0.8000\n",
      "Epoch 709/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2969 - acc: 0.8000\n",
      "Epoch 710/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2966 - acc: 0.8000\n",
      "Epoch 711/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2963 - acc: 0.8000\n",
      "Epoch 712/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2961 - acc: 0.8000\n",
      "Epoch 713/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2958 - acc: 0.8000\n",
      "Epoch 714/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2956 - acc: 0.8000\n",
      "Epoch 715/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2953 - acc: 0.8000\n",
      "Epoch 716/1000\n",
      "20/20 [==============================] - 0s 203us/sample - loss: 0.2951 - acc: 0.8000\n",
      "Epoch 717/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2949 - acc: 0.8500\n",
      "Epoch 718/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2945 - acc: 0.8500\n",
      "Epoch 719/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2943 - acc: 0.8000\n",
      "Epoch 720/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2941 - acc: 0.8000\n",
      "Epoch 721/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2938 - acc: 0.8000\n",
      "Epoch 722/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2935 - acc: 0.8500\n",
      "Epoch 723/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2933 - acc: 0.8500\n",
      "Epoch 724/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2930 - acc: 0.8500\n",
      "Epoch 725/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2927 - acc: 0.8500\n",
      "Epoch 726/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2925 - acc: 0.8500\n",
      "Epoch 727/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2921 - acc: 0.8500\n",
      "Epoch 728/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2919 - acc: 0.8500\n",
      "Epoch 729/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2916 - acc: 0.8500\n",
      "Epoch 730/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2914 - acc: 0.8500\n",
      "Epoch 731/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2912 - acc: 0.8500\n",
      "Epoch 732/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.2909 - acc: 0.8500\n",
      "Epoch 733/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2906 - acc: 0.8500\n",
      "Epoch 734/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2904 - acc: 0.8500\n",
      "Epoch 735/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2901 - acc: 0.8500\n",
      "Epoch 736/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2897 - acc: 0.8500\n",
      "Epoch 737/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2895 - acc: 0.8500\n",
      "Epoch 738/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2893 - acc: 0.8500\n",
      "Epoch 739/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2890 - acc: 0.8500\n",
      "Epoch 740/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2887 - acc: 0.8500\n",
      "Epoch 741/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2884 - acc: 0.8500\n",
      "Epoch 742/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2882 - acc: 0.8500\n",
      "Epoch 743/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2880 - acc: 0.8500\n",
      "Epoch 744/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2876 - acc: 0.8500\n",
      "Epoch 745/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2874 - acc: 0.8500\n",
      "Epoch 746/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2871 - acc: 0.8500\n",
      "Epoch 747/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2869 - acc: 0.8500\n",
      "Epoch 748/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2867 - acc: 0.8500\n",
      "Epoch 749/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2863 - acc: 0.8500\n",
      "Epoch 750/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2861 - acc: 0.8500\n",
      "Epoch 751/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2859 - acc: 0.8500\n",
      "Epoch 752/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2856 - acc: 0.8500\n",
      "Epoch 753/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2853 - acc: 0.8500\n",
      "Epoch 754/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2850 - acc: 0.8500\n",
      "Epoch 755/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2847 - acc: 0.8500\n",
      "Epoch 756/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2845 - acc: 0.8500\n",
      "Epoch 757/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2843 - acc: 0.8500\n",
      "Epoch 758/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2840 - acc: 0.8500\n",
      "Epoch 759/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2837 - acc: 0.8500\n",
      "Epoch 760/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2834 - acc: 0.8500\n",
      "Epoch 761/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2831 - acc: 0.8500\n",
      "Epoch 762/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2829 - acc: 0.8500\n",
      "Epoch 763/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2827 - acc: 0.8500\n",
      "Epoch 764/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2824 - acc: 0.8500\n",
      "Epoch 765/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2821 - acc: 0.8500\n",
      "Epoch 766/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2818 - acc: 0.8500\n",
      "Epoch 767/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2816 - acc: 0.8500\n",
      "Epoch 768/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2813 - acc: 0.8500\n",
      "Epoch 769/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2811 - acc: 0.8500\n",
      "Epoch 770/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2808 - acc: 0.8500\n",
      "Epoch 771/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2805 - acc: 0.8500\n",
      "Epoch 772/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2802 - acc: 0.8500\n",
      "Epoch 773/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2800 - acc: 0.8500\n",
      "Epoch 774/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2797 - acc: 0.8500\n",
      "Epoch 775/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2795 - acc: 0.8500\n",
      "Epoch 776/1000\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.2793 - acc: 0.8500\n",
      "Epoch 777/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2790 - acc: 0.8500\n",
      "Epoch 778/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2787 - acc: 0.8500\n",
      "Epoch 779/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2784 - acc: 0.8500\n",
      "Epoch 780/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.2782 - acc: 0.8500\n",
      "Epoch 781/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2778 - acc: 0.8500\n",
      "Epoch 782/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2776 - acc: 0.8500\n",
      "Epoch 783/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2773 - acc: 0.8500\n",
      "Epoch 784/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2770 - acc: 0.8500\n",
      "Epoch 785/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2768 - acc: 0.8500\n",
      "Epoch 786/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2765 - acc: 0.8500\n",
      "Epoch 787/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2763 - acc: 0.8500\n",
      "Epoch 788/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2760 - acc: 0.8500\n",
      "Epoch 789/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2757 - acc: 0.8500\n",
      "Epoch 790/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2754 - acc: 0.8500\n",
      "Epoch 791/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2752 - acc: 0.8500\n",
      "Epoch 792/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2749 - acc: 0.8500\n",
      "Epoch 793/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2747 - acc: 0.8500\n",
      "Epoch 794/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2744 - acc: 0.8500\n",
      "Epoch 795/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2741 - acc: 0.8500\n",
      "Epoch 796/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2738 - acc: 0.8500\n",
      "Epoch 797/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2736 - acc: 0.8500\n",
      "Epoch 798/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2733 - acc: 0.8500\n",
      "Epoch 799/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2730 - acc: 0.8500\n",
      "Epoch 800/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2728 - acc: 0.8500\n",
      "Epoch 801/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2725 - acc: 0.8500\n",
      "Epoch 802/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2723 - acc: 0.8500\n",
      "Epoch 803/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2720 - acc: 0.8500\n",
      "Epoch 804/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2717 - acc: 0.8500\n",
      "Epoch 805/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2714 - acc: 0.8500\n",
      "Epoch 806/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2712 - acc: 0.8500\n",
      "Epoch 807/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2710 - acc: 0.8500\n",
      "Epoch 808/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2707 - acc: 0.8500\n",
      "Epoch 809/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2704 - acc: 0.8500\n",
      "Epoch 810/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2701 - acc: 0.8500\n",
      "Epoch 811/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2698 - acc: 0.8500\n",
      "Epoch 812/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2695 - acc: 0.8500\n",
      "Epoch 813/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2693 - acc: 0.8500\n",
      "Epoch 814/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.2690 - acc: 0.8500\n",
      "Epoch 815/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2688 - acc: 0.8500\n",
      "Epoch 816/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2685 - acc: 0.8500\n",
      "Epoch 817/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2682 - acc: 0.8500\n",
      "Epoch 818/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2679 - acc: 0.8500\n",
      "Epoch 819/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2677 - acc: 0.8500\n",
      "Epoch 820/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2674 - acc: 0.8500\n",
      "Epoch 821/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2672 - acc: 0.8500\n",
      "Epoch 822/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2669 - acc: 0.8500\n",
      "Epoch 823/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2666 - acc: 0.8500\n",
      "Epoch 824/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2663 - acc: 0.8500\n",
      "Epoch 825/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2661 - acc: 0.8500\n",
      "Epoch 826/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2658 - acc: 0.8500\n",
      "Epoch 827/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2656 - acc: 0.8500\n",
      "Epoch 828/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2653 - acc: 0.8500\n",
      "Epoch 829/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2650 - acc: 0.8500\n",
      "Epoch 830/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2647 - acc: 0.8500\n",
      "Epoch 831/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2645 - acc: 0.8500\n",
      "Epoch 832/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2642 - acc: 0.8500\n",
      "Epoch 833/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2639 - acc: 0.8500\n",
      "Epoch 834/1000\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.2636 - acc: 0.8500\n",
      "Epoch 835/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2634 - acc: 0.8500\n",
      "Epoch 836/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2631 - acc: 0.8500\n",
      "Epoch 837/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2628 - acc: 0.8500\n",
      "Epoch 838/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2626 - acc: 0.8500\n",
      "Epoch 839/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2623 - acc: 0.8500\n",
      "Epoch 840/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2621 - acc: 0.8500\n",
      "Epoch 841/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2618 - acc: 0.8500\n",
      "Epoch 842/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2615 - acc: 0.8500\n",
      "Epoch 843/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2613 - acc: 0.8500\n",
      "Epoch 844/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2610 - acc: 0.8500\n",
      "Epoch 845/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2607 - acc: 0.8500\n",
      "Epoch 846/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2604 - acc: 0.8500\n",
      "Epoch 847/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2602 - acc: 0.8500\n",
      "Epoch 848/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2598 - acc: 0.8500\n",
      "Epoch 849/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2596 - acc: 0.8500\n",
      "Epoch 850/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2594 - acc: 0.8500\n",
      "Epoch 851/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2590 - acc: 0.8500\n",
      "Epoch 852/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2588 - acc: 0.8500\n",
      "Epoch 853/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2586 - acc: 0.8500\n",
      "Epoch 854/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2582 - acc: 0.8500\n",
      "Epoch 855/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2580 - acc: 0.8500\n",
      "Epoch 856/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2578 - acc: 0.8500\n",
      "Epoch 857/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2575 - acc: 0.8500\n",
      "Epoch 858/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2571 - acc: 0.8500\n",
      "Epoch 859/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2570 - acc: 0.8500\n",
      "Epoch 860/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2568 - acc: 0.8500\n",
      "Epoch 861/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2564 - acc: 0.8500\n",
      "Epoch 862/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2561 - acc: 0.8500\n",
      "Epoch 863/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2559 - acc: 0.8500\n",
      "Epoch 864/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2556 - acc: 0.8500\n",
      "Epoch 865/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2552 - acc: 0.8500\n",
      "Epoch 866/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2550 - acc: 0.8500\n",
      "Epoch 867/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2547 - acc: 0.8500\n",
      "Epoch 868/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2545 - acc: 0.8500\n",
      "Epoch 869/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2543 - acc: 0.8500\n",
      "Epoch 870/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2540 - acc: 0.8500\n",
      "Epoch 871/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2536 - acc: 0.8500\n",
      "Epoch 872/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2534 - acc: 0.8500\n",
      "Epoch 873/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2532 - acc: 0.8500\n",
      "Epoch 874/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2528 - acc: 0.8500\n",
      "Epoch 875/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2526 - acc: 0.8500\n",
      "Epoch 876/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2524 - acc: 0.8500\n",
      "Epoch 877/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2521 - acc: 0.8500\n",
      "Epoch 878/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2518 - acc: 0.8500\n",
      "Epoch 879/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2514 - acc: 0.8500\n",
      "Epoch 880/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2512 - acc: 0.8500\n",
      "Epoch 881/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2510 - acc: 0.8500\n",
      "Epoch 882/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2506 - acc: 0.8500\n",
      "Epoch 883/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2504 - acc: 0.8500\n",
      "Epoch 884/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2501 - acc: 0.8500\n",
      "Epoch 885/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2498 - acc: 0.8500\n",
      "Epoch 886/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2495 - acc: 0.8500\n",
      "Epoch 887/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2492 - acc: 0.8500\n",
      "Epoch 888/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2490 - acc: 0.8500\n",
      "Epoch 889/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2487 - acc: 0.8500\n",
      "Epoch 890/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2484 - acc: 0.8500\n",
      "Epoch 891/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2481 - acc: 0.8500\n",
      "Epoch 892/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2479 - acc: 0.8500\n",
      "Epoch 893/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2476 - acc: 0.8500\n",
      "Epoch 894/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2474 - acc: 0.8500\n",
      "Epoch 895/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2471 - acc: 0.8500\n",
      "Epoch 896/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2468 - acc: 0.8500\n",
      "Epoch 897/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2465 - acc: 0.8500\n",
      "Epoch 898/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2462 - acc: 0.8500\n",
      "Epoch 899/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2460 - acc: 0.8500\n",
      "Epoch 900/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2457 - acc: 0.8500\n",
      "Epoch 901/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2454 - acc: 0.8500\n",
      "Epoch 902/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2451 - acc: 0.8500\n",
      "Epoch 903/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2449 - acc: 0.8500\n",
      "Epoch 904/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2446 - acc: 0.8500\n",
      "Epoch 905/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2443 - acc: 0.8500\n",
      "Epoch 906/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2441 - acc: 0.8500\n",
      "Epoch 907/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2439 - acc: 0.8500\n",
      "Epoch 908/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2435 - acc: 0.8500\n",
      "Epoch 909/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2432 - acc: 0.8500\n",
      "Epoch 910/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.2429 - acc: 0.8500\n",
      "Epoch 911/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2427 - acc: 0.8500\n",
      "Epoch 912/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2425 - acc: 0.8500\n",
      "Epoch 913/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2422 - acc: 0.8500\n",
      "Epoch 914/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2419 - acc: 0.8500\n",
      "Epoch 915/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2416 - acc: 0.8500\n",
      "Epoch 916/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2413 - acc: 0.8500\n",
      "Epoch 917/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2410 - acc: 0.8500\n",
      "Epoch 918/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2409 - acc: 0.8500\n",
      "Epoch 919/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2406 - acc: 0.8500\n",
      "Epoch 920/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2402 - acc: 0.8500\n",
      "Epoch 921/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2400 - acc: 0.8500\n",
      "Epoch 922/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2398 - acc: 0.8500\n",
      "Epoch 923/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2396 - acc: 0.8500\n",
      "Epoch 924/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2392 - acc: 0.8500\n",
      "Epoch 925/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2389 - acc: 0.8500\n",
      "Epoch 926/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2386 - acc: 0.8500\n",
      "Epoch 927/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2384 - acc: 0.8500\n",
      "Epoch 928/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2380 - acc: 0.8500\n",
      "Epoch 929/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2377 - acc: 0.8500\n",
      "Epoch 930/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2375 - acc: 0.8500\n",
      "Epoch 931/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2372 - acc: 0.8500\n",
      "Epoch 932/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2369 - acc: 0.8500\n",
      "Epoch 933/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2366 - acc: 0.8500\n",
      "Epoch 934/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2363 - acc: 0.8500\n",
      "Epoch 935/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2360 - acc: 0.8500\n",
      "Epoch 936/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2357 - acc: 0.8500\n",
      "Epoch 937/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.2355 - acc: 0.8500\n",
      "Epoch 938/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2352 - acc: 0.8500\n",
      "Epoch 939/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2350 - acc: 0.8500\n",
      "Epoch 940/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2347 - acc: 0.8500\n",
      "Epoch 941/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2344 - acc: 0.8500\n",
      "Epoch 942/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2341 - acc: 0.8500\n",
      "Epoch 943/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2338 - acc: 0.8500\n",
      "Epoch 944/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2336 - acc: 0.8500\n",
      "Epoch 945/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2333 - acc: 0.8500\n",
      "Epoch 946/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2330 - acc: 0.8500\n",
      "Epoch 947/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2327 - acc: 0.8500\n",
      "Epoch 948/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2325 - acc: 0.8500\n",
      "Epoch 949/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2322 - acc: 0.8500\n",
      "Epoch 950/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2319 - acc: 0.8500\n",
      "Epoch 951/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2316 - acc: 0.8500\n",
      "Epoch 952/1000\n",
      "20/20 [==============================] - 0s 200us/sample - loss: 0.2314 - acc: 0.8500\n",
      "Epoch 953/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2311 - acc: 0.8500\n",
      "Epoch 954/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2308 - acc: 0.8500\n",
      "Epoch 955/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2305 - acc: 0.8500\n",
      "Epoch 956/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2303 - acc: 0.8500\n",
      "Epoch 957/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2300 - acc: 0.8500\n",
      "Epoch 958/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2297 - acc: 0.8500\n",
      "Epoch 959/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2295 - acc: 0.8500\n",
      "Epoch 960/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2292 - acc: 0.8500\n",
      "Epoch 961/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2289 - acc: 0.8500\n",
      "Epoch 962/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2287 - acc: 0.8500\n",
      "Epoch 963/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2284 - acc: 0.8500\n",
      "Epoch 964/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2281 - acc: 0.8500\n",
      "Epoch 965/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2278 - acc: 0.8500\n",
      "Epoch 966/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.2275 - acc: 0.8500\n",
      "Epoch 967/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2272 - acc: 0.9000\n",
      "Epoch 968/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2269 - acc: 0.9000\n",
      "Epoch 969/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2267 - acc: 0.9000\n",
      "Epoch 970/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2264 - acc: 0.9000\n",
      "Epoch 971/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2261 - acc: 0.9000\n",
      "Epoch 972/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2258 - acc: 0.9000\n",
      "Epoch 973/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2256 - acc: 0.9000\n",
      "Epoch 974/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2253 - acc: 0.9000\n",
      "Epoch 975/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2250 - acc: 0.9000\n",
      "Epoch 976/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2247 - acc: 0.9000\n",
      "Epoch 977/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2245 - acc: 0.9000\n",
      "Epoch 978/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2242 - acc: 0.9000\n",
      "Epoch 979/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2239 - acc: 0.9000\n",
      "Epoch 980/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2236 - acc: 0.9000\n",
      "Epoch 981/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2234 - acc: 0.9000\n",
      "Epoch 982/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2230 - acc: 0.9000\n",
      "Epoch 983/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2229 - acc: 0.9000\n",
      "Epoch 984/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2225 - acc: 0.9000\n",
      "Epoch 985/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2222 - acc: 0.9000\n",
      "Epoch 986/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2220 - acc: 0.9000\n",
      "Epoch 987/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2217 - acc: 0.9000\n",
      "Epoch 988/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.2215 - acc: 0.9000\n",
      "Epoch 989/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2211 - acc: 0.9000\n",
      "Epoch 990/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2209 - acc: 0.9000\n",
      "Epoch 991/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2207 - acc: 0.9000\n",
      "Epoch 992/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2204 - acc: 0.9000\n",
      "Epoch 993/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2201 - acc: 0.9000\n",
      "Epoch 994/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2197 - acc: 0.9000\n",
      "Epoch 995/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2195 - acc: 0.9000\n",
      "Epoch 996/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2192 - acc: 0.9000\n",
      "Epoch 997/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2189 - acc: 0.9000\n",
      "Epoch 998/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2187 - acc: 0.9000\n",
      "Epoch 999/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2184 - acc: 0.9000\n",
      "Epoch 1000/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.2181 - acc: 0.9000\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n",
      "boundary points finished.\n",
      "(80, 2)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00956925 1.01026608]]\n",
      "[[ 2.34375  -3.796875]]\n",
      "Optimal point distance: 4.5069473075054125\n",
      "cf point distance: 5.51736\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_nn = nn_model()\n",
    "df[['x1', 'x2']] = df[['x1', 'x2']].astype('float64')\n",
    "df['y'] = df['y'].astype('int64')\n",
    "new_nn, optimal_datapt = optimal_point(df, new_nn, desired_class=1, original_class=0, threshold=10000, chosen_row=4, epsilon=0.01, plot=True)\n",
    "target_class=1\n",
    "plot_decision_boundary(new_nn, X_train.to_numpy(), y_train)\n",
    "cf = Counterfactual(new_nn, shape=shape, target_proba=target_proba, tol=tol,\n",
    "                    target_class=target_class, max_iter=max_iter,\n",
    "                    feature_range=feature_range)\n",
    "X_point = X_train.iloc[4, :].to_numpy().reshape(1, -1)\n",
    "explainer = cf.explain(X_point)\n",
    "cf_point = explainer.data['cf']['X'] \n",
    "points = [(X_point, cf_point)]\n",
    "plot_func(points)\n",
    "print(\"Optimal point distance:\", euclidean_distance(X_point, optimal_datapt))\n",
    "print(\"cf point distance:\", euclidean_distance(X_point, cf_point))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9810911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " y\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 20 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\drexel_research_2024_2025\\Docs\\files\\common_functions.py:422: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/sample - loss: 4.3987 - acc: 0.5000\n",
      "Epoch 2/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 4.3343 - acc: 0.5000\n",
      "Epoch 3/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 4.2700 - acc: 0.5000\n",
      "Epoch 4/1000\n",
      "20/20 [==============================] - 0s 53us/sample - loss: 4.2058 - acc: 0.5000\n",
      "Epoch 5/1000\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 4.1419 - acc: 0.5000\n",
      "Epoch 6/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 4.0781 - acc: 0.5000\n",
      "Epoch 7/1000\n",
      "20/20 [==============================] - 0s 77us/sample - loss: 4.0145 - acc: 0.5000\n",
      "Epoch 8/1000\n",
      "20/20 [==============================] - 0s 54us/sample - loss: 3.9511 - acc: 0.5000\n",
      "Epoch 9/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 3.8879 - acc: 0.5000\n",
      "Epoch 10/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 3.8248 - acc: 0.5000\n",
      "Epoch 11/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 3.7620 - acc: 0.5000\n",
      "Epoch 12/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 3.6993 - acc: 0.5000\n",
      "Epoch 13/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 3.6369 - acc: 0.5000\n",
      "Epoch 14/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 3.5746 - acc: 0.5000\n",
      "Epoch 15/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 3.5126 - acc: 0.5000\n",
      "Epoch 16/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 3.4508 - acc: 0.5000\n",
      "Epoch 17/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 3.3892 - acc: 0.5000\n",
      "Epoch 18/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 3.3279 - acc: 0.5000\n",
      "Epoch 19/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 3.2667 - acc: 0.5000\n",
      "Epoch 20/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 3.2059 - acc: 0.5000\n",
      "Epoch 21/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 3.1452 - acc: 0.5000\n",
      "Epoch 22/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 3.0848 - acc: 0.5000\n",
      "Epoch 23/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 3.0247 - acc: 0.5000\n",
      "Epoch 24/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.9648 - acc: 0.5000\n",
      "Epoch 25/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.9053 - acc: 0.5000\n",
      "Epoch 26/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.8460 - acc: 0.5000\n",
      "Epoch 27/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.7870 - acc: 0.5000\n",
      "Epoch 28/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.7282 - acc: 0.5000\n",
      "Epoch 29/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.6699 - acc: 0.5000\n",
      "Epoch 30/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.6118 - acc: 0.5000\n",
      "Epoch 31/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.5541 - acc: 0.5000\n",
      "Epoch 32/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.4967 - acc: 0.5000\n",
      "Epoch 33/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 2.4397 - acc: 0.5000\n",
      "Epoch 34/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.3831 - acc: 0.5000\n",
      "Epoch 35/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.3268 - acc: 0.5000\n",
      "Epoch 36/1000\n",
      "20/20 [==============================] - 0s 78us/sample - loss: 2.2710 - acc: 0.5000\n",
      "Epoch 37/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 2.2157 - acc: 0.5000\n",
      "Epoch 38/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.1608 - acc: 0.5000\n",
      "Epoch 39/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 2.1063 - acc: 0.5000\n",
      "Epoch 40/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 2.0524 - acc: 0.5000\n",
      "Epoch 41/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 1.9990 - acc: 0.5000\n",
      "Epoch 42/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 1.9462 - acc: 0.5000\n",
      "Epoch 43/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.8940 - acc: 0.5000\n",
      "Epoch 44/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.8424 - acc: 0.5000\n",
      "Epoch 45/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 1.7915 - acc: 0.5000\n",
      "Epoch 46/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.7412 - acc: 0.5000\n",
      "Epoch 47/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 1.6917 - acc: 0.5000\n",
      "Epoch 48/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 1.6430 - acc: 0.5000\n",
      "Epoch 49/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 1.5951 - acc: 0.5000\n",
      "Epoch 50/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.5480 - acc: 0.5000\n",
      "Epoch 51/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 1.5019 - acc: 0.5000\n",
      "Epoch 52/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 1.4567 - acc: 0.5000\n",
      "Epoch 53/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 1.4126 - acc: 0.5000\n",
      "Epoch 54/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.3695 - acc: 0.5000\n",
      "Epoch 55/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.3275 - acc: 0.5000\n",
      "Epoch 56/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.2867 - acc: 0.5000\n",
      "Epoch 57/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 1.2471 - acc: 0.5000\n",
      "Epoch 58/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.2088 - acc: 0.5000\n",
      "Epoch 59/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.1718 - acc: 0.5000\n",
      "Epoch 60/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.1362 - acc: 0.5000\n",
      "Epoch 61/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.1020 - acc: 0.5000\n",
      "Epoch 62/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 1.0692 - acc: 0.5000\n",
      "Epoch 63/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 1.0380 - acc: 0.5000\n",
      "Epoch 64/1000\n",
      "20/20 [==============================] - 0s 79us/sample - loss: 1.0083 - acc: 0.5000\n",
      "Epoch 65/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.9801 - acc: 0.5000\n",
      "Epoch 66/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.9536 - acc: 0.5000\n",
      "Epoch 67/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.9286 - acc: 0.5000\n",
      "Epoch 68/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.9051 - acc: 0.5000\n",
      "Epoch 69/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.8833 - acc: 0.5000\n",
      "Epoch 70/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.8630 - acc: 0.5000\n",
      "Epoch 71/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.8443 - acc: 0.5000\n",
      "Epoch 72/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.8271 - acc: 0.5000\n",
      "Epoch 73/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.8114 - acc: 0.5000\n",
      "Epoch 74/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7971 - acc: 0.5000\n",
      "Epoch 75/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7841 - acc: 0.5000\n",
      "Epoch 76/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7724 - acc: 0.5000\n",
      "Epoch 77/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7620 - acc: 0.5000\n",
      "Epoch 78/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7527 - acc: 0.5000\n",
      "Epoch 79/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.7445 - acc: 0.5000\n",
      "Epoch 80/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7374 - acc: 0.5000\n",
      "Epoch 81/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7311 - acc: 0.4500\n",
      "Epoch 82/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7257 - acc: 0.2000\n",
      "Epoch 83/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7210 - acc: 0.1000\n",
      "Epoch 84/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7171 - acc: 0.0500\n",
      "Epoch 85/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.7138 - acc: 0.4000\n",
      "Epoch 86/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7110 - acc: 0.5000\n",
      "Epoch 87/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7087 - acc: 0.5000\n",
      "Epoch 88/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7068 - acc: 0.5000\n",
      "Epoch 89/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7053 - acc: 0.5000\n",
      "Epoch 90/1000\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.7041 - acc: 0.5000\n",
      "Epoch 91/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.7032 - acc: 0.5000\n",
      "Epoch 92/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7025 - acc: 0.5000\n",
      "Epoch 93/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7020 - acc: 0.5000\n",
      "Epoch 94/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7016 - acc: 0.5000\n",
      "Epoch 95/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7014 - acc: 0.5000\n",
      "Epoch 96/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7013 - acc: 0.5000\n",
      "Epoch 97/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.7012 - acc: 0.5000\n",
      "Epoch 98/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7012 - acc: 0.5000\n",
      "Epoch 99/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7012 - acc: 0.5000\n",
      "Epoch 100/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7012 - acc: 0.5000\n",
      "Epoch 101/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7013 - acc: 0.5000\n",
      "Epoch 102/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.7013 - acc: 0.5000\n",
      "Epoch 103/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7014 - acc: 0.5000\n",
      "Epoch 104/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7014 - acc: 0.5000\n",
      "Epoch 105/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7014 - acc: 0.5000\n",
      "Epoch 106/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7014 - acc: 0.5000\n",
      "Epoch 107/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7014 - acc: 0.5000\n",
      "Epoch 108/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7014 - acc: 0.5000\n",
      "Epoch 109/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7013 - acc: 0.5000\n",
      "Epoch 110/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7013 - acc: 0.5000\n",
      "Epoch 111/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7012 - acc: 0.5000\n",
      "Epoch 112/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7011 - acc: 0.5000\n",
      "Epoch 113/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7010 - acc: 0.5000\n",
      "Epoch 114/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7008 - acc: 0.5000\n",
      "Epoch 115/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7007 - acc: 0.5000\n",
      "Epoch 116/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.7005 - acc: 0.5000\n",
      "Epoch 117/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.7004 - acc: 0.5000\n",
      "Epoch 118/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7002 - acc: 0.5000\n",
      "Epoch 119/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.7001 - acc: 0.5000\n",
      "Epoch 120/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6999 - acc: 0.5000\n",
      "Epoch 121/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6997 - acc: 0.5000\n",
      "Epoch 122/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6996 - acc: 0.5000\n",
      "Epoch 123/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6994 - acc: 0.5000\n",
      "Epoch 124/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6992 - acc: 0.5000\n",
      "Epoch 125/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6991 - acc: 0.5000\n",
      "Epoch 126/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6989 - acc: 0.5000\n",
      "Epoch 127/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6987 - acc: 0.5000\n",
      "Epoch 128/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6986 - acc: 0.5000\n",
      "Epoch 129/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6984 - acc: 0.5000\n",
      "Epoch 130/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6983 - acc: 0.5000\n",
      "Epoch 131/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6981 - acc: 0.5000\n",
      "Epoch 132/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6980 - acc: 0.5000\n",
      "Epoch 133/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6979 - acc: 0.5000\n",
      "Epoch 134/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6977 - acc: 0.5000\n",
      "Epoch 135/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6976 - acc: 0.5000\n",
      "Epoch 136/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6975 - acc: 0.5000\n",
      "Epoch 137/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6974 - acc: 0.5000\n",
      "Epoch 138/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6973 - acc: 0.5000\n",
      "Epoch 139/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6971 - acc: 0.5000\n",
      "Epoch 140/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6970 - acc: 0.5000\n",
      "Epoch 141/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6969 - acc: 0.5000\n",
      "Epoch 142/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6968 - acc: 0.5000\n",
      "Epoch 143/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6967 - acc: 0.5000\n",
      "Epoch 144/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6966 - acc: 0.5000\n",
      "Epoch 145/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6965 - acc: 0.5000\n",
      "Epoch 146/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6964 - acc: 0.5000\n",
      "Epoch 147/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6963 - acc: 0.5000\n",
      "Epoch 148/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6961 - acc: 0.5000\n",
      "Epoch 149/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6960 - acc: 0.5000\n",
      "Epoch 150/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6959 - acc: 0.5000\n",
      "Epoch 151/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6958 - acc: 0.5000\n",
      "Epoch 152/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6957 - acc: 0.5000\n",
      "Epoch 153/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6956 - acc: 0.5000\n",
      "Epoch 154/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6955 - acc: 0.5000\n",
      "Epoch 155/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6954 - acc: 0.5000\n",
      "Epoch 156/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6953 - acc: 0.5000\n",
      "Epoch 157/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6952 - acc: 0.5000\n",
      "Epoch 158/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6951 - acc: 0.5000\n",
      "Epoch 159/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6950 - acc: 0.5000\n",
      "Epoch 160/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6948 - acc: 0.5000\n",
      "Epoch 161/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6947 - acc: 0.5000\n",
      "Epoch 162/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6946 - acc: 0.5000\n",
      "Epoch 163/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6945 - acc: 0.5000\n",
      "Epoch 164/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6944 - acc: 0.5000\n",
      "Epoch 165/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6943 - acc: 0.5000\n",
      "Epoch 166/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6942 - acc: 0.5000\n",
      "Epoch 167/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6941 - acc: 0.5000\n",
      "Epoch 168/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6939 - acc: 0.5000\n",
      "Epoch 169/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6938 - acc: 0.5000\n",
      "Epoch 170/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6937 - acc: 0.5000\n",
      "Epoch 171/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6936 - acc: 0.5000\n",
      "Epoch 172/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6935 - acc: 0.5000\n",
      "Epoch 173/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6934 - acc: 0.5000\n",
      "Epoch 174/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 175/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 176/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6930 - acc: 0.5000\n",
      "Epoch 177/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6929 - acc: 0.5000\n",
      "Epoch 178/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6928 - acc: 0.5000\n",
      "Epoch 179/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6927 - acc: 0.5000\n",
      "Epoch 180/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6926 - acc: 0.5000\n",
      "Epoch 181/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6924 - acc: 0.5000\n",
      "Epoch 182/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6923 - acc: 0.5000\n",
      "Epoch 183/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6922 - acc: 0.5000\n",
      "Epoch 184/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6921 - acc: 0.5000\n",
      "Epoch 185/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6920 - acc: 0.5000\n",
      "Epoch 186/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6918 - acc: 0.5000\n",
      "Epoch 187/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6917 - acc: 0.5000\n",
      "Epoch 188/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6916 - acc: 0.5000\n",
      "Epoch 189/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6915 - acc: 0.5000\n",
      "Epoch 190/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6914 - acc: 0.5000\n",
      "Epoch 191/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6912 - acc: 0.5000\n",
      "Epoch 192/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6911 - acc: 0.5000\n",
      "Epoch 193/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6910 - acc: 0.5000\n",
      "Epoch 194/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6909 - acc: 0.5000\n",
      "Epoch 195/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6908 - acc: 0.5000\n",
      "Epoch 196/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6906 - acc: 0.5000\n",
      "Epoch 197/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6905 - acc: 0.5000\n",
      "Epoch 198/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6904 - acc: 0.5000\n",
      "Epoch 199/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6903 - acc: 0.5000\n",
      "Epoch 200/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6902 - acc: 0.5000\n",
      "Epoch 201/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6900 - acc: 0.5000\n",
      "Epoch 202/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6899 - acc: 0.5000\n",
      "Epoch 203/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6898 - acc: 0.5000\n",
      "Epoch 204/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6897 - acc: 0.5000\n",
      "Epoch 205/1000\n",
      "20/20 [==============================] - 0s 51us/sample - loss: 0.6895 - acc: 0.5000\n",
      "Epoch 206/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6894 - acc: 0.5000\n",
      "Epoch 207/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6893 - acc: 0.5000\n",
      "Epoch 208/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6892 - acc: 0.5000\n",
      "Epoch 209/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6890 - acc: 0.5000\n",
      "Epoch 210/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6889 - acc: 0.5000\n",
      "Epoch 211/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6888 - acc: 0.5000\n",
      "Epoch 212/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6887 - acc: 0.5000\n",
      "Epoch 213/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6885 - acc: 0.5000\n",
      "Epoch 214/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6884 - acc: 0.5000\n",
      "Epoch 215/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6883 - acc: 0.5000\n",
      "Epoch 216/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6882 - acc: 0.5000\n",
      "Epoch 217/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6880 - acc: 0.5000\n",
      "Epoch 218/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6879 - acc: 0.5000\n",
      "Epoch 219/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6878 - acc: 0.5000\n",
      "Epoch 220/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6877 - acc: 0.5000\n",
      "Epoch 221/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6875 - acc: 0.5000\n",
      "Epoch 222/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6874 - acc: 0.5000\n",
      "Epoch 223/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6873 - acc: 0.5000\n",
      "Epoch 224/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6871 - acc: 0.5000\n",
      "Epoch 225/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6870 - acc: 0.5000\n",
      "Epoch 226/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6869 - acc: 0.5000\n",
      "Epoch 227/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6868 - acc: 0.5000\n",
      "Epoch 228/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6866 - acc: 0.5000\n",
      "Epoch 229/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6865 - acc: 0.5000\n",
      "Epoch 230/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6864 - acc: 0.5000\n",
      "Epoch 231/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6862 - acc: 0.5000\n",
      "Epoch 232/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6861 - acc: 0.5000\n",
      "Epoch 233/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6860 - acc: 0.5000\n",
      "Epoch 234/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6858 - acc: 0.5000\n",
      "Epoch 235/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6857 - acc: 0.5000\n",
      "Epoch 236/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6856 - acc: 0.5000\n",
      "Epoch 237/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6855 - acc: 0.5000\n",
      "Epoch 238/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6853 - acc: 0.5000\n",
      "Epoch 239/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6852 - acc: 0.5000\n",
      "Epoch 240/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6851 - acc: 0.5000\n",
      "Epoch 241/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6849 - acc: 0.5000\n",
      "Epoch 242/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6848 - acc: 0.5000\n",
      "Epoch 243/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6847 - acc: 0.5000\n",
      "Epoch 244/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6845 - acc: 0.5000\n",
      "Epoch 245/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6844 - acc: 0.5000\n",
      "Epoch 246/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6843 - acc: 0.5000\n",
      "Epoch 247/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6841 - acc: 0.5000\n",
      "Epoch 248/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6840 - acc: 0.5000\n",
      "Epoch 249/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6839 - acc: 0.5000\n",
      "Epoch 250/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6837 - acc: 0.5000\n",
      "Epoch 251/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6836 - acc: 0.5000\n",
      "Epoch 252/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6835 - acc: 0.5000\n",
      "Epoch 253/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6833 - acc: 0.5000\n",
      "Epoch 254/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6832 - acc: 0.5000\n",
      "Epoch 255/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6831 - acc: 0.5000\n",
      "Epoch 256/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6829 - acc: 0.5000\n",
      "Epoch 257/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6828 - acc: 0.5000\n",
      "Epoch 258/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6826 - acc: 0.5000\n",
      "Epoch 259/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6825 - acc: 0.5000\n",
      "Epoch 260/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6824 - acc: 0.5000\n",
      "Epoch 261/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6822 - acc: 0.5000\n",
      "Epoch 262/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6821 - acc: 0.5000\n",
      "Epoch 263/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6820 - acc: 0.5000\n",
      "Epoch 264/1000\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.6818 - acc: 0.5000\n",
      "Epoch 265/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6817 - acc: 0.5000\n",
      "Epoch 266/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6816 - acc: 0.5000\n",
      "Epoch 267/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6814 - acc: 0.5000\n",
      "Epoch 268/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6813 - acc: 0.5000\n",
      "Epoch 269/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6811 - acc: 0.5000\n",
      "Epoch 270/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6810 - acc: 0.5000\n",
      "Epoch 271/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6809 - acc: 0.5000\n",
      "Epoch 272/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6807 - acc: 0.5000\n",
      "Epoch 273/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6806 - acc: 0.5000\n",
      "Epoch 274/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6804 - acc: 0.5000\n",
      "Epoch 275/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6803 - acc: 0.5000\n",
      "Epoch 276/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6802 - acc: 0.5000\n",
      "Epoch 277/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6800 - acc: 0.5000\n",
      "Epoch 278/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6799 - acc: 0.5000\n",
      "Epoch 279/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6797 - acc: 0.5000\n",
      "Epoch 280/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6796 - acc: 0.5000\n",
      "Epoch 281/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6795 - acc: 0.5000\n",
      "Epoch 282/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6793 - acc: 0.5000\n",
      "Epoch 283/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6792 - acc: 0.5000\n",
      "Epoch 284/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6790 - acc: 0.5000\n",
      "Epoch 285/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6789 - acc: 0.5000\n",
      "Epoch 286/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6788 - acc: 0.5000\n",
      "Epoch 287/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6786 - acc: 0.5000\n",
      "Epoch 288/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6785 - acc: 0.5000\n",
      "Epoch 289/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6783 - acc: 0.5000\n",
      "Epoch 290/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6782 - acc: 0.5000\n",
      "Epoch 291/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6781 - acc: 0.5000\n",
      "Epoch 292/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6779 - acc: 0.5000\n",
      "Epoch 293/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6778 - acc: 0.5000\n",
      "Epoch 294/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6776 - acc: 0.5000\n",
      "Epoch 295/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6775 - acc: 0.5000\n",
      "Epoch 296/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6773 - acc: 0.5000\n",
      "Epoch 297/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6772 - acc: 0.5000\n",
      "Epoch 298/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6770 - acc: 0.5000\n",
      "Epoch 299/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6769 - acc: 0.5000\n",
      "Epoch 300/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6768 - acc: 0.5000\n",
      "Epoch 301/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6766 - acc: 0.5000\n",
      "Epoch 302/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6765 - acc: 0.5000\n",
      "Epoch 303/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6763 - acc: 0.5000\n",
      "Epoch 304/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6762 - acc: 0.5000\n",
      "Epoch 305/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6760 - acc: 0.5000\n",
      "Epoch 306/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6759 - acc: 0.5000\n",
      "Epoch 307/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6757 - acc: 0.5000\n",
      "Epoch 308/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6756 - acc: 0.5000\n",
      "Epoch 309/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6755 - acc: 0.5000\n",
      "Epoch 310/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6753 - acc: 0.5000\n",
      "Epoch 311/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6752 - acc: 0.5000\n",
      "Epoch 312/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6750 - acc: 0.5000\n",
      "Epoch 313/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6749 - acc: 0.5000\n",
      "Epoch 314/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6747 - acc: 0.5000\n",
      "Epoch 315/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6746 - acc: 0.5000\n",
      "Epoch 316/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6744 - acc: 0.5000\n",
      "Epoch 317/1000\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.6743 - acc: 0.5000\n",
      "Epoch 318/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6741 - acc: 0.5000\n",
      "Epoch 319/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6740 - acc: 0.5000\n",
      "Epoch 320/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6738 - acc: 0.5000\n",
      "Epoch 321/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6737 - acc: 0.5000\n",
      "Epoch 322/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6735 - acc: 0.5000\n",
      "Epoch 323/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6734 - acc: 0.5000\n",
      "Epoch 324/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6733 - acc: 0.5000\n",
      "Epoch 325/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6731 - acc: 0.5000\n",
      "Epoch 326/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6730 - acc: 0.5000\n",
      "Epoch 327/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6728 - acc: 0.5000\n",
      "Epoch 328/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6727 - acc: 0.5000\n",
      "Epoch 329/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6725 - acc: 0.5000\n",
      "Epoch 330/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6724 - acc: 0.5000\n",
      "Epoch 331/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6722 - acc: 0.5000\n",
      "Epoch 332/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6721 - acc: 0.5000\n",
      "Epoch 333/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6719 - acc: 0.5000\n",
      "Epoch 334/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6718 - acc: 0.5000\n",
      "Epoch 335/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6716 - acc: 0.5000\n",
      "Epoch 336/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6715 - acc: 0.5000\n",
      "Epoch 337/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6713 - acc: 0.5000\n",
      "Epoch 338/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6712 - acc: 0.5000\n",
      "Epoch 339/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6710 - acc: 0.5000\n",
      "Epoch 340/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6709 - acc: 0.5000\n",
      "Epoch 341/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6707 - acc: 0.5000\n",
      "Epoch 342/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6706 - acc: 0.5000\n",
      "Epoch 343/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6704 - acc: 0.5000\n",
      "Epoch 344/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6703 - acc: 0.5000\n",
      "Epoch 345/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6701 - acc: 0.5000\n",
      "Epoch 346/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6699 - acc: 0.5000\n",
      "Epoch 347/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6698 - acc: 0.5000\n",
      "Epoch 348/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6696 - acc: 0.5000\n",
      "Epoch 349/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6695 - acc: 0.5000\n",
      "Epoch 350/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6693 - acc: 0.5000\n",
      "Epoch 351/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6692 - acc: 0.5000\n",
      "Epoch 352/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6690 - acc: 0.5000\n",
      "Epoch 353/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6689 - acc: 0.5000\n",
      "Epoch 354/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6687 - acc: 0.5000\n",
      "Epoch 355/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6686 - acc: 0.5000\n",
      "Epoch 356/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6684 - acc: 0.5000\n",
      "Epoch 357/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6683 - acc: 0.5000\n",
      "Epoch 358/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6681 - acc: 0.5000\n",
      "Epoch 359/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6680 - acc: 0.5000\n",
      "Epoch 360/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6678 - acc: 0.5000\n",
      "Epoch 361/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6677 - acc: 0.5000\n",
      "Epoch 362/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6675 - acc: 0.5000\n",
      "Epoch 363/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6673 - acc: 0.5000\n",
      "Epoch 364/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6672 - acc: 0.5000\n",
      "Epoch 365/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6670 - acc: 0.5000\n",
      "Epoch 366/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6669 - acc: 0.5000\n",
      "Epoch 367/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6667 - acc: 0.5000\n",
      "Epoch 368/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6666 - acc: 0.5000\n",
      "Epoch 369/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6664 - acc: 0.5000\n",
      "Epoch 370/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6663 - acc: 0.5000\n",
      "Epoch 371/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6661 - acc: 0.5000\n",
      "Epoch 372/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6660 - acc: 0.5000\n",
      "Epoch 373/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6658 - acc: 0.5000\n",
      "Epoch 374/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6656 - acc: 0.5000\n",
      "Epoch 375/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6655 - acc: 0.5000\n",
      "Epoch 376/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6653 - acc: 0.5000\n",
      "Epoch 377/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6652 - acc: 0.5000\n",
      "Epoch 378/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6650 - acc: 0.5000\n",
      "Epoch 379/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6649 - acc: 0.5000\n",
      "Epoch 380/1000\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.6647 - acc: 0.5000\n",
      "Epoch 381/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6645 - acc: 0.5000\n",
      "Epoch 382/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6644 - acc: 0.5000\n",
      "Epoch 383/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6642 - acc: 0.5000\n",
      "Epoch 384/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6641 - acc: 0.5000\n",
      "Epoch 385/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6639 - acc: 0.5000\n",
      "Epoch 386/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6638 - acc: 0.5000\n",
      "Epoch 387/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6636 - acc: 0.5000\n",
      "Epoch 388/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6634 - acc: 0.5000\n",
      "Epoch 389/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6633 - acc: 0.5000\n",
      "Epoch 390/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6631 - acc: 0.5000\n",
      "Epoch 391/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6630 - acc: 0.5000\n",
      "Epoch 392/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6628 - acc: 0.5000\n",
      "Epoch 393/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6626 - acc: 0.5000\n",
      "Epoch 394/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6625 - acc: 0.5000\n",
      "Epoch 395/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6623 - acc: 0.5000\n",
      "Epoch 396/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6622 - acc: 0.5000\n",
      "Epoch 397/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6620 - acc: 0.5000\n",
      "Epoch 398/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6619 - acc: 0.5000\n",
      "Epoch 399/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6617 - acc: 0.5000\n",
      "Epoch 400/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6615 - acc: 0.5000\n",
      "Epoch 401/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6614 - acc: 0.5000\n",
      "Epoch 402/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6612 - acc: 0.5000\n",
      "Epoch 403/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6611 - acc: 0.5000\n",
      "Epoch 404/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6609 - acc: 0.5000\n",
      "Epoch 405/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6607 - acc: 0.5000\n",
      "Epoch 406/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6606 - acc: 0.5000\n",
      "Epoch 407/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6604 - acc: 0.5000\n",
      "Epoch 408/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6603 - acc: 0.5000\n",
      "Epoch 409/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6601 - acc: 0.5000\n",
      "Epoch 410/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6599 - acc: 0.5000\n",
      "Epoch 411/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6598 - acc: 0.5000\n",
      "Epoch 412/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6596 - acc: 0.5000\n",
      "Epoch 413/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6594 - acc: 0.5000\n",
      "Epoch 414/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6593 - acc: 0.5000\n",
      "Epoch 415/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6591 - acc: 0.5000\n",
      "Epoch 416/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6590 - acc: 0.5000\n",
      "Epoch 417/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6588 - acc: 0.5000\n",
      "Epoch 418/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6586 - acc: 0.5000\n",
      "Epoch 419/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6585 - acc: 0.5000\n",
      "Epoch 420/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6583 - acc: 0.5000\n",
      "Epoch 421/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6582 - acc: 0.5000\n",
      "Epoch 422/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6580 - acc: 0.5000\n",
      "Epoch 423/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6578 - acc: 0.5000\n",
      "Epoch 424/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6577 - acc: 0.5000\n",
      "Epoch 425/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6575 - acc: 0.5000\n",
      "Epoch 426/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6573 - acc: 0.5000\n",
      "Epoch 427/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6572 - acc: 0.5000\n",
      "Epoch 428/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6570 - acc: 0.5000\n",
      "Epoch 429/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6569 - acc: 0.5000\n",
      "Epoch 430/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6567 - acc: 0.5000\n",
      "Epoch 431/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6565 - acc: 0.5000\n",
      "Epoch 432/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6564 - acc: 0.5000\n",
      "Epoch 433/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6562 - acc: 0.5000\n",
      "Epoch 434/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6560 - acc: 0.5000\n",
      "Epoch 435/1000\n",
      "20/20 [==============================] - 0s 200us/sample - loss: 0.6559 - acc: 0.5000\n",
      "Epoch 436/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6557 - acc: 0.5000\n",
      "Epoch 437/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6555 - acc: 0.5000\n",
      "Epoch 438/1000\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.6554 - acc: 0.5000\n",
      "Epoch 439/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6552 - acc: 0.5000\n",
      "Epoch 440/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6551 - acc: 0.5000\n",
      "Epoch 441/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6549 - acc: 0.5000\n",
      "Epoch 442/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6547 - acc: 0.5000\n",
      "Epoch 443/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6546 - acc: 0.5000\n",
      "Epoch 444/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6544 - acc: 0.5000\n",
      "Epoch 445/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6542 - acc: 0.5000\n",
      "Epoch 446/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6541 - acc: 0.5000\n",
      "Epoch 447/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6539 - acc: 0.5000\n",
      "Epoch 448/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6537 - acc: 0.5000\n",
      "Epoch 449/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6536 - acc: 0.5000\n",
      "Epoch 450/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6534 - acc: 0.5000\n",
      "Epoch 451/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6532 - acc: 0.5000\n",
      "Epoch 452/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6531 - acc: 0.5000\n",
      "Epoch 453/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6529 - acc: 0.5000\n",
      "Epoch 454/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6527 - acc: 0.5000\n",
      "Epoch 455/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6526 - acc: 0.5000\n",
      "Epoch 456/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6524 - acc: 0.5000\n",
      "Epoch 457/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6522 - acc: 0.5000\n",
      "Epoch 458/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6521 - acc: 0.5000\n",
      "Epoch 459/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6519 - acc: 0.5000\n",
      "Epoch 460/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6517 - acc: 0.5000\n",
      "Epoch 461/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6516 - acc: 0.5000\n",
      "Epoch 462/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6514 - acc: 0.5000\n",
      "Epoch 463/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6512 - acc: 0.5000\n",
      "Epoch 464/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6511 - acc: 0.5000\n",
      "Epoch 465/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6509 - acc: 0.5000\n",
      "Epoch 466/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6507 - acc: 0.5000\n",
      "Epoch 467/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6506 - acc: 0.5000\n",
      "Epoch 468/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6504 - acc: 0.5000\n",
      "Epoch 469/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6502 - acc: 0.5000\n",
      "Epoch 470/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6501 - acc: 0.5000\n",
      "Epoch 471/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6499 - acc: 0.5000\n",
      "Epoch 472/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6497 - acc: 0.5000\n",
      "Epoch 473/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6496 - acc: 0.5000\n",
      "Epoch 474/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6494 - acc: 0.5000\n",
      "Epoch 475/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6492 - acc: 0.5000\n",
      "Epoch 476/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6491 - acc: 0.5000\n",
      "Epoch 477/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6489 - acc: 0.5000\n",
      "Epoch 478/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6487 - acc: 0.5000\n",
      "Epoch 479/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6485 - acc: 0.5000\n",
      "Epoch 480/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6484 - acc: 0.5000\n",
      "Epoch 481/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6482 - acc: 0.5000\n",
      "Epoch 482/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6480 - acc: 0.5000\n",
      "Epoch 483/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6479 - acc: 0.5000\n",
      "Epoch 484/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6477 - acc: 0.5000\n",
      "Epoch 485/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6475 - acc: 0.5000\n",
      "Epoch 486/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6474 - acc: 0.5000\n",
      "Epoch 487/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6472 - acc: 0.5000\n",
      "Epoch 488/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6470 - acc: 0.5000\n",
      "Epoch 489/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6469 - acc: 0.5000\n",
      "Epoch 490/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6467 - acc: 0.5000\n",
      "Epoch 491/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6465 - acc: 0.5000\n",
      "Epoch 492/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6463 - acc: 0.5000\n",
      "Epoch 493/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6462 - acc: 0.5000\n",
      "Epoch 494/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6460 - acc: 0.5000\n",
      "Epoch 495/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6458 - acc: 0.5000\n",
      "Epoch 496/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6457 - acc: 0.5000\n",
      "Epoch 497/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6455 - acc: 0.5000\n",
      "Epoch 498/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6453 - acc: 0.5000\n",
      "Epoch 499/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6451 - acc: 0.5000\n",
      "Epoch 500/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6450 - acc: 0.5000\n",
      "Epoch 501/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6448 - acc: 0.5000\n",
      "Epoch 502/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6446 - acc: 0.5000\n",
      "Epoch 503/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6445 - acc: 0.5000\n",
      "Epoch 504/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6443 - acc: 0.5000\n",
      "Epoch 505/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6441 - acc: 0.5000\n",
      "Epoch 506/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6439 - acc: 0.5000\n",
      "Epoch 507/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6438 - acc: 0.5000\n",
      "Epoch 508/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6436 - acc: 0.5000\n",
      "Epoch 509/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6434 - acc: 0.5000\n",
      "Epoch 510/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6433 - acc: 0.5000\n",
      "Epoch 511/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6431 - acc: 0.5000\n",
      "Epoch 512/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6429 - acc: 0.5000\n",
      "Epoch 513/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6427 - acc: 0.5000\n",
      "Epoch 514/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6426 - acc: 0.5000\n",
      "Epoch 515/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6424 - acc: 0.5000\n",
      "Epoch 516/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6422 - acc: 0.5000\n",
      "Epoch 517/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6421 - acc: 0.5000\n",
      "Epoch 518/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6419 - acc: 0.5000\n",
      "Epoch 519/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6417 - acc: 0.5000\n",
      "Epoch 520/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6415 - acc: 0.5000\n",
      "Epoch 521/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6414 - acc: 0.5000\n",
      "Epoch 522/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6412 - acc: 0.5000\n",
      "Epoch 523/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6410 - acc: 0.5000\n",
      "Epoch 524/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6408 - acc: 0.5000\n",
      "Epoch 525/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6407 - acc: 0.5000\n",
      "Epoch 526/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6405 - acc: 0.5000\n",
      "Epoch 527/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6403 - acc: 0.5000\n",
      "Epoch 528/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6401 - acc: 0.5000\n",
      "Epoch 529/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6400 - acc: 0.5000\n",
      "Epoch 530/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6398 - acc: 0.5000\n",
      "Epoch 531/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6396 - acc: 0.5000\n",
      "Epoch 532/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6395 - acc: 0.5000\n",
      "Epoch 533/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6393 - acc: 0.5000\n",
      "Epoch 534/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6391 - acc: 0.5000\n",
      "Epoch 535/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6389 - acc: 0.5000\n",
      "Epoch 536/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6388 - acc: 0.5000\n",
      "Epoch 537/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6386 - acc: 0.5000\n",
      "Epoch 538/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6384 - acc: 0.5000\n",
      "Epoch 539/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6382 - acc: 0.5000\n",
      "Epoch 540/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6381 - acc: 0.5000\n",
      "Epoch 541/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6379 - acc: 0.5000\n",
      "Epoch 542/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6377 - acc: 0.5000\n",
      "Epoch 543/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6375 - acc: 0.5000\n",
      "Epoch 544/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6374 - acc: 0.5000\n",
      "Epoch 545/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6372 - acc: 0.5000\n",
      "Epoch 546/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6370 - acc: 0.5000\n",
      "Epoch 547/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6368 - acc: 0.5000\n",
      "Epoch 548/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6367 - acc: 0.5000\n",
      "Epoch 549/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6365 - acc: 0.5000\n",
      "Epoch 550/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6363 - acc: 0.5000\n",
      "Epoch 551/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6361 - acc: 0.5000\n",
      "Epoch 552/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6359 - acc: 0.5000\n",
      "Epoch 553/1000\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.6358 - acc: 0.5000\n",
      "Epoch 554/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6356 - acc: 0.5000\n",
      "Epoch 555/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6354 - acc: 0.5000\n",
      "Epoch 556/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6352 - acc: 0.5000\n",
      "Epoch 557/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6351 - acc: 0.5000\n",
      "Epoch 558/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6349 - acc: 0.5000\n",
      "Epoch 559/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6347 - acc: 0.5000\n",
      "Epoch 560/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6345 - acc: 0.5000\n",
      "Epoch 561/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6344 - acc: 0.5000\n",
      "Epoch 562/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6342 - acc: 0.5000\n",
      "Epoch 563/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6340 - acc: 0.5000\n",
      "Epoch 564/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6338 - acc: 0.5000\n",
      "Epoch 565/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6337 - acc: 0.5000\n",
      "Epoch 566/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6335 - acc: 0.5000\n",
      "Epoch 567/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6333 - acc: 0.5000\n",
      "Epoch 568/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6331 - acc: 0.5000\n",
      "Epoch 569/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6329 - acc: 0.5000\n",
      "Epoch 570/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6328 - acc: 0.5000\n",
      "Epoch 571/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6326 - acc: 0.5000\n",
      "Epoch 572/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6324 - acc: 0.5000\n",
      "Epoch 573/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6322 - acc: 0.5000\n",
      "Epoch 574/1000\n",
      "20/20 [==============================] - 0s 56us/sample - loss: 0.6321 - acc: 0.5000\n",
      "Epoch 575/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6319 - acc: 0.5000\n",
      "Epoch 576/1000\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.6317 - acc: 0.5000\n",
      "Epoch 577/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6315 - acc: 0.5000\n",
      "Epoch 578/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6313 - acc: 0.5000\n",
      "Epoch 579/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6312 - acc: 0.5000\n",
      "Epoch 580/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6310 - acc: 0.5000\n",
      "Epoch 581/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6308 - acc: 0.5000\n",
      "Epoch 582/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6306 - acc: 0.5000\n",
      "Epoch 583/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6305 - acc: 0.5000\n",
      "Epoch 584/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6303 - acc: 0.5000\n",
      "Epoch 585/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6301 - acc: 0.5000\n",
      "Epoch 586/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6299 - acc: 0.5000\n",
      "Epoch 587/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6297 - acc: 0.5000\n",
      "Epoch 588/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6296 - acc: 0.5000\n",
      "Epoch 589/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6294 - acc: 0.5000\n",
      "Epoch 590/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6292 - acc: 0.5000\n",
      "Epoch 591/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6290 - acc: 0.5000\n",
      "Epoch 592/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6288 - acc: 0.5000\n",
      "Epoch 593/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6287 - acc: 0.5000\n",
      "Epoch 594/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6285 - acc: 0.5000\n",
      "Epoch 595/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6283 - acc: 0.5000\n",
      "Epoch 596/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6281 - acc: 0.5000\n",
      "Epoch 597/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6279 - acc: 0.5000\n",
      "Epoch 598/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6278 - acc: 0.5000\n",
      "Epoch 599/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6276 - acc: 0.5000\n",
      "Epoch 600/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6274 - acc: 0.5000\n",
      "Epoch 601/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6272 - acc: 0.5000\n",
      "Epoch 602/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6270 - acc: 0.5000\n",
      "Epoch 603/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6269 - acc: 0.5000\n",
      "Epoch 604/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6267 - acc: 0.5000\n",
      "Epoch 605/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6265 - acc: 0.5000\n",
      "Epoch 606/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6263 - acc: 0.5000\n",
      "Epoch 607/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6261 - acc: 0.5000\n",
      "Epoch 608/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6260 - acc: 0.5000\n",
      "Epoch 609/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6258 - acc: 0.5000\n",
      "Epoch 610/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6256 - acc: 0.5000\n",
      "Epoch 611/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6254 - acc: 0.5000\n",
      "Epoch 612/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6252 - acc: 0.5000\n",
      "Epoch 613/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6251 - acc: 0.5000\n",
      "Epoch 614/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6249 - acc: 0.5000\n",
      "Epoch 615/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6247 - acc: 0.5000\n",
      "Epoch 616/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6245 - acc: 0.5000\n",
      "Epoch 617/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6243 - acc: 0.5000\n",
      "Epoch 618/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6241 - acc: 0.5000\n",
      "Epoch 619/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6240 - acc: 0.5000\n",
      "Epoch 620/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6238 - acc: 0.5000\n",
      "Epoch 621/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6236 - acc: 0.5000\n",
      "Epoch 622/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6234 - acc: 0.5000\n",
      "Epoch 623/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6232 - acc: 0.5000\n",
      "Epoch 624/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6231 - acc: 0.5000\n",
      "Epoch 625/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6229 - acc: 0.5000\n",
      "Epoch 626/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6227 - acc: 0.5000\n",
      "Epoch 627/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6225 - acc: 0.5000\n",
      "Epoch 628/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6223 - acc: 0.5000\n",
      "Epoch 629/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6221 - acc: 0.5000\n",
      "Epoch 630/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6220 - acc: 0.5000\n",
      "Epoch 631/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6218 - acc: 0.5000\n",
      "Epoch 632/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6216 - acc: 0.5000\n",
      "Epoch 633/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6214 - acc: 0.5000\n",
      "Epoch 634/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6212 - acc: 0.5000\n",
      "Epoch 635/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6211 - acc: 0.5000\n",
      "Epoch 636/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6209 - acc: 0.5000\n",
      "Epoch 637/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6207 - acc: 0.5000\n",
      "Epoch 638/1000\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.6205 - acc: 0.5000\n",
      "Epoch 639/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6203 - acc: 0.5000\n",
      "Epoch 640/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6201 - acc: 0.5000\n",
      "Epoch 641/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6200 - acc: 0.5000\n",
      "Epoch 642/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6198 - acc: 0.5000\n",
      "Epoch 643/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6196 - acc: 0.5000\n",
      "Epoch 644/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6194 - acc: 0.5000\n",
      "Epoch 645/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6192 - acc: 0.5000\n",
      "Epoch 646/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6190 - acc: 0.5000\n",
      "Epoch 647/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6189 - acc: 0.5000\n",
      "Epoch 648/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6187 - acc: 0.5000\n",
      "Epoch 649/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6185 - acc: 0.5000\n",
      "Epoch 650/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6183 - acc: 0.5000\n",
      "Epoch 651/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6181 - acc: 0.5000\n",
      "Epoch 652/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6179 - acc: 0.5000\n",
      "Epoch 653/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6178 - acc: 0.5000\n",
      "Epoch 654/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6176 - acc: 0.5000\n",
      "Epoch 655/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6174 - acc: 0.5000\n",
      "Epoch 656/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6172 - acc: 0.5000\n",
      "Epoch 657/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6170 - acc: 0.5000\n",
      "Epoch 658/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6168 - acc: 0.5000\n",
      "Epoch 659/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6166 - acc: 0.5000\n",
      "Epoch 660/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6165 - acc: 0.5000\n",
      "Epoch 661/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6163 - acc: 0.5000\n",
      "Epoch 662/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6161 - acc: 0.5000\n",
      "Epoch 663/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6159 - acc: 0.5000\n",
      "Epoch 664/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6157 - acc: 0.5000\n",
      "Epoch 665/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6155 - acc: 0.5000\n",
      "Epoch 666/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6154 - acc: 0.5000\n",
      "Epoch 667/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6152 - acc: 0.5000\n",
      "Epoch 668/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6150 - acc: 0.5000\n",
      "Epoch 669/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6148 - acc: 0.5000\n",
      "Epoch 670/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6146 - acc: 0.5000\n",
      "Epoch 671/1000\n",
      "20/20 [==============================] - 0s 25us/sample - loss: 0.6144 - acc: 0.5000\n",
      "Epoch 672/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6142 - acc: 0.5000\n",
      "Epoch 673/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6141 - acc: 0.5000\n",
      "Epoch 674/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6139 - acc: 0.5000\n",
      "Epoch 675/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6137 - acc: 0.5000\n",
      "Epoch 676/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6135 - acc: 0.5000\n",
      "Epoch 677/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6133 - acc: 0.5000\n",
      "Epoch 678/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6131 - acc: 0.5000\n",
      "Epoch 679/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6129 - acc: 0.5000\n",
      "Epoch 680/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6128 - acc: 0.5000\n",
      "Epoch 681/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6126 - acc: 0.5000\n",
      "Epoch 682/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6124 - acc: 0.5000\n",
      "Epoch 683/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6122 - acc: 0.5000\n",
      "Epoch 684/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6120 - acc: 0.5500\n",
      "Epoch 685/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6118 - acc: 0.5500\n",
      "Epoch 686/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6116 - acc: 0.5500\n",
      "Epoch 687/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6115 - acc: 0.5500\n",
      "Epoch 688/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6113 - acc: 0.5500\n",
      "Epoch 689/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6111 - acc: 0.5500\n",
      "Epoch 690/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6109 - acc: 0.5500\n",
      "Epoch 691/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6107 - acc: 0.5500\n",
      "Epoch 692/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6105 - acc: 0.5500\n",
      "Epoch 693/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6103 - acc: 0.5500\n",
      "Epoch 694/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6101 - acc: 0.5500\n",
      "Epoch 695/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6100 - acc: 0.5500\n",
      "Epoch 696/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6098 - acc: 0.5500\n",
      "Epoch 697/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6096 - acc: 0.5500\n",
      "Epoch 698/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6094 - acc: 0.5500\n",
      "Epoch 699/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6092 - acc: 0.5500\n",
      "Epoch 700/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6090 - acc: 0.5500\n",
      "Epoch 701/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6088 - acc: 0.5500\n",
      "Epoch 702/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6086 - acc: 0.5500\n",
      "Epoch 703/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6085 - acc: 0.5500\n",
      "Epoch 704/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6083 - acc: 0.5500\n",
      "Epoch 705/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6081 - acc: 0.5500\n",
      "Epoch 706/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6079 - acc: 0.5500\n",
      "Epoch 707/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6077 - acc: 0.5500\n",
      "Epoch 708/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6075 - acc: 0.5500\n",
      "Epoch 709/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6073 - acc: 0.5500\n",
      "Epoch 710/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6071 - acc: 0.5500\n",
      "Epoch 711/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6070 - acc: 0.5500\n",
      "Epoch 712/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6068 - acc: 0.5500\n",
      "Epoch 713/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6066 - acc: 0.5500\n",
      "Epoch 714/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6064 - acc: 0.5500\n",
      "Epoch 715/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6062 - acc: 0.5500\n",
      "Epoch 716/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6060 - acc: 0.5500\n",
      "Epoch 717/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6058 - acc: 0.5500\n",
      "Epoch 718/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6056 - acc: 0.5500\n",
      "Epoch 719/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6054 - acc: 0.5500\n",
      "Epoch 720/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6053 - acc: 0.5500\n",
      "Epoch 721/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6051 - acc: 0.5500\n",
      "Epoch 722/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6049 - acc: 0.5500\n",
      "Epoch 723/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6047 - acc: 0.5500\n",
      "Epoch 724/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6045 - acc: 0.5500\n",
      "Epoch 725/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6043 - acc: 0.5500\n",
      "Epoch 726/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6041 - acc: 0.5500\n",
      "Epoch 727/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6039 - acc: 0.5500\n",
      "Epoch 728/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6037 - acc: 0.5500\n",
      "Epoch 729/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6036 - acc: 0.5500\n",
      "Epoch 730/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6034 - acc: 0.5500\n",
      "Epoch 731/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6032 - acc: 0.5500\n",
      "Epoch 732/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6030 - acc: 0.5500\n",
      "Epoch 733/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6028 - acc: 0.5500\n",
      "Epoch 734/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6026 - acc: 0.5500\n",
      "Epoch 735/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6024 - acc: 0.5500\n",
      "Epoch 736/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6022 - acc: 0.5500\n",
      "Epoch 737/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6020 - acc: 0.5500\n",
      "Epoch 738/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6019 - acc: 0.5500\n",
      "Epoch 739/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6017 - acc: 0.5500\n",
      "Epoch 740/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6015 - acc: 0.5500\n",
      "Epoch 741/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6013 - acc: 0.5500\n",
      "Epoch 742/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6011 - acc: 0.5500\n",
      "Epoch 743/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.6009 - acc: 0.5500\n",
      "Epoch 744/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6007 - acc: 0.5500\n",
      "Epoch 745/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6005 - acc: 0.5500\n",
      "Epoch 746/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.6003 - acc: 0.5500\n",
      "Epoch 747/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.6001 - acc: 0.5500\n",
      "Epoch 748/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5999 - acc: 0.5500\n",
      "Epoch 749/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5998 - acc: 0.5500\n",
      "Epoch 750/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5996 - acc: 0.5500\n",
      "Epoch 751/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5994 - acc: 0.5500\n",
      "Epoch 752/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5992 - acc: 0.5500\n",
      "Epoch 753/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5990 - acc: 0.5500\n",
      "Epoch 754/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5988 - acc: 0.5500\n",
      "Epoch 755/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5986 - acc: 0.5500\n",
      "Epoch 756/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5984 - acc: 0.5500\n",
      "Epoch 757/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5982 - acc: 0.5500\n",
      "Epoch 758/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5980 - acc: 0.5500\n",
      "Epoch 759/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5978 - acc: 0.5500\n",
      "Epoch 760/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5977 - acc: 0.5500\n",
      "Epoch 761/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5975 - acc: 0.5500\n",
      "Epoch 762/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5973 - acc: 0.5500\n",
      "Epoch 763/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5971 - acc: 0.5500\n",
      "Epoch 764/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5969 - acc: 0.5500\n",
      "Epoch 765/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5967 - acc: 0.5500\n",
      "Epoch 766/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5965 - acc: 0.5500\n",
      "Epoch 767/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5963 - acc: 0.5500\n",
      "Epoch 768/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5961 - acc: 0.6000\n",
      "Epoch 769/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5959 - acc: 0.6000\n",
      "Epoch 770/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5957 - acc: 0.6000\n",
      "Epoch 771/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5955 - acc: 0.6000\n",
      "Epoch 772/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5954 - acc: 0.6000\n",
      "Epoch 773/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5952 - acc: 0.6000\n",
      "Epoch 774/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5950 - acc: 0.6000\n",
      "Epoch 775/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5948 - acc: 0.6000\n",
      "Epoch 776/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5946 - acc: 0.6000\n",
      "Epoch 777/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5944 - acc: 0.6000\n",
      "Epoch 778/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5942 - acc: 0.6000\n",
      "Epoch 779/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5940 - acc: 0.6000\n",
      "Epoch 780/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5938 - acc: 0.6000\n",
      "Epoch 781/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5936 - acc: 0.6000\n",
      "Epoch 782/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5934 - acc: 0.6000\n",
      "Epoch 783/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5932 - acc: 0.6000\n",
      "Epoch 784/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5930 - acc: 0.6000\n",
      "Epoch 785/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5929 - acc: 0.6000\n",
      "Epoch 786/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5927 - acc: 0.6000\n",
      "Epoch 787/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5925 - acc: 0.6000\n",
      "Epoch 788/1000\n",
      "20/20 [==============================] - 0s 52us/sample - loss: 0.5923 - acc: 0.6000\n",
      "Epoch 789/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5921 - acc: 0.6000\n",
      "Epoch 790/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5919 - acc: 0.6000\n",
      "Epoch 791/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5917 - acc: 0.6000\n",
      "Epoch 792/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5915 - acc: 0.6000\n",
      "Epoch 793/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5913 - acc: 0.6000\n",
      "Epoch 794/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5911 - acc: 0.6000\n",
      "Epoch 795/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5909 - acc: 0.6000\n",
      "Epoch 796/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5907 - acc: 0.6000\n",
      "Epoch 797/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5905 - acc: 0.6000\n",
      "Epoch 798/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5903 - acc: 0.6000\n",
      "Epoch 799/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5901 - acc: 0.6000\n",
      "Epoch 800/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.5900 - acc: 0.6000\n",
      "Epoch 801/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5898 - acc: 0.6000\n",
      "Epoch 802/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5896 - acc: 0.6000\n",
      "Epoch 803/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5894 - acc: 0.6000\n",
      "Epoch 804/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5892 - acc: 0.6000\n",
      "Epoch 805/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5890 - acc: 0.6000\n",
      "Epoch 806/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5888 - acc: 0.6000\n",
      "Epoch 807/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5886 - acc: 0.6000\n",
      "Epoch 808/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5884 - acc: 0.6000\n",
      "Epoch 809/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5882 - acc: 0.6000\n",
      "Epoch 810/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5880 - acc: 0.6000\n",
      "Epoch 811/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5878 - acc: 0.6000\n",
      "Epoch 812/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5876 - acc: 0.6000\n",
      "Epoch 813/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5874 - acc: 0.6000\n",
      "Epoch 814/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5872 - acc: 0.6000\n",
      "Epoch 815/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5870 - acc: 0.6000\n",
      "Epoch 816/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5868 - acc: 0.6000\n",
      "Epoch 817/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5866 - acc: 0.6000\n",
      "Epoch 818/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5865 - acc: 0.6000\n",
      "Epoch 819/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5863 - acc: 0.6000\n",
      "Epoch 820/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5861 - acc: 0.6000\n",
      "Epoch 821/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5859 - acc: 0.6000\n",
      "Epoch 822/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5857 - acc: 0.6000\n",
      "Epoch 823/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5855 - acc: 0.6500\n",
      "Epoch 824/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5853 - acc: 0.6500\n",
      "Epoch 825/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5851 - acc: 0.6500\n",
      "Epoch 826/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5849 - acc: 0.6500\n",
      "Epoch 827/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5847 - acc: 0.6500\n",
      "Epoch 828/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5845 - acc: 0.6500\n",
      "Epoch 829/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5843 - acc: 0.6500\n",
      "Epoch 830/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5841 - acc: 0.6500\n",
      "Epoch 831/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5839 - acc: 0.6500\n",
      "Epoch 832/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5837 - acc: 0.6500\n",
      "Epoch 833/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5835 - acc: 0.6500\n",
      "Epoch 834/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5833 - acc: 0.6500\n",
      "Epoch 835/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5831 - acc: 0.6500\n",
      "Epoch 836/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5829 - acc: 0.6500\n",
      "Epoch 837/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5827 - acc: 0.6500\n",
      "Epoch 838/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5825 - acc: 0.6500\n",
      "Epoch 839/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5823 - acc: 0.6500\n",
      "Epoch 840/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5821 - acc: 0.6500\n",
      "Epoch 841/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5820 - acc: 0.6500\n",
      "Epoch 842/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5818 - acc: 0.6500\n",
      "Epoch 843/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5816 - acc: 0.6500\n",
      "Epoch 844/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5814 - acc: 0.6500\n",
      "Epoch 845/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5812 - acc: 0.6500\n",
      "Epoch 846/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5810 - acc: 0.6500\n",
      "Epoch 847/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5808 - acc: 0.7000\n",
      "Epoch 848/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5806 - acc: 0.7000\n",
      "Epoch 849/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5804 - acc: 0.7000\n",
      "Epoch 850/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5802 - acc: 0.7000\n",
      "Epoch 851/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5800 - acc: 0.7000\n",
      "Epoch 852/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5798 - acc: 0.7000\n",
      "Epoch 853/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5796 - acc: 0.7000\n",
      "Epoch 854/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5794 - acc: 0.7500\n",
      "Epoch 855/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5792 - acc: 0.7500\n",
      "Epoch 856/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5790 - acc: 0.7500\n",
      "Epoch 857/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5788 - acc: 0.7500\n",
      "Epoch 858/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5786 - acc: 0.7500\n",
      "Epoch 859/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5784 - acc: 0.7500\n",
      "Epoch 860/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5782 - acc: 0.8000\n",
      "Epoch 861/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5780 - acc: 0.8000\n",
      "Epoch 862/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5778 - acc: 0.8000\n",
      "Epoch 863/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5776 - acc: 0.8000\n",
      "Epoch 864/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5774 - acc: 0.8000\n",
      "Epoch 865/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5772 - acc: 0.8000\n",
      "Epoch 866/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5770 - acc: 0.8000\n",
      "Epoch 867/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5768 - acc: 0.8000\n",
      "Epoch 868/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5766 - acc: 0.8000\n",
      "Epoch 869/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5764 - acc: 0.8000\n",
      "Epoch 870/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5762 - acc: 0.8000\n",
      "Epoch 871/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5760 - acc: 0.8000\n",
      "Epoch 872/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5758 - acc: 0.8000\n",
      "Epoch 873/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5756 - acc: 0.8000\n",
      "Epoch 874/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5754 - acc: 0.8000\n",
      "Epoch 875/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5752 - acc: 0.8000\n",
      "Epoch 876/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5750 - acc: 0.8000\n",
      "Epoch 877/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5748 - acc: 0.8000\n",
      "Epoch 878/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5746 - acc: 0.8000\n",
      "Epoch 879/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5744 - acc: 0.8000\n",
      "Epoch 880/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5742 - acc: 0.8000\n",
      "Epoch 881/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5740 - acc: 0.8000\n",
      "Epoch 882/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5738 - acc: 0.8000\n",
      "Epoch 883/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5736 - acc: 0.8000\n",
      "Epoch 884/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5734 - acc: 0.8000\n",
      "Epoch 885/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5733 - acc: 0.8000\n",
      "Epoch 886/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5731 - acc: 0.8000\n",
      "Epoch 887/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5729 - acc: 0.8000\n",
      "Epoch 888/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5727 - acc: 0.8000\n",
      "Epoch 889/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5725 - acc: 0.8000\n",
      "Epoch 890/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5723 - acc: 0.8000\n",
      "Epoch 891/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5721 - acc: 0.8000\n",
      "Epoch 892/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5719 - acc: 0.8000\n",
      "Epoch 893/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5717 - acc: 0.8000\n",
      "Epoch 894/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5715 - acc: 0.8000\n",
      "Epoch 895/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5713 - acc: 0.8000\n",
      "Epoch 896/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5711 - acc: 0.8000\n",
      "Epoch 897/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5709 - acc: 0.8000\n",
      "Epoch 898/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5707 - acc: 0.8000\n",
      "Epoch 899/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5705 - acc: 0.8000\n",
      "Epoch 900/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5703 - acc: 0.8000\n",
      "Epoch 901/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5701 - acc: 0.8000\n",
      "Epoch 902/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5699 - acc: 0.8000\n",
      "Epoch 903/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5697 - acc: 0.8000\n",
      "Epoch 904/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5695 - acc: 0.8000\n",
      "Epoch 905/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.5693 - acc: 0.8000\n",
      "Epoch 906/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5691 - acc: 0.8000\n",
      "Epoch 907/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5689 - acc: 0.8000\n",
      "Epoch 908/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5687 - acc: 0.8000\n",
      "Epoch 909/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5685 - acc: 0.8000\n",
      "Epoch 910/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5683 - acc: 0.8000\n",
      "Epoch 911/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5681 - acc: 0.8000\n",
      "Epoch 912/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5679 - acc: 0.8000\n",
      "Epoch 913/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5677 - acc: 0.8000\n",
      "Epoch 914/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5675 - acc: 0.8000\n",
      "Epoch 915/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5673 - acc: 0.8000\n",
      "Epoch 916/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5671 - acc: 0.8000\n",
      "Epoch 917/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5668 - acc: 0.8000\n",
      "Epoch 918/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5666 - acc: 0.8000\n",
      "Epoch 919/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5664 - acc: 0.8000\n",
      "Epoch 920/1000\n",
      "20/20 [==============================] - 0s 250us/sample - loss: 0.5662 - acc: 0.8000\n",
      "Epoch 921/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5660 - acc: 0.8000\n",
      "Epoch 922/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5658 - acc: 0.8000\n",
      "Epoch 923/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5656 - acc: 0.8000\n",
      "Epoch 924/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5654 - acc: 0.8000\n",
      "Epoch 925/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5652 - acc: 0.8000\n",
      "Epoch 926/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5650 - acc: 0.8000\n",
      "Epoch 927/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5648 - acc: 0.8000\n",
      "Epoch 928/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5646 - acc: 0.8000\n",
      "Epoch 929/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5644 - acc: 0.8000\n",
      "Epoch 930/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5642 - acc: 0.8000\n",
      "Epoch 931/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.5640 - acc: 0.8000\n",
      "Epoch 932/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5638 - acc: 0.8000\n",
      "Epoch 933/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5636 - acc: 0.8000\n",
      "Epoch 934/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5634 - acc: 0.8000\n",
      "Epoch 935/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5632 - acc: 0.8000\n",
      "Epoch 936/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5630 - acc: 0.8000\n",
      "Epoch 937/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5628 - acc: 0.8000\n",
      "Epoch 938/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5626 - acc: 0.8000\n",
      "Epoch 939/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5624 - acc: 0.8000\n",
      "Epoch 940/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5622 - acc: 0.8000\n",
      "Epoch 941/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5620 - acc: 0.8000\n",
      "Epoch 942/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5618 - acc: 0.8000\n",
      "Epoch 943/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5616 - acc: 0.8000\n",
      "Epoch 944/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5614 - acc: 0.8000\n",
      "Epoch 945/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5612 - acc: 0.8000\n",
      "Epoch 946/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5610 - acc: 0.8500\n",
      "Epoch 947/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5608 - acc: 0.8500\n",
      "Epoch 948/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5606 - acc: 0.8500\n",
      "Epoch 949/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5604 - acc: 0.8500\n",
      "Epoch 950/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5602 - acc: 0.8500\n",
      "Epoch 951/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5600 - acc: 0.8500\n",
      "Epoch 952/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5598 - acc: 0.8500\n",
      "Epoch 953/1000\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.5596 - acc: 0.8500\n",
      "Epoch 954/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5594 - acc: 0.8500\n",
      "Epoch 955/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5592 - acc: 0.8500\n",
      "Epoch 956/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5590 - acc: 0.8500\n",
      "Epoch 957/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5588 - acc: 0.8500\n",
      "Epoch 958/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.5586 - acc: 0.8500\n",
      "Epoch 959/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5584 - acc: 0.8500\n",
      "Epoch 960/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5582 - acc: 0.8500\n",
      "Epoch 961/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5579 - acc: 0.8500\n",
      "Epoch 962/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5577 - acc: 0.8500\n",
      "Epoch 963/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5575 - acc: 0.8500\n",
      "Epoch 964/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5573 - acc: 0.8500\n",
      "Epoch 965/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5571 - acc: 0.8500\n",
      "Epoch 966/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5569 - acc: 0.8500\n",
      "Epoch 967/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5567 - acc: 0.8500\n",
      "Epoch 968/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5565 - acc: 0.8500\n",
      "Epoch 969/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5563 - acc: 0.8500\n",
      "Epoch 970/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5561 - acc: 0.8500\n",
      "Epoch 971/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5559 - acc: 0.8500\n",
      "Epoch 972/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5557 - acc: 0.8500\n",
      "Epoch 973/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5555 - acc: 0.8500\n",
      "Epoch 974/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5553 - acc: 0.8500\n",
      "Epoch 975/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5551 - acc: 0.8500\n",
      "Epoch 976/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5549 - acc: 0.8500\n",
      "Epoch 977/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5547 - acc: 0.8500\n",
      "Epoch 978/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5545 - acc: 0.8500\n",
      "Epoch 979/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5543 - acc: 0.8500\n",
      "Epoch 980/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5541 - acc: 0.8500\n",
      "Epoch 981/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5539 - acc: 0.8500\n",
      "Epoch 982/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5537 - acc: 0.8500\n",
      "Epoch 983/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5535 - acc: 0.8500\n",
      "Epoch 984/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5532 - acc: 0.8500\n",
      "Epoch 985/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5530 - acc: 0.8500\n",
      "Epoch 986/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5528 - acc: 0.8500\n",
      "Epoch 987/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.5526 - acc: 0.8500\n",
      "Epoch 988/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5524 - acc: 0.8500\n",
      "Epoch 989/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5522 - acc: 0.8500\n",
      "Epoch 990/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5520 - acc: 0.8500\n",
      "Epoch 991/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5518 - acc: 0.8500\n",
      "Epoch 992/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5516 - acc: 0.8500\n",
      "Epoch 993/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5514 - acc: 0.8500\n",
      "Epoch 994/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5512 - acc: 0.8500\n",
      "Epoch 995/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5510 - acc: 0.8500\n",
      "Epoch 996/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5508 - acc: 0.8500\n",
      "Epoch 997/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5506 - acc: 0.8500\n",
      "Epoch 998/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5504 - acc: 0.8500\n",
      "Epoch 999/1000\n",
      "20/20 [==============================] - 0s 0s/sample - loss: 0.5502 - acc: 0.8500\n",
      "Epoch 1000/1000\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.5500 - acc: 0.8500\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n",
      "boundary points finished.\n",
      "(70, 2)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01026177 1.01026071]]\n",
      "[[-3.859375 -3.875   ]]\n",
      "Optimal point distance: 5.525159294813364\n",
      "cf point distance: 5.9530754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_38064\\3996785700.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x, y = point[0], point[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_nn = nn_model()\n",
    "df[['x1', 'x2']] = df[['x1', 'x2']].astype('float64')\n",
    "df['y'] = df['y'].astype('int64')\n",
    "chosen_row=5\n",
    "nn, optimal_datapt = optimal_point(df, new_nn, desired_class=1, original_class=0, threshold=100, chosen_row=chosen_row, epsilon=0.01, plot=True)\n",
    "target_class=1\n",
    "plot_decision_boundary(nn, X_train.to_numpy(), y_train)\n",
    "cf = Counterfactual(nn, shape=shape, target_proba=target_proba, tol=tol,\n",
    "                    target_class=target_class, max_iter=max_iter)\n",
    "X_point = X_train.iloc[chosen_row,:]\n",
    "explainer = cf.explain(np.reshape(X_point, (1,-1)))\n",
    "cf_point = explainer.data['cf']['X'] \n",
    "points = [(X_point, cf_point)]\n",
    "plot_func(points)\n",
    "print(\"Optimal point distance:\", euclidean_distance(X_point, optimal_datapt))\n",
    "print(\"cf point distance:\", euclidean_distance(X_point, cf_point))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d3a5148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.500099   0.49990094]]\n"
     ]
    }
   ],
   "source": [
    "print(nn.predict(cf_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0919ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5009424 0.4990576]]\n"
     ]
    }
   ],
   "source": [
    "print(nn.predict(np.reshape(optimal_datapt, (1,-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "caca6082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Class counts:\n",
      " y\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 5 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_13932\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 641us/step - batch: 2.0000 - size: 1.0000 - loss: 0.7667 - acc: 0.5000\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 625us/step - batch: 2.0000 - size: 1.0000 - loss: 0.7438 - acc: 0.5200\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.7266 - acc: 0.5200\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.7141 - acc: 0.5000\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.7051 - acc: 0.5000\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6992 - acc: 0.5000\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6956 - acc: 0.4600\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6937 - acc: 0.4900\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6929 - acc: 0.5000\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6926 - acc: 0.5300\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.6923 - acc: 0.5000\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.6920 - acc: 0.5000\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6919 - acc: 0.5500\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6917 - acc: 0.5100\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6916 - acc: 0.5000\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6915 - acc: 0.4900\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6914 - acc: 0.5000\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6914 - acc: 0.5000\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6914 - acc: 0.5000\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6913 - acc: 0.5000\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6913 - acc: 0.5000\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6913 - acc: 0.5000\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6913 - acc: 0.5000\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6912 - acc: 0.4700\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6912 - acc: 0.4500\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6912 - acc: 0.4800\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6912 - acc: 0.5000\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6912 - acc: 0.4900\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6911 - acc: 0.5000\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6911 - acc: 0.5000\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6911 - acc: 0.5000\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6910 - acc: 0.5000\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6910 - acc: 0.5000\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6910 - acc: 0.5000\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6910 - acc: 0.5000\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.6909 - acc: 0.5000\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6909 - acc: 0.5000\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6909 - acc: 0.5000\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6908 - acc: 0.5000\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6908 - acc: 0.5000\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.6908 - acc: 0.5000\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 542us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6908 - acc: 0.5000\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6908 - acc: 0.5000\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6907 - acc: 0.5000\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6907 - acc: 0.5000\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6907 - acc: 0.5000\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6907 - acc: 0.5000\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6906 - acc: 0.5000\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6906 - acc: 0.5000\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6906 - acc: 0.5000\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6905 - acc: 0.5000\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6905 - acc: 0.5000\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6904 - acc: 0.5000\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6904 - acc: 0.5000\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6904 - acc: 0.5000\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6904 - acc: 0.5000\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6903 - acc: 0.5000\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6903 - acc: 0.5000\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6903 - acc: 0.5000\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6902 - acc: 0.5000\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6902 - acc: 0.5000\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6902 - acc: 0.5000\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6901 - acc: 0.5000\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6901 - acc: 0.5000\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6900 - acc: 0.5000\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 756us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6900 - acc: 0.5000\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6900 - acc: 0.5000\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6899 - acc: 0.5000\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.6899 - acc: 0.5000\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6898 - acc: 0.5000\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6898 - acc: 0.5000\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6898 - acc: 0.5000\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6897 - acc: 0.5000\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6897 - acc: 0.5000\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6896 - acc: 0.5000\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6896 - acc: 0.5000\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.6895 - acc: 0.5000\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6895 - acc: 0.5000\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6894 - acc: 0.5000\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6894 - acc: 0.5000\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6894 - acc: 0.5000\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6893 - acc: 0.5000\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 538us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6893 - acc: 0.5000\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6892 - acc: 0.5000\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6892 - acc: 0.5000\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6891 - acc: 0.5000\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6891 - acc: 0.5000\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6890 - acc: 0.5000\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6890 - acc: 0.5000\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6889 - acc: 0.5000\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6889 - acc: 0.5000\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6888 - acc: 0.5000\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6888 - acc: 0.5000\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6887 - acc: 0.5000\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6886 - acc: 0.5000\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6886 - acc: 0.5000\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6885 - acc: 0.5000\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6885 - acc: 0.5000\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6884 - acc: 0.5000\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6884 - acc: 0.5000\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6883 - acc: 0.5000\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6882 - acc: 0.5000\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6882 - acc: 0.5000\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6881 - acc: 0.5000\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6880 - acc: 0.5000\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6880 - acc: 0.5000\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6879 - acc: 0.5000\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6878 - acc: 0.5000\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6878 - acc: 0.5000\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6877 - acc: 0.5000\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6876 - acc: 0.5000\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6875 - acc: 0.5000\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 649us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6875 - acc: 0.5000\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6874 - acc: 0.5000\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6873 - acc: 0.5000\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 511us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6872 - acc: 0.5000\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6872 - acc: 0.5000\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6871 - acc: 0.5000\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6870 - acc: 0.5000\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6869 - acc: 0.5000\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6868 - acc: 0.5000\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6868 - acc: 0.5000\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 762us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6866 - acc: 0.5000\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6865 - acc: 0.5000\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6865 - acc: 0.5000\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6864 - acc: 0.5000\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6863 - acc: 0.5000\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6862 - acc: 0.5000\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6861 - acc: 0.5000\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6860 - acc: 0.5000\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6859 - acc: 0.5000\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6858 - acc: 0.5000\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6857 - acc: 0.5000\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.6857 - acc: 0.5000\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6856 - acc: 0.5000\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.6855 - acc: 0.5000\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.6854 - acc: 0.5000\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6853 - acc: 0.5000\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6852 - acc: 0.5000\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6851 - acc: 0.5000\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6850 - acc: 0.5000\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6849 - acc: 0.5000\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6848 - acc: 0.5000\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6846 - acc: 0.5000\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6845 - acc: 0.5000\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6844 - acc: 0.5000\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6842 - acc: 0.5000\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6841 - acc: 0.5000\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 766us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6840 - acc: 0.5000\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6838 - acc: 0.5000\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 763us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6836 - acc: 0.5000\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6834 - acc: 0.5000\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6832 - acc: 0.5000\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6830 - acc: 0.5000\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6828 - acc: 0.5000\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6826 - acc: 0.5000\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6823 - acc: 0.5000\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6820 - acc: 0.5000\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6817 - acc: 0.5000\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6813 - acc: 0.5000\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 625us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6809 - acc: 0.5000\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6805 - acc: 0.5000\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6800 - acc: 0.5000\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6795 - acc: 0.5500\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6789 - acc: 0.5500\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6783 - acc: 0.5500\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6768 - acc: 0.5500\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6716 - acc: 0.5500\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6637 - acc: 0.5400\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6538 - acc: 0.5500\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6461 - acc: 0.5800\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6399 - acc: 0.6100\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6341 - acc: 0.6500\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6281 - acc: 0.6500\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.6220 - acc: 0.6500\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6156 - acc: 0.6500\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6090 - acc: 0.6500\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.6020 - acc: 0.6500\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.5947 - acc: 0.6500\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.5869 - acc: 0.6800\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.5788 - acc: 0.7300\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.5701 - acc: 0.7900\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.5609 - acc: 0.8000\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 625us/step - batch: 2.0000 - size: 1.0000 - loss: 0.5512 - acc: 0.8000\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.5409 - acc: 0.8000\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 562us/step - batch: 2.0000 - size: 1.0000 - loss: 0.5299 - acc: 0.8000\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 762us/step - batch: 2.0000 - size: 1.0000 - loss: 0.5184 - acc: 0.8000\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.5062 - acc: 0.8300\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.4934 - acc: 0.8500\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.4800 - acc: 0.8500\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.4662 - acc: 0.8500\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.4520 - acc: 0.8700\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.4376 - acc: 0.9000\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.4232 - acc: 0.9000\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.4090 - acc: 0.9000\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.3955 - acc: 0.9000\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.3828 - acc: 0.9000\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.3708 - acc: 0.9000\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.3598 - acc: 0.9000\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.3498 - acc: 0.9000\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.3406 - acc: 0.9000\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.3323 - acc: 0.9000\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.3246 - acc: 0.9000\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.3176 - acc: 0.9000\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.3109 - acc: 0.9000\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 754us/step - batch: 2.0000 - size: 1.0000 - loss: 0.3044 - acc: 0.9000\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2981 - acc: 0.9000\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2920 - acc: 0.9000\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2861 - acc: 0.9000\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2804 - acc: 0.9000\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2748 - acc: 0.9000\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2695 - acc: 0.9000\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2644 - acc: 0.9000\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2595 - acc: 0.9000\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2547 - acc: 0.9000\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2502 - acc: 0.9000\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2459 - acc: 0.9500\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2418 - acc: 0.9500\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2378 - acc: 0.9500\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2340 - acc: 0.9500\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2304 - acc: 0.9500\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2269 - acc: 0.9500\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2236 - acc: 0.9500\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2204 - acc: 0.9500\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2174 - acc: 0.9500\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2144 - acc: 0.9500\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2117 - acc: 0.9500\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2090 - acc: 0.9500\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2065 - acc: 0.9500\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2041 - acc: 0.9500\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.2017 - acc: 0.9500\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1995 - acc: 0.9500\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1974 - acc: 0.9500\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 786us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1954 - acc: 0.9500\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1935 - acc: 0.9500\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1916 - acc: 0.9500\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1898 - acc: 0.9500\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1881 - acc: 0.9500\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1865 - acc: 0.9500\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1850 - acc: 0.9500\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1835 - acc: 0.9500\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1820 - acc: 0.9500\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1807 - acc: 0.9500\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1794 - acc: 0.9500\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1781 - acc: 0.9500\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1769 - acc: 0.9500\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1758 - acc: 0.9500\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1747 - acc: 0.9500\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1736 - acc: 0.9500\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1726 - acc: 0.9500\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1716 - acc: 0.9500\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1707 - acc: 0.9500\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1698 - acc: 0.9500\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 657us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1689 - acc: 0.9500\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1681 - acc: 0.9500\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 536us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1673 - acc: 0.9500\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1665 - acc: 0.9500\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1658 - acc: 0.9500\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1651 - acc: 0.9500\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1644 - acc: 0.9500\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1638 - acc: 0.9500\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1631 - acc: 0.9500\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1625 - acc: 0.9500\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1619 - acc: 0.9500\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1614 - acc: 0.9500\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1608 - acc: 0.9500\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1603 - acc: 0.9500\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1598 - acc: 0.9500\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1593 - acc: 0.9500\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1589 - acc: 0.9500\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1584 - acc: 0.9500\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1580 - acc: 0.9500\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1576 - acc: 0.9500\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1572 - acc: 0.9500\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1568 - acc: 0.9500\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1564 - acc: 0.9500\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1561 - acc: 0.9500\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 568us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1557 - acc: 0.9500\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1554 - acc: 0.9500\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1551 - acc: 0.9500\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1548 - acc: 0.9500\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1545 - acc: 0.9500\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1542 - acc: 0.9500\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1539 - acc: 0.9500\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1536 - acc: 0.9500\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1534 - acc: 0.9500\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1531 - acc: 0.9500\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1529 - acc: 0.9500\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1526 - acc: 0.9500\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1524 - acc: 0.9500\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1522 - acc: 0.9500\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1520 - acc: 0.9500\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1518 - acc: 0.9500\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1516 - acc: 0.9500\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1514 - acc: 0.9500\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1512 - acc: 0.9500\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1510 - acc: 0.9500\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1508 - acc: 0.9500\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1507 - acc: 0.9500\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1505 - acc: 0.9500\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1503 - acc: 0.9500\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1502 - acc: 0.9500\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1500 - acc: 0.9500\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1499 - acc: 0.9500\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1498 - acc: 0.9500\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1496 - acc: 0.9500\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1495 - acc: 0.9500\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1494 - acc: 0.9500\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1492 - acc: 0.9500\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1491 - acc: 0.9500\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1490 - acc: 0.9500\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1489 - acc: 0.9500\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1488 - acc: 0.9500\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1487 - acc: 0.9500\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1486 - acc: 0.9500\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1485 - acc: 0.9500\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1484 - acc: 0.9500\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1483 - acc: 0.9500\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1482 - acc: 0.9500\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1481 - acc: 0.9500\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1480 - acc: 0.9500\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1479 - acc: 0.9500\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1478 - acc: 0.9500\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1478 - acc: 0.9500\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 553us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1477 - acc: 0.9500\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1476 - acc: 0.9500\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1475 - acc: 0.9500\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1475 - acc: 0.9500\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1474 - acc: 0.9500\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1473 - acc: 0.9500\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1473 - acc: 0.9500\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1472 - acc: 0.9500\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1471 - acc: 0.9500\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1471 - acc: 0.9500\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1470 - acc: 0.9500\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1470 - acc: 0.9500\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1469 - acc: 0.9500\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1469 - acc: 0.9500\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1468 - acc: 0.9500\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 764us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1468 - acc: 0.9500\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1467 - acc: 0.9500\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1467 - acc: 0.9500\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1466 - acc: 0.9500\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1466 - acc: 0.9500\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1465 - acc: 0.9500\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1465 - acc: 0.9500\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1464 - acc: 0.9500\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 534us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1464 - acc: 0.9500\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1464 - acc: 0.9500\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1463 - acc: 0.9500\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1463 - acc: 0.9500\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1463 - acc: 0.9500\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1462 - acc: 0.9500\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1462 - acc: 0.9500\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1462 - acc: 0.9500\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1461 - acc: 0.9500\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1461 - acc: 0.9500\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1461 - acc: 0.9500\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1460 - acc: 0.9500\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1460 - acc: 0.9500\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1460 - acc: 0.9500\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1460 - acc: 0.9500\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1459 - acc: 0.9500\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1459 - acc: 0.9500\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1459 - acc: 0.9500\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1459 - acc: 0.9500\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1458 - acc: 0.9500\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 516us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1458 - acc: 0.9500\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1458 - acc: 0.9500\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1458 - acc: 0.9500\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1457 - acc: 0.9500\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1457 - acc: 0.9500\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1457 - acc: 0.9500\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1457 - acc: 0.9500\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1457 - acc: 0.9500\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 896us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1456 - acc: 0.9500\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1456 - acc: 0.9500\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1456 - acc: 0.9500\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1456 - acc: 0.9500\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1456 - acc: 0.9500\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1456 - acc: 0.9500\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1456 - acc: 0.9500\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1455 - acc: 0.9500\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1455 - acc: 0.9500\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1455 - acc: 0.9500\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1455 - acc: 0.9500\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1455 - acc: 0.9500\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1455 - acc: 0.9500\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1455 - acc: 0.9500\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1454 - acc: 0.9500\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1454 - acc: 0.9500\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1454 - acc: 0.9500\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1454 - acc: 0.9500\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1454 - acc: 0.9500\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1454 - acc: 0.9500\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1454 - acc: 0.9500\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1454 - acc: 0.9500\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1454 - acc: 0.9500\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 645us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 797us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 656us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 646us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 546us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1453 - acc: 0.9500\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 533us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 669us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 642us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 783us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1451 - acc: 0.9500\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 766us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 793us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 516us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 515us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1450 - acc: 0.9500\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 787us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 509us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 786us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 765us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 645us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 554us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 535us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 534us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 787us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 885us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 647us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 672us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 652us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 765us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 392us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 502us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 765us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1449 - acc: 0.9500\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Model training complete.\n",
      "boundary points started generation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(90, 2)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.05047014 1.05021004]]\n",
      "[[-2.234375 -5.      ]]\n",
      "0\n",
      "1\n",
      "Class counts:\n",
      " y\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 5 samples\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 502us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 43/1000\n",
      "1/5 [=====>........................] - ETA: 0s - batch: 0.0000e+00 - size: 1.0000 - loss: 0.1448 - acc: 0.9500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_13932\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 498us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 529us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 811us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 250us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 610us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 792us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 766us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 748us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 824us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 677us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 790us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 659us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 754us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 757us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 516us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 529us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 910us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 898us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 610us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 647us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 762us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 787us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 534us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 898us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 961us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 537us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 926us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 674us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 646us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 647us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 640us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 894us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 503us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 625us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 795us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 554us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 539us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 786us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 503us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 639us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 654us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 534us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "boundary points finished.\n",
      "(90, 2)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.04606188 1.04889952]]\n",
      "[[0.265625 0.953125]]\n",
      "0\n",
      "1\n",
      "Class counts:\n",
      " y\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 5 samples\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 510us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 787us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 797us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_13932\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 537us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 849us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 531us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 765us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 625us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 766us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 549us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 511us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 534us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 625us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 537us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 783us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 786us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 752us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 766us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 878us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 529us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 658us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 673us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 908us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 545us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 799us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 632us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 756us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 640us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 510us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 765us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 895us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 765us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 878us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 788us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 502us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 752us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 878us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 814us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 644us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 655us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 628us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 890us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 651us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 625us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "boundary points finished.\n",
      "(90, 2)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.05029226 1.05023751]]\n",
      "[[-3.59375  -4.421875]]\n",
      "0\n",
      "1\n",
      "Class counts:\n",
      " y\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 5 samples\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 42/1000\n",
      "1/5 [=====>........................] - ETA: 0s - batch: 0.0000e+00 - size: 1.0000 - loss: 0.1448 - acc: 0.9500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_13932\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 998us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 516us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 250us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 766us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 766us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 529us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 376us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 791us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 921us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 651us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 789us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 673us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 642us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 510us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 747us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 515us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 759us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 745us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 511us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 657us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 765us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 732us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 647us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 535us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 904us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 514us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 644us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 757us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 533us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 907us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 661us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 807us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 511us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 644us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 649us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 646us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 661us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 511us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 765us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 648us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 902us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 788us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 396us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 623us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 756us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "boundary points finished.\n",
      "(90, 2)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.05061406 1.05026673]]\n",
      "[[-1.7109375 -3.9375   ]]\n",
      "0\n",
      "1\n",
      "Class counts:\n",
      " y\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 5 samples\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 531us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_13932\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 569us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 529us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 505us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 628us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 503us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 792us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 742us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 529us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 731us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 579us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 606us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 834us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 497us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 788us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 762us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 763us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 791us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 831us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 648us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 659us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 914us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 792us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 566us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 644us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 890us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 761us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 504us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 761us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 798us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 783us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 812us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 503us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 654us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 531us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 763us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 658us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 845us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 753us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 761us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 864us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 641us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 923us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 639us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 644us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 655us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 630us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 643us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 537us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "boundary points finished.\n",
      "(90, 2)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.05076419 1.05038858]]\n",
      "[[-1.375    -2.703125]]\n",
      "0\n",
      "1\n",
      "Class counts:\n",
      " y\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 5 samples\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 600us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 509us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 37/1000\n",
      "1/5 [=====>........................] - ETA: 0s - batch: 0.0000e+00 - size: 1.0000 - loss: 0.1448 - acc: 0.9500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_13932\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 787us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 766us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 590us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 875us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 529us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 529us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 506us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 799us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 997us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 878us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 823us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 752us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 628us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 670us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 662us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 906us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 901us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 654us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 670us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 761us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 534us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 786us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 633us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 787us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 794us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 763us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 796us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 829us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 754us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 815us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 874us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 875us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 856us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 426us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 823us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 940us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 341us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 382us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 635us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 348us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 410us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 368us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 470us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 797us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 764us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 802us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 786us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 818us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 685us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 688us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 383us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 649us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 386us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 653us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 250us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 884us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 739us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 384us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 491us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 757us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 885us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 502us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 590us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 918us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 761us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 794us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 386us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 878us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 754us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 603us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 783us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 790us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 787us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 629us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 897us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 752us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 625us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 752us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 625us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 609us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "boundary points finished.\n",
      "(90, 2)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.05082015 1.05038414]]\n",
      "[[-1.28125  -2.734375]]\n",
      "0\n",
      "1\n",
      "Class counts:\n",
      " y\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 5 samples\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 743us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 747us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_13932\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 901us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 834us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 644us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 802us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 644us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 889us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 786us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 902us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 649us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 764us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 612us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 793us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 868us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 589us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 905us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 657us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 541us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 541us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 901us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 546us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 843us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 672us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 630us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 887us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 650us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 806us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 787us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 861us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 765us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 903us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 752us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 993us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 875us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 739us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 799us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 748us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 738us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 765us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 2ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 649us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 644us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 787us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 646us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "boundary points finished.\n",
      "(90, 2)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.05181936 1.05062841]]\n",
      "[[-0.578125 -1.671875]]\n",
      "0\n",
      "1\n",
      "Class counts:\n",
      " y\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 5 samples\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_13932\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 533us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 681us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 645us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 904us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 652us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 515us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 515us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 639us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 502us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 502us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 535us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 561us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 752us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 898us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 822us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 783us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 748us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 787us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 529us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 549us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 763us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 507us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 758us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 498us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 656us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 905us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 505us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 786us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 616us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 529us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 577us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 790us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 753us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 788us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 578us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 644us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 646us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 516us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 640us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 657us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 657us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 798us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 534us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 531us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 510us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 539us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 534us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 529us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 534us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 683us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 766us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 551us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 904us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 798us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 878us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "boundary points finished.\n",
      "(90, 2)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.05066577 1.05028604]]\n",
      "[[-1.578125 -3.671875]]\n",
      "0\n",
      "1\n",
      "Class counts:\n",
      " y\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 5 samples\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 766us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_13932\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 913us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 763us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 591us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 761us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 765us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 765us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 514us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 752us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 655us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 582us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 625us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 906us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 739us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 649us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 909us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 649us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 651us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 805us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 649us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 502us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 752us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 643us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 982us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 826us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 514us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 461us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 866us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 417us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 844us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 862us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 860us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 948us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 812us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 865us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 446us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 853us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 419us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 439us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 848us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 688us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 529us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 916us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 744us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 633us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 531us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 766us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 555us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 752us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 902us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 651us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 502us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 667us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 531us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 533us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 814us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 376us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 899us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 815us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 979us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 647us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 791us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 913us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 382us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 891us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 542us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 515us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 617us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 612us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "boundary points finished.\n",
      "(90, 2)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.05032791 1.05018215]]\n",
      "[[-3.203125 -5.765625]]\n",
      "0\n",
      "1\n",
      "Class counts:\n",
      " y\n",
      "0    10\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 5 samples\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 34/1000\n",
      "1/5 [=====>........................] - ETA: 0s - batch: 0.0000e+00 - size: 1.0000 - loss: 0.1448 - acc: 0.9500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_13932\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 781us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 691us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 865us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 658us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 498us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 498us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 898us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 527us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 530us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 541us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 498us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 797us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 646us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 646us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 515us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 642us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 677us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 761us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 999us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 556us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 790us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 909us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 517us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 515us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 649us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 516us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 876us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 531us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 516us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 800us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 516us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 877us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 524us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 519us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 528us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 786us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 647us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 920us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 649us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 926us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 732us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 778us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 499us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 895us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 543us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 858us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 645us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 752us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 498us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 763us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 773us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 526us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 784us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 516us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 779us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 769us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 518us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 815us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 782us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 520us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 626us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 525us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 749us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 770us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 521us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 627us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 771us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 788us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 775us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 751us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 774us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 532us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 523us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 507us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 825us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 783us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 780us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 501us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 767us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 776us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 785us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 768us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 500us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 772us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 1000us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 786us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 777us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 750us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 522us/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 1ms/step - batch: 2.0000 - size: 1.0000 - loss: 0.1448 - acc: 0.9500\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "boundary points finished.\n",
      "(90, 2)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.05040743 1.05018516]]\n",
      "[[-2.578125 -5.671875]]\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "nn=nn_model()\n",
    "optimal_dists, wachter_dists = [], []\n",
    "optimal_probs,  wachter_probs = [], [] \n",
    "inv_map = { \n",
    "    0: 1, \n",
    "    1: 0\n",
    "}\n",
    "df[['x1', 'x2']] = df[['x1', 'x2']].astype('float64')\n",
    "for i in range(df.shape[0]):\n",
    "    X_point = df.iloc[i,:-1]\n",
    "    y_point = df.iloc[i,-1]\n",
    "    y_label = int(y_point.item())\n",
    "    target_label = inv_map[y_label]\n",
    "    print(y_label) \n",
    "    print(target_label)\n",
    "    if y_label == 0:\n",
    "        nn, optimal_datapt = optimal_point(df, nn, desired_class=inv_map[y_label], original_class=y_label, threshold=50000, chosen_row=i, epsilon=0.05)\n",
    "\n",
    "        target_class=target_label\n",
    "        explainer2 = Counterfactual(nn, shape=shape, target_proba=target_proba, tol=tol,\n",
    "                                target_class=target_class)\n",
    "        #print(np.reshape(X_point, (1,-1)).shape)\n",
    "        cf = explainer2.explain(np.reshape(X_point, (1,-1)))\n",
    "        cf_point = cf.data['cf']['X'] \n",
    "        cf_pt_probs = nn.predict(np.reshape(cf_point, (1,-1)))\n",
    "        opt_pt_probs = nn.predict(np.reshape(optimal_datapt, (1,-1)))\n",
    "        optimal_probs.append(opt_pt_probs)\n",
    "        wachter_probs.append(cf_pt_probs)\n",
    "        optimal_dists.append(euclidean_distance(X_point, optimal_datapt))\n",
    "        wachter_dists.append(euclidean_distance(X_point, cf_point))\n",
    "        # print(cf_point)\n",
    "        # print(income_nn.predict(np.reshape(X_point, (1,-1))))\n",
    "        # print(\"DISTANCE:\", euclidean_distance(X_point, cf_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "307ae745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3167593470051395 4.522210562357206\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(optimal_dists), np.mean(wachter_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9308e3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4488957 0.5511043]] [[0.50675935 0.49324068]]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(optimal_probs,axis=0), np.mean(wachter_probs,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97b7698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_columns(df): \n",
    "    inv_col_map = {} \n",
    "\n",
    "    for col in df.columns: \n",
    "        any_string = df[col].apply(lambda x: isinstance(x, str)).any()\n",
    "\n",
    "        if not any_string: \n",
    "            df[col] = df[col].astype('float64')\n",
    "        else: \n",
    "            inv_col_map[col] = {}\n",
    "            unique_vals = np.unique(df[col])\n",
    "\n",
    "            for i, val in enumerate(unique_vals): \n",
    "                inv_col_map[col][i] = val \n",
    "                df.loc[df[col] == val, col] = i\n",
    "\n",
    "            df[col] = df[col].astype('int32')\n",
    "\n",
    "    return inv_col_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d61e19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()  # For TensorFlow 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c20c445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\dice_ml\\utils\\helpers.py:79: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  adult_data = adult_data.replace({'income': {'<=50K': 0, '>50K': 1}})\n"
     ]
    }
   ],
   "source": [
    "dataset = helpers.load_adult_income_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4da8de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset[\"income\"]\n",
    "# Split data into train and test\n",
    "datasetX = dataset.drop(\"income\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d59d3659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 9)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "379bdf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    x_in = Input(shape=(8,))\n",
    "\n",
    "    x = Flatten()(x_in)\n",
    "    x = Dense(8, activation='relu')(x)\n",
    "    x = Dense(10, activation='relu')(x) \n",
    "    probs = Dense(2, activation='softmax')(x)\n",
    "    nn = Model(inputs=x_in, outputs=probs)\n",
    "    nn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a9d4784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Assoc</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Single</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Single</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age      workclass     education marital_status    occupation   race  \\\n",
       "0   28        Private     Bachelors         Single  White-Collar  White   \n",
       "1   30  Self-Employed         Assoc        Married  Professional  White   \n",
       "2   32        Private  Some-college        Married  White-Collar  White   \n",
       "3   20        Private  Some-college         Single       Service  White   \n",
       "4   41  Self-Employed  Some-college        Married  White-Collar  White   \n",
       "5   40        Private  Some-college       Divorced   Blue-Collar  White   \n",
       "6   24        Private     Bachelors         Single  White-Collar  White   \n",
       "7   54        Private         Assoc        Married       Service  Other   \n",
       "8   27        Private  Some-college         Single       Service  White   \n",
       "9   57        Private  Some-college        Married  Professional  White   \n",
       "\n",
       "   gender  hours_per_week  income  \n",
       "0  Female              60       0  \n",
       "1    Male              65       1  \n",
       "2    Male              50       0  \n",
       "3  Female              35       0  \n",
       "4    Male              50       0  \n",
       "5    Male              50       0  \n",
       "6    Male              40       0  \n",
       "7    Male              38       1  \n",
       "8    Male              40       0  \n",
       "9    Male              40       1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "baa1dae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          28\n",
       "workclass         Other/Unknown\n",
       "education                 Assoc\n",
       "marital_status        Separated\n",
       "occupation        Other/Unknown\n",
       "race                      White\n",
       "gender                   Female\n",
       "hours_per_week               40\n",
       "income                        0\n",
       "Name: 25954, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[25954,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a979423c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                         32\n",
       "workclass              Private\n",
       "education         Some-college\n",
       "marital_status         Married\n",
       "occupation        White-Collar\n",
       "race                     White\n",
       "gender                    Male\n",
       "hours_per_week              50\n",
       "income                       0\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "008b7421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n"
     ]
    }
   ],
   "source": [
    "shape = (1,) + datasetX.shape[1:]\n",
    "print(shape)\n",
    "target_proba = 0.5\n",
    "tol = 0.0001 # want counterfactuals with p(class)>0.99\n",
    "target_class = 'other' # any class other than 7 will do\n",
    "max_iter = 1000\n",
    "lam_init = 1e-1\n",
    "max_lam_steps = 10\n",
    "learning_rate_init = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a27d5f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " income\n",
      "0    19820\n",
      "1    19820\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 10000 samples\n",
      "Epoch 1/1000\n",
      " 3552/10000 [=========>....................] - ETA: 0s - loss: 1.3025 - acc: 0.5403"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\drexel_research_2024_2025\\Docs\\files\\common_functions.py:422: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 15us/sample - loss: 0.8885 - acc: 0.6031\n",
      "Epoch 2/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.6066 - acc: 0.6794\n",
      "Epoch 3/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5820 - acc: 0.6989\n",
      "Epoch 4/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5709 - acc: 0.7037\n",
      "Epoch 5/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5671 - acc: 0.7099\n",
      "Epoch 6/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5630 - acc: 0.7062\n",
      "Epoch 7/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5596 - acc: 0.7071\n",
      "Epoch 8/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5544 - acc: 0.7090\n",
      "Epoch 9/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5536 - acc: 0.7057\n",
      "Epoch 10/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5503 - acc: 0.7144\n",
      "Epoch 11/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5500 - acc: 0.7110\n",
      "Epoch 12/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5452 - acc: 0.7122\n",
      "Epoch 13/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5460 - acc: 0.7132\n",
      "Epoch 14/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5435 - acc: 0.7148\n",
      "Epoch 15/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5423 - acc: 0.7162\n",
      "Epoch 16/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5388 - acc: 0.7161\n",
      "Epoch 17/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5392 - acc: 0.7159\n",
      "Epoch 18/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5358 - acc: 0.7171\n",
      "Epoch 19/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5355 - acc: 0.7174\n",
      "Epoch 20/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5346 - acc: 0.7196\n",
      "Epoch 21/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5308 - acc: 0.7189\n",
      "Epoch 22/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5288 - acc: 0.7233\n",
      "Epoch 23/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5250 - acc: 0.7250\n",
      "Epoch 24/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5226 - acc: 0.7288\n",
      "Epoch 25/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5243 - acc: 0.7259\n",
      "Epoch 26/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5170 - acc: 0.7316\n",
      "Epoch 27/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5144 - acc: 0.7393\n",
      "Epoch 28/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5055 - acc: 0.7473\n",
      "Epoch 29/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5035 - acc: 0.7465\n",
      "Epoch 30/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5013 - acc: 0.7553\n",
      "Epoch 31/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4982 - acc: 0.7549\n",
      "Epoch 32/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4947 - acc: 0.7596\n",
      "Epoch 33/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4964 - acc: 0.7597\n",
      "Epoch 34/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4945 - acc: 0.7598\n",
      "Epoch 35/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4966 - acc: 0.7616\n",
      "Epoch 36/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4922 - acc: 0.7626\n",
      "Epoch 37/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4916 - acc: 0.7632\n",
      "Epoch 38/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4897 - acc: 0.7635\n",
      "Epoch 39/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4913 - acc: 0.7675\n",
      "Epoch 40/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4900 - acc: 0.7648\n",
      "Epoch 41/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4888 - acc: 0.7686\n",
      "Epoch 42/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4880 - acc: 0.7671\n",
      "Epoch 43/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4881 - acc: 0.7663\n",
      "Epoch 44/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4906 - acc: 0.7640\n",
      "Epoch 45/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4867 - acc: 0.7678\n",
      "Epoch 46/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4877 - acc: 0.7698\n",
      "Epoch 47/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4877 - acc: 0.7677\n",
      "Epoch 48/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4871 - acc: 0.7662\n",
      "Epoch 49/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4857 - acc: 0.7717\n",
      "Epoch 50/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4870 - acc: 0.7669\n",
      "Epoch 51/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4880 - acc: 0.7696\n",
      "Epoch 52/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4855 - acc: 0.7704\n",
      "Epoch 53/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4867 - acc: 0.7677\n",
      "Epoch 54/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4860 - acc: 0.7688\n",
      "Epoch 55/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4854 - acc: 0.7676\n",
      "Epoch 56/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4853 - acc: 0.7706\n",
      "Epoch 57/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4864 - acc: 0.7689\n",
      "Epoch 58/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4871 - acc: 0.7684\n",
      "Epoch 59/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4839 - acc: 0.7708\n",
      "Epoch 60/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4864 - acc: 0.7671\n",
      "Epoch 61/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4865 - acc: 0.7674\n",
      "Epoch 62/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4837 - acc: 0.7698\n",
      "Epoch 63/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4870 - acc: 0.7677\n",
      "Epoch 64/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4861 - acc: 0.7673\n",
      "Epoch 65/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4855 - acc: 0.7705\n",
      "Epoch 66/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4847 - acc: 0.7721\n",
      "Epoch 67/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4853 - acc: 0.7673\n",
      "Epoch 68/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4865 - acc: 0.7670\n",
      "Epoch 69/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4851 - acc: 0.7696\n",
      "Epoch 70/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4843 - acc: 0.7716\n",
      "Epoch 71/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4838 - acc: 0.7710\n",
      "Epoch 72/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4850 - acc: 0.7690\n",
      "Epoch 73/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4852 - acc: 0.7692\n",
      "Epoch 74/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4847 - acc: 0.7691\n",
      "Epoch 75/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4868 - acc: 0.7685\n",
      "Epoch 76/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4854 - acc: 0.7693\n",
      "Epoch 77/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4826 - acc: 0.7686\n",
      "Epoch 78/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4861 - acc: 0.7695\n",
      "Epoch 79/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4845 - acc: 0.7697\n",
      "Epoch 80/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4821 - acc: 0.7683\n",
      "Epoch 81/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4820 - acc: 0.7712\n",
      "Epoch 82/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4850 - acc: 0.7695\n",
      "Epoch 83/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4832 - acc: 0.7725\n",
      "Epoch 84/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4837 - acc: 0.7705\n",
      "Epoch 85/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4839 - acc: 0.7682\n",
      "Epoch 86/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4824 - acc: 0.7700\n",
      "Epoch 87/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4821 - acc: 0.7724\n",
      "Epoch 88/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4837 - acc: 0.7720\n",
      "Epoch 89/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4814 - acc: 0.7724\n",
      "Epoch 90/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4823 - acc: 0.7712\n",
      "Epoch 91/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4822 - acc: 0.7702\n",
      "Epoch 92/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4828 - acc: 0.7701\n",
      "Epoch 93/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4836 - acc: 0.7686\n",
      "Epoch 94/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4808 - acc: 0.7729\n",
      "Epoch 95/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4859 - acc: 0.7668\n",
      "Epoch 96/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4834 - acc: 0.7693\n",
      "Epoch 97/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4814 - acc: 0.7701\n",
      "Epoch 98/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4822 - acc: 0.7712\n",
      "Epoch 99/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4806 - acc: 0.7704\n",
      "Epoch 100/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4796 - acc: 0.7726\n",
      "Epoch 101/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4821 - acc: 0.7727\n",
      "Epoch 102/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4813 - acc: 0.7709\n",
      "Epoch 103/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4809 - acc: 0.7701\n",
      "Epoch 104/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4806 - acc: 0.7693\n",
      "Epoch 105/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4815 - acc: 0.7717\n",
      "Epoch 106/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4807 - acc: 0.7715\n",
      "Epoch 107/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4831 - acc: 0.7693\n",
      "Epoch 108/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4798 - acc: 0.7711\n",
      "Epoch 109/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4795 - acc: 0.7711\n",
      "Epoch 110/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4806 - acc: 0.7702\n",
      "Epoch 111/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4825 - acc: 0.7715\n",
      "Epoch 112/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4807 - acc: 0.7686\n",
      "Epoch 113/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4787 - acc: 0.7719\n",
      "Epoch 114/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4823 - acc: 0.7702\n",
      "Epoch 115/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4798 - acc: 0.7703\n",
      "Epoch 116/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4804 - acc: 0.7708\n",
      "Epoch 117/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4799 - acc: 0.7708\n",
      "Epoch 118/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4802 - acc: 0.7710\n",
      "Epoch 119/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4817 - acc: 0.7719\n",
      "Epoch 120/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4817 - acc: 0.7707\n",
      "Epoch 121/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4801 - acc: 0.7708\n",
      "Epoch 122/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4799 - acc: 0.7704\n",
      "Epoch 123/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4804 - acc: 0.7720\n",
      "Epoch 124/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4795 - acc: 0.7713\n",
      "Epoch 125/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4789 - acc: 0.7701\n",
      "Epoch 126/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4792 - acc: 0.7714\n",
      "Epoch 127/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4808 - acc: 0.7692\n",
      "Epoch 128/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4796 - acc: 0.7693\n",
      "Epoch 129/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4815 - acc: 0.7703\n",
      "Epoch 130/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4788 - acc: 0.7690\n",
      "Epoch 131/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4805 - acc: 0.7712\n",
      "Epoch 132/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4805 - acc: 0.7703\n",
      "Epoch 133/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4814 - acc: 0.7717\n",
      "Epoch 134/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4780 - acc: 0.7697\n",
      "Epoch 135/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4784 - acc: 0.7706\n",
      "Epoch 136/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4782 - acc: 0.7730\n",
      "Epoch 137/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4792 - acc: 0.7716\n",
      "Epoch 138/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4792 - acc: 0.7702\n",
      "Epoch 139/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4783 - acc: 0.7740\n",
      "Epoch 140/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4803 - acc: 0.7726\n",
      "Epoch 141/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4799 - acc: 0.7727\n",
      "Epoch 142/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4793 - acc: 0.7716\n",
      "Epoch 143/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4792 - acc: 0.7712\n",
      "Epoch 144/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4778 - acc: 0.7724\n",
      "Epoch 145/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4801 - acc: 0.7715\n",
      "Epoch 146/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4812 - acc: 0.7673\n",
      "Epoch 147/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4793 - acc: 0.7711\n",
      "Epoch 148/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4795 - acc: 0.7695\n",
      "Epoch 149/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4781 - acc: 0.7739\n",
      "Epoch 150/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4791 - acc: 0.7732\n",
      "Epoch 151/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4798 - acc: 0.7718\n",
      "Epoch 152/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4809 - acc: 0.7719\n",
      "Epoch 153/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4795 - acc: 0.7727\n",
      "Epoch 154/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4789 - acc: 0.7723\n",
      "Epoch 155/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4783 - acc: 0.7738\n",
      "Epoch 156/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4792 - acc: 0.7726\n",
      "Epoch 157/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4813 - acc: 0.7682\n",
      "Epoch 158/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4773 - acc: 0.7759\n",
      "Epoch 159/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4793 - acc: 0.7725\n",
      "Epoch 160/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4782 - acc: 0.7692\n",
      "Epoch 161/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4785 - acc: 0.7712\n",
      "Epoch 162/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4775 - acc: 0.7745\n",
      "Epoch 163/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4788 - acc: 0.7717\n",
      "Epoch 164/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4801 - acc: 0.7709\n",
      "Epoch 165/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4796 - acc: 0.7699\n",
      "Epoch 166/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4783 - acc: 0.7708\n",
      "Epoch 167/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4790 - acc: 0.7720\n",
      "Epoch 168/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4786 - acc: 0.7717\n",
      "Epoch 169/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4798 - acc: 0.7711\n",
      "Epoch 170/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4794 - acc: 0.7710\n",
      "Epoch 171/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4781 - acc: 0.7729\n",
      "Epoch 172/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4791 - acc: 0.7691\n",
      "Epoch 173/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4790 - acc: 0.7725\n",
      "Epoch 174/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4789 - acc: 0.7718\n",
      "Epoch 175/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4806 - acc: 0.7707\n",
      "Epoch 176/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4782 - acc: 0.7706\n",
      "Epoch 177/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4787 - acc: 0.7691\n",
      "Epoch 178/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4778 - acc: 0.7708\n",
      "Epoch 179/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4787 - acc: 0.7705\n",
      "Epoch 180/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4771 - acc: 0.7713\n",
      "Epoch 181/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4795 - acc: 0.7711\n",
      "Epoch 182/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4777 - acc: 0.7718\n",
      "Epoch 183/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4771 - acc: 0.7696\n",
      "Epoch 184/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4775 - acc: 0.7718\n",
      "Epoch 185/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4790 - acc: 0.7708\n",
      "Epoch 186/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4771 - acc: 0.7721\n",
      "Epoch 187/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4780 - acc: 0.7711\n",
      "Epoch 188/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4765 - acc: 0.7721\n",
      "Epoch 189/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4773 - acc: 0.7724\n",
      "Epoch 190/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4764 - acc: 0.7733\n",
      "Epoch 191/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4772 - acc: 0.7721\n",
      "Epoch 192/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4778 - acc: 0.7720\n",
      "Epoch 193/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4764 - acc: 0.7720\n",
      "Epoch 194/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4769 - acc: 0.7716\n",
      "Epoch 195/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4770 - acc: 0.7735\n",
      "Epoch 196/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4758 - acc: 0.7738\n",
      "Epoch 197/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4766 - acc: 0.7732\n",
      "Epoch 198/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4753 - acc: 0.7724\n",
      "Epoch 199/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4769 - acc: 0.7712\n",
      "Epoch 200/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4747 - acc: 0.7728\n",
      "Epoch 201/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4767 - acc: 0.7739\n",
      "Epoch 202/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4763 - acc: 0.7718\n",
      "Epoch 203/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4755 - acc: 0.7722\n",
      "Epoch 204/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4758 - acc: 0.7723\n",
      "Epoch 205/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4749 - acc: 0.7727\n",
      "Epoch 206/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4746 - acc: 0.7725\n",
      "Epoch 207/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4752 - acc: 0.7734\n",
      "Epoch 208/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4752 - acc: 0.7719\n",
      "Epoch 209/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4763 - acc: 0.7699\n",
      "Epoch 210/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4756 - acc: 0.7705\n",
      "Epoch 211/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4750 - acc: 0.7724\n",
      "Epoch 212/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4740 - acc: 0.7774\n",
      "Epoch 213/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4745 - acc: 0.7763\n",
      "Epoch 214/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4739 - acc: 0.7730\n",
      "Epoch 215/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4760 - acc: 0.7741\n",
      "Epoch 216/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4742 - acc: 0.7721\n",
      "Epoch 217/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4766 - acc: 0.7714\n",
      "Epoch 218/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4763 - acc: 0.7713\n",
      "Epoch 219/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4750 - acc: 0.7700\n",
      "Epoch 220/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4762 - acc: 0.7741\n",
      "Epoch 221/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4761 - acc: 0.7711\n",
      "Epoch 222/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4745 - acc: 0.7715\n",
      "Epoch 223/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4740 - acc: 0.7734\n",
      "Epoch 224/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4750 - acc: 0.7733\n",
      "Epoch 225/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4762 - acc: 0.7719\n",
      "Epoch 226/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4746 - acc: 0.7728\n",
      "Epoch 227/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4764 - acc: 0.7739\n",
      "Epoch 228/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4757 - acc: 0.7731\n",
      "Epoch 229/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4741 - acc: 0.7731\n",
      "Epoch 230/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4761 - acc: 0.7743\n",
      "Epoch 231/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4731 - acc: 0.7745\n",
      "Epoch 232/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4759 - acc: 0.7737\n",
      "Epoch 233/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4740 - acc: 0.7742\n",
      "Epoch 234/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4745 - acc: 0.7742\n",
      "Epoch 235/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4739 - acc: 0.7731\n",
      "Epoch 236/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4744 - acc: 0.7728\n",
      "Epoch 237/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4754 - acc: 0.7736\n",
      "Epoch 238/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4742 - acc: 0.7736\n",
      "Epoch 239/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4731 - acc: 0.7751\n",
      "Epoch 240/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4742 - acc: 0.7741\n",
      "Epoch 241/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4757 - acc: 0.7713\n",
      "Epoch 242/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4752 - acc: 0.7739\n",
      "Epoch 243/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4728 - acc: 0.7722\n",
      "Epoch 244/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4738 - acc: 0.7731\n",
      "Epoch 245/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4736 - acc: 0.7712\n",
      "Epoch 246/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4746 - acc: 0.7724\n",
      "Epoch 247/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4756 - acc: 0.7730\n",
      "Epoch 248/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4749 - acc: 0.7732\n",
      "Epoch 249/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4744 - acc: 0.7727\n",
      "Epoch 250/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4747 - acc: 0.7725\n",
      "Epoch 251/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4723 - acc: 0.7755\n",
      "Epoch 252/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4731 - acc: 0.7751\n",
      "Epoch 253/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4720 - acc: 0.7740\n",
      "Epoch 254/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4746 - acc: 0.7705\n",
      "Epoch 255/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4729 - acc: 0.7737\n",
      "Epoch 256/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4733 - acc: 0.7732\n",
      "Epoch 257/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4725 - acc: 0.7754\n",
      "Epoch 258/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4729 - acc: 0.7728\n",
      "Epoch 259/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4737 - acc: 0.7721\n",
      "Epoch 260/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4739 - acc: 0.7737\n",
      "Epoch 261/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4740 - acc: 0.7739\n",
      "Epoch 262/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4734 - acc: 0.7724\n",
      "Epoch 263/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4736 - acc: 0.7752\n",
      "Epoch 264/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4728 - acc: 0.7726\n",
      "Epoch 265/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4738 - acc: 0.7748\n",
      "Epoch 266/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4754 - acc: 0.7718\n",
      "Epoch 267/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4728 - acc: 0.7742\n",
      "Epoch 268/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4739 - acc: 0.7725\n",
      "Epoch 269/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4738 - acc: 0.7713\n",
      "Epoch 270/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4739 - acc: 0.7737\n",
      "Epoch 271/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4732 - acc: 0.7726\n",
      "Epoch 272/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4722 - acc: 0.7745\n",
      "Epoch 273/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4741 - acc: 0.7746\n",
      "Epoch 274/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4721 - acc: 0.7753\n",
      "Epoch 275/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4742 - acc: 0.7737\n",
      "Epoch 276/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4735 - acc: 0.7732\n",
      "Epoch 277/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4733 - acc: 0.7734\n",
      "Epoch 278/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4721 - acc: 0.7751\n",
      "Epoch 279/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4724 - acc: 0.7717\n",
      "Epoch 280/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4728 - acc: 0.7726\n",
      "Epoch 281/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4735 - acc: 0.7713\n",
      "Epoch 282/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4727 - acc: 0.7719\n",
      "Epoch 283/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4738 - acc: 0.7767\n",
      "Epoch 284/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4736 - acc: 0.7740\n",
      "Epoch 285/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4720 - acc: 0.7719\n",
      "Epoch 286/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4725 - acc: 0.7738\n",
      "Epoch 287/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4734 - acc: 0.7712\n",
      "Epoch 288/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4734 - acc: 0.7738\n",
      "Epoch 289/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4717 - acc: 0.7719\n",
      "Epoch 290/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4731 - acc: 0.7721\n",
      "Epoch 291/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4720 - acc: 0.7736\n",
      "Epoch 292/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4728 - acc: 0.7744\n",
      "Epoch 293/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4736 - acc: 0.7741\n",
      "Epoch 294/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4738 - acc: 0.7718\n",
      "Epoch 295/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4733 - acc: 0.7757\n",
      "Epoch 296/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4730 - acc: 0.7708\n",
      "Epoch 297/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4727 - acc: 0.7725\n",
      "Epoch 298/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4732 - acc: 0.7729\n",
      "Epoch 299/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4724 - acc: 0.7714\n",
      "Epoch 300/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4729 - acc: 0.7730\n",
      "Epoch 301/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4732 - acc: 0.7732\n",
      "Epoch 302/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4740 - acc: 0.7712\n",
      "Epoch 303/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4728 - acc: 0.7747\n",
      "Epoch 304/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4742 - acc: 0.7718\n",
      "Epoch 305/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4717 - acc: 0.7726\n",
      "Epoch 306/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4715 - acc: 0.7746\n",
      "Epoch 307/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4734 - acc: 0.7725\n",
      "Epoch 308/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4716 - acc: 0.7738\n",
      "Epoch 309/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4726 - acc: 0.7755\n",
      "Epoch 310/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4744 - acc: 0.7722\n",
      "Epoch 311/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4729 - acc: 0.7723\n",
      "Epoch 312/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4732 - acc: 0.7750\n",
      "Epoch 313/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4713 - acc: 0.7710\n",
      "Epoch 314/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4730 - acc: 0.7743\n",
      "Epoch 315/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4732 - acc: 0.7715\n",
      "Epoch 316/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4727 - acc: 0.7715\n",
      "Epoch 317/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4721 - acc: 0.7724\n",
      "Epoch 318/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4723 - acc: 0.7709\n",
      "Epoch 319/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4720 - acc: 0.7733\n",
      "Epoch 320/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4719 - acc: 0.7726\n",
      "Epoch 321/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4725 - acc: 0.7734\n",
      "Epoch 322/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4724 - acc: 0.7735\n",
      "Epoch 323/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4725 - acc: 0.7738\n",
      "Epoch 324/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4711 - acc: 0.7735\n",
      "Epoch 325/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4719 - acc: 0.7729\n",
      "Epoch 326/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4711 - acc: 0.7738\n",
      "Epoch 327/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4724 - acc: 0.7736\n",
      "Epoch 328/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4737 - acc: 0.7719\n",
      "Epoch 329/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4710 - acc: 0.7730\n",
      "Epoch 330/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4725 - acc: 0.7741\n",
      "Epoch 331/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4723 - acc: 0.7752\n",
      "Epoch 332/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4717 - acc: 0.7730\n",
      "Epoch 333/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4714 - acc: 0.7747\n",
      "Epoch 334/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4723 - acc: 0.7729\n",
      "Epoch 335/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4715 - acc: 0.7747\n",
      "Epoch 336/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4726 - acc: 0.7743\n",
      "Epoch 337/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4740 - acc: 0.7732\n",
      "Epoch 338/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4716 - acc: 0.7728\n",
      "Epoch 339/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4719 - acc: 0.7737\n",
      "Epoch 340/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4717 - acc: 0.7730\n",
      "Epoch 341/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4714 - acc: 0.7716\n",
      "Epoch 342/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4710 - acc: 0.7746\n",
      "Epoch 343/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4714 - acc: 0.7714\n",
      "Epoch 344/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4721 - acc: 0.7716\n",
      "Epoch 345/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4717 - acc: 0.7723\n",
      "Epoch 346/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4708 - acc: 0.7738\n",
      "Epoch 347/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4724 - acc: 0.7719\n",
      "Epoch 348/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4714 - acc: 0.7707\n",
      "Epoch 349/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4699 - acc: 0.7754\n",
      "Epoch 350/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4708 - acc: 0.7733\n",
      "Epoch 351/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4725 - acc: 0.7705\n",
      "Epoch 352/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4710 - acc: 0.7730\n",
      "Epoch 353/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4704 - acc: 0.7773\n",
      "Epoch 354/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4714 - acc: 0.7717\n",
      "Epoch 355/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4702 - acc: 0.7755\n",
      "Epoch 356/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4727 - acc: 0.7729\n",
      "Epoch 357/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4706 - acc: 0.7746\n",
      "Epoch 358/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4710 - acc: 0.7739\n",
      "Epoch 359/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4726 - acc: 0.7752\n",
      "Epoch 360/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4707 - acc: 0.7747\n",
      "Epoch 361/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4711 - acc: 0.7739\n",
      "Epoch 362/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4700 - acc: 0.7749\n",
      "Epoch 363/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4710 - acc: 0.7751\n",
      "Epoch 364/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4715 - acc: 0.7712\n",
      "Epoch 365/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4713 - acc: 0.7760\n",
      "Epoch 366/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4718 - acc: 0.7706\n",
      "Epoch 367/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4699 - acc: 0.7748\n",
      "Epoch 368/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4703 - acc: 0.7735\n",
      "Epoch 369/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4703 - acc: 0.7742\n",
      "Epoch 370/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4699 - acc: 0.7753\n",
      "Epoch 371/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4703 - acc: 0.7737\n",
      "Epoch 372/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4710 - acc: 0.7767\n",
      "Epoch 373/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4712 - acc: 0.7739\n",
      "Epoch 374/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4725 - acc: 0.7718\n",
      "Epoch 375/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4732 - acc: 0.7740\n",
      "Epoch 376/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4705 - acc: 0.7731\n",
      "Epoch 377/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4711 - acc: 0.7759\n",
      "Epoch 378/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4707 - acc: 0.7761\n",
      "Epoch 379/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4702 - acc: 0.7740\n",
      "Epoch 380/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4705 - acc: 0.7748\n",
      "Epoch 381/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4712 - acc: 0.7723\n",
      "Epoch 382/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4707 - acc: 0.7741\n",
      "Epoch 383/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4720 - acc: 0.7736\n",
      "Epoch 384/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4710 - acc: 0.7725\n",
      "Epoch 385/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4711 - acc: 0.7741\n",
      "Epoch 386/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4714 - acc: 0.7757\n",
      "Epoch 387/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4706 - acc: 0.7735\n",
      "Epoch 388/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4721 - acc: 0.7730\n",
      "Epoch 389/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4699 - acc: 0.7752\n",
      "Epoch 390/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4704 - acc: 0.7739\n",
      "Epoch 391/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4712 - acc: 0.7726\n",
      "Epoch 392/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4697 - acc: 0.7731\n",
      "Epoch 393/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4711 - acc: 0.7718\n",
      "Epoch 394/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4706 - acc: 0.7727\n",
      "Epoch 395/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4703 - acc: 0.7745\n",
      "Epoch 396/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4719 - acc: 0.7731\n",
      "Epoch 397/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4712 - acc: 0.7742\n",
      "Epoch 398/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4698 - acc: 0.7719\n",
      "Epoch 399/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4703 - acc: 0.7727\n",
      "Epoch 400/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4705 - acc: 0.7766\n",
      "Epoch 401/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4704 - acc: 0.7735\n",
      "Epoch 402/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4716 - acc: 0.7754\n",
      "Epoch 403/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4704 - acc: 0.7745\n",
      "Epoch 404/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4703 - acc: 0.7746\n",
      "Epoch 405/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4697 - acc: 0.7739\n",
      "Epoch 406/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4718 - acc: 0.7736\n",
      "Epoch 407/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4704 - acc: 0.7716\n",
      "Epoch 408/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4712 - acc: 0.7743\n",
      "Epoch 409/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4704 - acc: 0.7742\n",
      "Epoch 410/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4693 - acc: 0.7755\n",
      "Epoch 411/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4694 - acc: 0.7742\n",
      "Epoch 412/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4704 - acc: 0.7742\n",
      "Epoch 413/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4701 - acc: 0.7744\n",
      "Epoch 414/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4701 - acc: 0.7755\n",
      "Epoch 415/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4697 - acc: 0.7726\n",
      "Epoch 416/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4690 - acc: 0.7773\n",
      "Epoch 417/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4699 - acc: 0.7719\n",
      "Epoch 418/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4700 - acc: 0.7733\n",
      "Epoch 419/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4702 - acc: 0.7735\n",
      "Epoch 420/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4718 - acc: 0.7744\n",
      "Epoch 421/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4694 - acc: 0.7750\n",
      "Epoch 422/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4698 - acc: 0.7755\n",
      "Epoch 423/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4708 - acc: 0.7747\n",
      "Epoch 424/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4707 - acc: 0.7737\n",
      "Epoch 425/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4687 - acc: 0.7736\n",
      "Epoch 426/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4694 - acc: 0.7746\n",
      "Epoch 427/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4712 - acc: 0.7754\n",
      "Epoch 428/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4707 - acc: 0.7749\n",
      "Epoch 429/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4705 - acc: 0.7739\n",
      "Epoch 430/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4713 - acc: 0.7734\n",
      "Epoch 431/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4712 - acc: 0.7765\n",
      "Epoch 432/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4698 - acc: 0.7739\n",
      "Epoch 433/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4698 - acc: 0.7747\n",
      "Epoch 434/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4699 - acc: 0.7746\n",
      "Epoch 435/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4698 - acc: 0.7737\n",
      "Epoch 436/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4704 - acc: 0.7735\n",
      "Epoch 437/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4693 - acc: 0.7748\n",
      "Epoch 438/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4701 - acc: 0.7754\n",
      "Epoch 439/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4697 - acc: 0.7749\n",
      "Epoch 440/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4692 - acc: 0.7769\n",
      "Epoch 441/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4710 - acc: 0.7750\n",
      "Epoch 442/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4693 - acc: 0.7742\n",
      "Epoch 443/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4700 - acc: 0.7759\n",
      "Epoch 444/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4708 - acc: 0.7739\n",
      "Epoch 445/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4697 - acc: 0.7753\n",
      "Epoch 446/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4696 - acc: 0.7743\n",
      "Epoch 447/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4685 - acc: 0.7780\n",
      "Epoch 448/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4707 - acc: 0.7733\n",
      "Epoch 449/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4689 - acc: 0.7769\n",
      "Epoch 450/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4698 - acc: 0.7751\n",
      "Epoch 451/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4691 - acc: 0.7746\n",
      "Epoch 452/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4695 - acc: 0.7755\n",
      "Epoch 453/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4703 - acc: 0.7728\n",
      "Epoch 454/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4692 - acc: 0.7740\n",
      "Epoch 455/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4701 - acc: 0.7732\n",
      "Epoch 456/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4696 - acc: 0.7743\n",
      "Epoch 457/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4698 - acc: 0.7745\n",
      "Epoch 458/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4694 - acc: 0.7726\n",
      "Epoch 459/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4691 - acc: 0.7737\n",
      "Epoch 460/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4690 - acc: 0.7741\n",
      "Epoch 461/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4688 - acc: 0.7765\n",
      "Epoch 462/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4711 - acc: 0.7737\n",
      "Epoch 463/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4690 - acc: 0.7761\n",
      "Epoch 464/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4701 - acc: 0.7765\n",
      "Epoch 465/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4717 - acc: 0.7769\n",
      "Epoch 466/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4721 - acc: 0.7736\n",
      "Epoch 467/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4691 - acc: 0.7774\n",
      "Epoch 468/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4696 - acc: 0.7738\n",
      "Epoch 469/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4691 - acc: 0.7747\n",
      "Epoch 470/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4704 - acc: 0.7739\n",
      "Epoch 471/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4692 - acc: 0.7759\n",
      "Epoch 472/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4689 - acc: 0.7748\n",
      "Epoch 473/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4700 - acc: 0.7746\n",
      "Epoch 474/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4704 - acc: 0.7752\n",
      "Epoch 475/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4691 - acc: 0.7778\n",
      "Epoch 476/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4687 - acc: 0.7750\n",
      "Epoch 477/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4693 - acc: 0.7747\n",
      "Epoch 478/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4691 - acc: 0.7730\n",
      "Epoch 479/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4699 - acc: 0.7744\n",
      "Epoch 480/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4693 - acc: 0.7744\n",
      "Epoch 481/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4700 - acc: 0.7734\n",
      "Epoch 482/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4686 - acc: 0.7763\n",
      "Epoch 483/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4702 - acc: 0.7756\n",
      "Epoch 484/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4702 - acc: 0.7752\n",
      "Epoch 485/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4699 - acc: 0.7754\n",
      "Epoch 486/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4688 - acc: 0.7738\n",
      "Epoch 487/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4704 - acc: 0.7738\n",
      "Epoch 488/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4694 - acc: 0.7753\n",
      "Epoch 489/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4699 - acc: 0.7764\n",
      "Epoch 490/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4699 - acc: 0.7751\n",
      "Epoch 491/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4700 - acc: 0.7762\n",
      "Epoch 492/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4694 - acc: 0.7747\n",
      "Epoch 493/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4694 - acc: 0.7758\n",
      "Epoch 494/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4687 - acc: 0.7756\n",
      "Epoch 495/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4695 - acc: 0.7760\n",
      "Epoch 496/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4684 - acc: 0.7775\n",
      "Epoch 497/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4698 - acc: 0.7772\n",
      "Epoch 498/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4695 - acc: 0.7751\n",
      "Epoch 499/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4693 - acc: 0.7757\n",
      "Epoch 500/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4679 - acc: 0.7765\n",
      "Epoch 501/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4689 - acc: 0.7761\n",
      "Epoch 502/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4691 - acc: 0.7742\n",
      "Epoch 503/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4690 - acc: 0.7763\n",
      "Epoch 504/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4682 - acc: 0.7750\n",
      "Epoch 505/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4700 - acc: 0.7742\n",
      "Epoch 506/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4693 - acc: 0.7775\n",
      "Epoch 507/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4697 - acc: 0.7756\n",
      "Epoch 508/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4701 - acc: 0.7747\n",
      "Epoch 509/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4688 - acc: 0.7759\n",
      "Epoch 510/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4671 - acc: 0.7750\n",
      "Epoch 511/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4683 - acc: 0.7758\n",
      "Epoch 512/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4693 - acc: 0.7752\n",
      "Epoch 513/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4685 - acc: 0.7773\n",
      "Epoch 514/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4699 - acc: 0.7767\n",
      "Epoch 515/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4694 - acc: 0.7739\n",
      "Epoch 516/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4694 - acc: 0.7774\n",
      "Epoch 517/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4692 - acc: 0.7759\n",
      "Epoch 518/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4676 - acc: 0.7780\n",
      "Epoch 519/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4688 - acc: 0.7757\n",
      "Epoch 520/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4687 - acc: 0.7783\n",
      "Epoch 521/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4690 - acc: 0.7772\n",
      "Epoch 522/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4693 - acc: 0.7756\n",
      "Epoch 523/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4693 - acc: 0.7760\n",
      "Epoch 524/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4688 - acc: 0.7758\n",
      "Epoch 525/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4701 - acc: 0.7739\n",
      "Epoch 526/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4696 - acc: 0.7735\n",
      "Epoch 527/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4690 - acc: 0.7758\n",
      "Epoch 528/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4692 - acc: 0.7744\n",
      "Epoch 529/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4683 - acc: 0.7758\n",
      "Epoch 530/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4703 - acc: 0.7731\n",
      "Epoch 531/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4690 - acc: 0.7745\n",
      "Epoch 532/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4702 - acc: 0.7762\n",
      "Epoch 533/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4695 - acc: 0.7726\n",
      "Epoch 534/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4696 - acc: 0.7755\n",
      "Epoch 535/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4684 - acc: 0.7778\n",
      "Epoch 536/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4703 - acc: 0.7735\n",
      "Epoch 537/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4692 - acc: 0.7759\n",
      "Epoch 538/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4688 - acc: 0.7747\n",
      "Epoch 539/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4685 - acc: 0.7780\n",
      "Epoch 540/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4676 - acc: 0.7776\n",
      "Epoch 541/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4696 - acc: 0.7779\n",
      "Epoch 542/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4680 - acc: 0.7765\n",
      "Epoch 543/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4686 - acc: 0.7769\n",
      "Epoch 544/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4694 - acc: 0.7749\n",
      "Epoch 545/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4684 - acc: 0.7749\n",
      "Epoch 546/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4679 - acc: 0.7769\n",
      "Epoch 547/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4683 - acc: 0.7747\n",
      "Epoch 548/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4693 - acc: 0.7749\n",
      "Epoch 549/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4685 - acc: 0.7769\n",
      "Epoch 550/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4681 - acc: 0.7768\n",
      "Epoch 551/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4685 - acc: 0.7754\n",
      "Epoch 552/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4689 - acc: 0.7759\n",
      "Epoch 553/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4683 - acc: 0.7759\n",
      "Epoch 554/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4683 - acc: 0.7773\n",
      "Epoch 555/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4681 - acc: 0.7762\n",
      "Epoch 556/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4674 - acc: 0.7753\n",
      "Epoch 557/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4688 - acc: 0.7751\n",
      "Epoch 558/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4678 - acc: 0.7771\n",
      "Epoch 559/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4681 - acc: 0.7777\n",
      "Epoch 560/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4691 - acc: 0.7762\n",
      "Epoch 561/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4679 - acc: 0.7752\n",
      "Epoch 562/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4685 - acc: 0.7751\n",
      "Epoch 563/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4697 - acc: 0.7758\n",
      "Epoch 564/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4684 - acc: 0.7774\n",
      "Epoch 565/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4669 - acc: 0.7766\n",
      "Epoch 566/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4694 - acc: 0.7779\n",
      "Epoch 567/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4688 - acc: 0.7785\n",
      "Epoch 568/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4691 - acc: 0.7771\n",
      "Epoch 569/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4684 - acc: 0.7759\n",
      "Epoch 570/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4663 - acc: 0.7752\n",
      "Epoch 571/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4679 - acc: 0.7781\n",
      "Epoch 572/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4686 - acc: 0.7778\n",
      "Epoch 573/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4679 - acc: 0.7796\n",
      "Epoch 574/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4681 - acc: 0.7768\n",
      "Epoch 575/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4683 - acc: 0.7795\n",
      "Epoch 576/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4688 - acc: 0.7755\n",
      "Epoch 577/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4682 - acc: 0.7781\n",
      "Epoch 578/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 0.4670 - acc: 0.7764\n",
      "Epoch 579/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 0.4683 - acc: 0.7768\n",
      "Epoch 580/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 0.4678 - acc: 0.7781\n",
      "Epoch 581/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 0.4682 - acc: 0.7745\n",
      "Epoch 582/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4678 - acc: 0.7786\n",
      "Epoch 583/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4686 - acc: 0.7784\n",
      "Epoch 584/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4691 - acc: 0.7767\n",
      "Epoch 585/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4678 - acc: 0.7759\n",
      "Epoch 586/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 0.4686 - acc: 0.7776\n",
      "Epoch 587/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4681 - acc: 0.7777\n",
      "Epoch 588/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4676 - acc: 0.7770\n",
      "Epoch 589/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4674 - acc: 0.7777\n",
      "Epoch 590/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4676 - acc: 0.7805\n",
      "Epoch 591/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4683 - acc: 0.7760\n",
      "Epoch 592/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4688 - acc: 0.7735\n",
      "Epoch 593/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4686 - acc: 0.7770\n",
      "Epoch 594/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4688 - acc: 0.7755\n",
      "Epoch 595/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4678 - acc: 0.7779\n",
      "Epoch 596/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4687 - acc: 0.7766\n",
      "Epoch 597/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4678 - acc: 0.7785\n",
      "Epoch 598/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4685 - acc: 0.7753\n",
      "Epoch 599/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4681 - acc: 0.7756\n",
      "Epoch 600/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4661 - acc: 0.7786\n",
      "Epoch 601/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4687 - acc: 0.7755\n",
      "Epoch 602/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4693 - acc: 0.7756\n",
      "Epoch 603/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4665 - acc: 0.7779\n",
      "Epoch 604/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4690 - acc: 0.7782\n",
      "Epoch 605/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4677 - acc: 0.7763\n",
      "Epoch 606/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4681 - acc: 0.7772\n",
      "Epoch 607/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4679 - acc: 0.7769\n",
      "Epoch 608/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4665 - acc: 0.7767\n",
      "Epoch 609/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4673 - acc: 0.7761\n",
      "Epoch 610/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4691 - acc: 0.7751\n",
      "Epoch 611/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4686 - acc: 0.7765\n",
      "Epoch 612/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4685 - acc: 0.7760\n",
      "Epoch 613/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4668 - acc: 0.7769\n",
      "Epoch 614/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4684 - acc: 0.7787\n",
      "Epoch 615/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4689 - acc: 0.7769\n",
      "Epoch 616/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4671 - acc: 0.7763\n",
      "Epoch 617/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4687 - acc: 0.7759\n",
      "Epoch 618/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4679 - acc: 0.7765\n",
      "Epoch 619/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4682 - acc: 0.7761\n",
      "Epoch 620/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4669 - acc: 0.7758\n",
      "Epoch 621/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4690 - acc: 0.7785\n",
      "Epoch 622/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4673 - acc: 0.7764\n",
      "Epoch 623/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4682 - acc: 0.7768\n",
      "Epoch 624/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4687 - acc: 0.7794\n",
      "Epoch 625/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4678 - acc: 0.7772\n",
      "Epoch 626/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4672 - acc: 0.7786\n",
      "Epoch 627/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4677 - acc: 0.7763\n",
      "Epoch 628/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4676 - acc: 0.7772\n",
      "Epoch 629/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4672 - acc: 0.7784\n",
      "Epoch 630/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4666 - acc: 0.7790\n",
      "Epoch 631/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4677 - acc: 0.7770\n",
      "Epoch 632/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4678 - acc: 0.7789\n",
      "Epoch 633/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4668 - acc: 0.7790\n",
      "Epoch 634/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4679 - acc: 0.7758\n",
      "Epoch 635/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4660 - acc: 0.7791\n",
      "Epoch 636/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4684 - acc: 0.7763\n",
      "Epoch 637/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4663 - acc: 0.7772\n",
      "Epoch 638/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4665 - acc: 0.7777\n",
      "Epoch 639/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4667 - acc: 0.7779\n",
      "Epoch 640/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4666 - acc: 0.7785\n",
      "Epoch 641/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4672 - acc: 0.7782\n",
      "Epoch 642/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4669 - acc: 0.7793\n",
      "Epoch 643/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4674 - acc: 0.7762\n",
      "Epoch 644/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4677 - acc: 0.7783\n",
      "Epoch 645/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4672 - acc: 0.7782\n",
      "Epoch 646/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4667 - acc: 0.7779\n",
      "Epoch 647/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4670 - acc: 0.7779\n",
      "Epoch 648/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4676 - acc: 0.7741\n",
      "Epoch 649/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4673 - acc: 0.7771\n",
      "Epoch 650/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4676 - acc: 0.7765\n",
      "Epoch 651/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4669 - acc: 0.7803\n",
      "Epoch 652/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4664 - acc: 0.7808\n",
      "Epoch 653/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4670 - acc: 0.7789\n",
      "Epoch 654/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4658 - acc: 0.7785\n",
      "Epoch 655/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4665 - acc: 0.7765\n",
      "Epoch 656/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4669 - acc: 0.7761\n",
      "Epoch 657/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4685 - acc: 0.7773\n",
      "Epoch 658/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4686 - acc: 0.7756\n",
      "Epoch 659/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4664 - acc: 0.7780\n",
      "Epoch 660/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4671 - acc: 0.7765\n",
      "Epoch 661/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4672 - acc: 0.7793\n",
      "Epoch 662/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4663 - acc: 0.7781\n",
      "Epoch 663/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4671 - acc: 0.7778\n",
      "Epoch 664/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4665 - acc: 0.7776\n",
      "Epoch 665/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4670 - acc: 0.7793\n",
      "Epoch 666/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4663 - acc: 0.7797\n",
      "Epoch 667/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4668 - acc: 0.7782\n",
      "Epoch 668/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4669 - acc: 0.7773\n",
      "Epoch 669/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4664 - acc: 0.7793\n",
      "Epoch 670/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4661 - acc: 0.7771\n",
      "Epoch 671/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4660 - acc: 0.7814\n",
      "Epoch 672/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4671 - acc: 0.7783\n",
      "Epoch 673/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4664 - acc: 0.7785\n",
      "Epoch 674/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4656 - acc: 0.7785\n",
      "Epoch 675/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4668 - acc: 0.7801\n",
      "Epoch 676/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4658 - acc: 0.7811\n",
      "Epoch 677/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4671 - acc: 0.7764\n",
      "Epoch 678/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4665 - acc: 0.7764\n",
      "Epoch 679/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4668 - acc: 0.7786\n",
      "Epoch 680/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4663 - acc: 0.7791\n",
      "Epoch 681/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4667 - acc: 0.7810\n",
      "Epoch 682/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4659 - acc: 0.7794\n",
      "Epoch 683/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4660 - acc: 0.7761\n",
      "Epoch 684/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4659 - acc: 0.7767\n",
      "Epoch 685/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4649 - acc: 0.7783\n",
      "Epoch 686/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4667 - acc: 0.7765\n",
      "Epoch 687/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4652 - acc: 0.7770\n",
      "Epoch 688/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4665 - acc: 0.7783\n",
      "Epoch 689/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4655 - acc: 0.7769\n",
      "Epoch 690/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4661 - acc: 0.7759\n",
      "Epoch 691/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4658 - acc: 0.7785\n",
      "Epoch 692/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4675 - acc: 0.7800\n",
      "Epoch 693/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4667 - acc: 0.7787\n",
      "Epoch 694/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4669 - acc: 0.7775\n",
      "Epoch 695/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4670 - acc: 0.7783\n",
      "Epoch 696/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4654 - acc: 0.7800\n",
      "Epoch 697/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4656 - acc: 0.7792\n",
      "Epoch 698/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4660 - acc: 0.7805\n",
      "Epoch 699/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4675 - acc: 0.7759\n",
      "Epoch 700/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4662 - acc: 0.7770\n",
      "Epoch 701/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4666 - acc: 0.7793\n",
      "Epoch 702/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4664 - acc: 0.7790\n",
      "Epoch 703/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4657 - acc: 0.7782\n",
      "Epoch 704/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4660 - acc: 0.7791\n",
      "Epoch 705/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4652 - acc: 0.7791\n",
      "Epoch 706/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4654 - acc: 0.7802\n",
      "Epoch 707/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4673 - acc: 0.7777\n",
      "Epoch 708/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4663 - acc: 0.7780\n",
      "Epoch 709/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4654 - acc: 0.7775\n",
      "Epoch 710/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4653 - acc: 0.7777\n",
      "Epoch 711/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4645 - acc: 0.7796\n",
      "Epoch 712/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4662 - acc: 0.7767\n",
      "Epoch 713/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4652 - acc: 0.7801\n",
      "Epoch 714/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4648 - acc: 0.7806\n",
      "Epoch 715/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4654 - acc: 0.7799\n",
      "Epoch 716/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4668 - acc: 0.7768\n",
      "Epoch 717/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4649 - acc: 0.7796\n",
      "Epoch 718/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4650 - acc: 0.7779\n",
      "Epoch 719/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4656 - acc: 0.7789\n",
      "Epoch 720/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4669 - acc: 0.7798\n",
      "Epoch 721/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4655 - acc: 0.7795\n",
      "Epoch 722/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4651 - acc: 0.7770\n",
      "Epoch 723/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4642 - acc: 0.7795\n",
      "Epoch 724/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4661 - acc: 0.7773\n",
      "Epoch 725/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4650 - acc: 0.7787\n",
      "Epoch 726/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4655 - acc: 0.7797\n",
      "Epoch 727/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4659 - acc: 0.7781\n",
      "Epoch 728/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4649 - acc: 0.7786\n",
      "Epoch 729/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4654 - acc: 0.7784\n",
      "Epoch 730/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4649 - acc: 0.7789\n",
      "Epoch 731/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4656 - acc: 0.7748\n",
      "Epoch 732/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4665 - acc: 0.7783\n",
      "Epoch 733/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4645 - acc: 0.7798\n",
      "Epoch 734/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4642 - acc: 0.7801\n",
      "Epoch 735/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4640 - acc: 0.7788\n",
      "Epoch 736/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4662 - acc: 0.7786\n",
      "Epoch 737/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4653 - acc: 0.7777\n",
      "Epoch 738/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4676 - acc: 0.7774\n",
      "Epoch 739/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4653 - acc: 0.7783\n",
      "Epoch 740/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4639 - acc: 0.7787\n",
      "Epoch 741/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4645 - acc: 0.7803\n",
      "Epoch 742/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4658 - acc: 0.7782\n",
      "Epoch 743/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4645 - acc: 0.7798\n",
      "Epoch 744/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4664 - acc: 0.7803\n",
      "Epoch 745/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4652 - acc: 0.7798\n",
      "Epoch 746/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4653 - acc: 0.7786\n",
      "Epoch 747/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4647 - acc: 0.7783\n",
      "Epoch 748/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4658 - acc: 0.7807\n",
      "Epoch 749/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4653 - acc: 0.7787\n",
      "Epoch 750/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4655 - acc: 0.7785\n",
      "Epoch 751/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4657 - acc: 0.7789\n",
      "Epoch 752/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4657 - acc: 0.7781\n",
      "Epoch 753/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4664 - acc: 0.7805\n",
      "Epoch 754/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4675 - acc: 0.7773\n",
      "Epoch 755/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4660 - acc: 0.7781\n",
      "Epoch 756/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4647 - acc: 0.7819\n",
      "Epoch 757/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4659 - acc: 0.7772\n",
      "Epoch 758/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4650 - acc: 0.7791\n",
      "Epoch 759/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4646 - acc: 0.7804\n",
      "Epoch 760/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 0.4646 - acc: 0.7801\n",
      "Epoch 761/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4647 - acc: 0.7788\n",
      "Epoch 762/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4672 - acc: 0.7793\n",
      "Epoch 763/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4650 - acc: 0.7779\n",
      "Epoch 764/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4655 - acc: 0.7782\n",
      "Epoch 765/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4653 - acc: 0.7760\n",
      "Epoch 766/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4642 - acc: 0.7777\n",
      "Epoch 767/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4647 - acc: 0.7782\n",
      "Epoch 768/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4661 - acc: 0.7803\n",
      "Epoch 769/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4644 - acc: 0.7794\n",
      "Epoch 770/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4650 - acc: 0.7775\n",
      "Epoch 771/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4643 - acc: 0.7777\n",
      "Epoch 772/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4648 - acc: 0.7778\n",
      "Epoch 773/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4655 - acc: 0.7775\n",
      "Epoch 774/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4649 - acc: 0.7812\n",
      "Epoch 775/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4642 - acc: 0.7809\n",
      "Epoch 776/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4648 - acc: 0.7799\n",
      "Epoch 777/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4655 - acc: 0.7779\n",
      "Epoch 778/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4648 - acc: 0.7792\n",
      "Epoch 779/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4634 - acc: 0.7810\n",
      "Epoch 780/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4635 - acc: 0.7796\n",
      "Epoch 781/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4644 - acc: 0.7795\n",
      "Epoch 782/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4655 - acc: 0.7805\n",
      "Epoch 783/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4648 - acc: 0.7776\n",
      "Epoch 784/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4645 - acc: 0.7803\n",
      "Epoch 785/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4626 - acc: 0.7801\n",
      "Epoch 786/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4639 - acc: 0.7804\n",
      "Epoch 787/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4649 - acc: 0.7796\n",
      "Epoch 788/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4643 - acc: 0.7781\n",
      "Epoch 789/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4650 - acc: 0.7791\n",
      "Epoch 790/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4639 - acc: 0.7791\n",
      "Epoch 791/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4642 - acc: 0.7804\n",
      "Epoch 792/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4651 - acc: 0.7810\n",
      "Epoch 793/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4643 - acc: 0.7792\n",
      "Epoch 794/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4652 - acc: 0.7776\n",
      "Epoch 795/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4636 - acc: 0.7807\n",
      "Epoch 796/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4632 - acc: 0.7789\n",
      "Epoch 797/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4656 - acc: 0.7785\n",
      "Epoch 798/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4647 - acc: 0.7811\n",
      "Epoch 799/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4651 - acc: 0.7831\n",
      "Epoch 800/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4628 - acc: 0.7818\n",
      "Epoch 801/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4639 - acc: 0.7776\n",
      "Epoch 802/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4640 - acc: 0.7814\n",
      "Epoch 803/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4649 - acc: 0.7787\n",
      "Epoch 804/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4652 - acc: 0.7787\n",
      "Epoch 805/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4628 - acc: 0.7786\n",
      "Epoch 806/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4637 - acc: 0.7788\n",
      "Epoch 807/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4638 - acc: 0.7788\n",
      "Epoch 808/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4645 - acc: 0.7808\n",
      "Epoch 809/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4647 - acc: 0.7788\n",
      "Epoch 810/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4651 - acc: 0.7771\n",
      "Epoch 811/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4632 - acc: 0.7789\n",
      "Epoch 812/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4631 - acc: 0.7807\n",
      "Epoch 813/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4630 - acc: 0.7798\n",
      "Epoch 814/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4641 - acc: 0.7777\n",
      "Epoch 815/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4637 - acc: 0.7794\n",
      "Epoch 816/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4642 - acc: 0.7808\n",
      "Epoch 817/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4639 - acc: 0.7795\n",
      "Epoch 818/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4639 - acc: 0.7798\n",
      "Epoch 819/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4639 - acc: 0.7812\n",
      "Epoch 820/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4632 - acc: 0.7820\n",
      "Epoch 821/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4642 - acc: 0.7814\n",
      "Epoch 822/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4646 - acc: 0.7822\n",
      "Epoch 823/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4635 - acc: 0.7799\n",
      "Epoch 824/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4655 - acc: 0.7781\n",
      "Epoch 825/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4641 - acc: 0.7797\n",
      "Epoch 826/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4635 - acc: 0.7794\n",
      "Epoch 827/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4633 - acc: 0.7804\n",
      "Epoch 828/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4634 - acc: 0.7804\n",
      "Epoch 829/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4641 - acc: 0.7827\n",
      "Epoch 830/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4643 - acc: 0.7795\n",
      "Epoch 831/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4626 - acc: 0.7803\n",
      "Epoch 832/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4630 - acc: 0.7809\n",
      "Epoch 833/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4635 - acc: 0.7809\n",
      "Epoch 834/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4642 - acc: 0.7802\n",
      "Epoch 835/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4636 - acc: 0.7790\n",
      "Epoch 836/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4633 - acc: 0.7808\n",
      "Epoch 837/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4643 - acc: 0.7800\n",
      "Epoch 838/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4656 - acc: 0.7776\n",
      "Epoch 839/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4627 - acc: 0.7786\n",
      "Epoch 840/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4636 - acc: 0.7807\n",
      "Epoch 841/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4630 - acc: 0.7810\n",
      "Epoch 842/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4636 - acc: 0.7778\n",
      "Epoch 843/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4636 - acc: 0.7808\n",
      "Epoch 844/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4643 - acc: 0.7802\n",
      "Epoch 845/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4634 - acc: 0.7817\n",
      "Epoch 846/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4639 - acc: 0.7797\n",
      "Epoch 847/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4627 - acc: 0.7804\n",
      "Epoch 848/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4634 - acc: 0.7790\n",
      "Epoch 849/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4623 - acc: 0.7828\n",
      "Epoch 850/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4625 - acc: 0.7799\n",
      "Epoch 851/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 0.4628 - acc: 0.7822\n",
      "Epoch 852/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4641 - acc: 0.7804\n",
      "Epoch 853/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4628 - acc: 0.7796\n",
      "Epoch 854/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4624 - acc: 0.7787\n",
      "Epoch 855/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4636 - acc: 0.7772\n",
      "Epoch 856/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4621 - acc: 0.7818\n",
      "Epoch 857/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4624 - acc: 0.7800\n",
      "Epoch 858/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4616 - acc: 0.7801\n",
      "Epoch 859/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4615 - acc: 0.7806\n",
      "Epoch 860/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4615 - acc: 0.7797\n",
      "Epoch 861/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4619 - acc: 0.7798\n",
      "Epoch 862/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4623 - acc: 0.7795\n",
      "Epoch 863/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4626 - acc: 0.7806\n",
      "Epoch 864/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4618 - acc: 0.7816\n",
      "Epoch 865/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4623 - acc: 0.7802\n",
      "Epoch 866/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4620 - acc: 0.7830\n",
      "Epoch 867/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4625 - acc: 0.7769\n",
      "Epoch 868/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4618 - acc: 0.7809\n",
      "Epoch 869/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4608 - acc: 0.7848\n",
      "Epoch 870/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4634 - acc: 0.7809\n",
      "Epoch 871/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4618 - acc: 0.7814\n",
      "Epoch 872/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4621 - acc: 0.7839\n",
      "Epoch 873/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4614 - acc: 0.7814\n",
      "Epoch 874/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4601 - acc: 0.7802\n",
      "Epoch 875/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4612 - acc: 0.7813\n",
      "Epoch 876/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4610 - acc: 0.7792\n",
      "Epoch 877/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4605 - acc: 0.7788\n",
      "Epoch 878/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4617 - acc: 0.7823\n",
      "Epoch 879/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4617 - acc: 0.7804\n",
      "Epoch 880/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4605 - acc: 0.7834\n",
      "Epoch 881/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4603 - acc: 0.7810\n",
      "Epoch 882/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4610 - acc: 0.7831\n",
      "Epoch 883/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4598 - acc: 0.7822\n",
      "Epoch 884/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4612 - acc: 0.7839\n",
      "Epoch 885/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4614 - acc: 0.7816\n",
      "Epoch 886/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4606 - acc: 0.7809\n",
      "Epoch 887/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4615 - acc: 0.7806\n",
      "Epoch 888/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4612 - acc: 0.7837\n",
      "Epoch 889/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4603 - acc: 0.7810\n",
      "Epoch 890/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4612 - acc: 0.7805\n",
      "Epoch 891/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4601 - acc: 0.7826\n",
      "Epoch 892/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4626 - acc: 0.7802\n",
      "Epoch 893/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4606 - acc: 0.7815\n",
      "Epoch 894/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4605 - acc: 0.7813\n",
      "Epoch 895/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4598 - acc: 0.7820\n",
      "Epoch 896/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4605 - acc: 0.7821\n",
      "Epoch 897/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4607 - acc: 0.7820\n",
      "Epoch 898/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4611 - acc: 0.7806\n",
      "Epoch 899/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4617 - acc: 0.7804\n",
      "Epoch 900/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4597 - acc: 0.7834\n",
      "Epoch 901/1000\n",
      "10000/10000 [==============================] - 0s 11us/sample - loss: 0.4594 - acc: 0.7826\n",
      "Epoch 902/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4598 - acc: 0.7845\n",
      "Epoch 903/1000\n",
      "   32/10000 [..............................] - ETA: 0s - loss: 0.5420 - acc: 0.7188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m income_nn\u001b[38;5;241m=\u001b[39mnn_model()\n\u001b[1;32m----> 2\u001b[0m income_nn, optimal_datapt \u001b[38;5;241m=\u001b[39m optimal_point(dataset, income_nn, desired_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, original_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, chosen_row\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25954\u001b[39m, point_epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m      3\u001b[0m X_point \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m25954\u001b[39m,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      4\u001b[0m target_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[27], line 96\u001b[0m, in \u001b[0;36moptimal_point\u001b[1;34m(dataset, model, desired_class, original_class, chosen_row, threshold, point_epsilon, epsilon, constraints, deltas, plot)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel training complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# STEP 2: Find decision boundary\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:856\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    855\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    858\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m    859\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    860\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    861\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m    862\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    863\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    864\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39mvalidation_split,\n\u001b[0;32m    865\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_data,\n\u001b[0;32m    866\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m    867\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weight,\n\u001b[0;32m    868\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    869\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[0;32m    870\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m    871\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m    872\u001b[0m     validation_freq\u001b[38;5;241m=\u001b[39mvalidation_freq,\n\u001b[0;32m    873\u001b[0m     max_queue_size\u001b[38;5;241m=\u001b[39mmax_queue_size,\n\u001b[0;32m    874\u001b[0m     workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[0;32m    875\u001b[0m     use_multiprocessing\u001b[38;5;241m=\u001b[39muse_multiprocessing,\n\u001b[0;32m    876\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    731\u001b[0m         )\n\u001b[0;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fit_loop(\n\u001b[0;32m    735\u001b[0m     model,\n\u001b[0;32m    736\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m    737\u001b[0m     targets\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    738\u001b[0m     sample_weights\u001b[38;5;241m=\u001b[39msample_weights,\n\u001b[0;32m    739\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    740\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m    741\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    742\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    743\u001b[0m     val_inputs\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    744\u001b[0m     val_targets\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m    745\u001b[0m     val_sample_weights\u001b[38;5;241m=\u001b[39mval_sample_weights,\n\u001b[0;32m    746\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m    747\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[0;32m    748\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m    749\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m    750\u001b[0m     validation_freq\u001b[38;5;241m=\u001b[39mvalidation_freq,\n\u001b[0;32m    751\u001b[0m     steps_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps_per_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    752\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(\n\u001b[0;32m    417\u001b[0m     mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_index, batch_logs\n\u001b[0;32m    418\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m f(ins_batch)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    423\u001b[0m     batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:4609\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4600\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4601\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4605\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[0;32m   4606\u001b[0m ):\n\u001b[0;32m   4607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4609\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn(\u001b[38;5;241m*\u001b[39marray_vals, run_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_metadata)\n\u001b[0;32m   4610\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n\u001b[0;32m   4611\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4612\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4613\u001b[0m     fetched[: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[0;32m   4614\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   4615\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1505\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1504\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1505\u001b[0m   ret \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_SessionRunCallable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39m_session,\n\u001b[0;32m   1506\u001b[0m                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle, args,\n\u001b[0;32m   1507\u001b[0m                                          run_metadata_ptr)\n\u001b[0;32m   1508\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1509\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "income_nn=nn_model()\n",
    "income_nn, optimal_datapt = optimal_point(dataset, income_nn, desired_class=1, original_class=0, threshold=10000, chosen_row=25954, point_epsilon=1e-3, epsilon=1e-3)\n",
    "X_point = dataset.iloc[25954,:-1]\n",
    "target_class=1\n",
    "explainer2 = Counterfactual(income_nn, shape=shape, target_proba=target_proba, tol=tol,\n",
    "                    target_class=target_class)\n",
    "print(np.reshape(X_point, (1,-1)).shape)\n",
    "cf = explainer2.explain(np.reshape(X_point, (1,-1)))\n",
    "cf_point = cf.data['cf']['X'] \n",
    "print(cf_point)\n",
    "print(income_nn.predict(np.reshape(X_point, (1,-1))))\n",
    "print(\"DISTANCE:\", euclidean_distance(X_point, cf_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd12b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " income\n",
      "0    19820\n",
      "1    19820\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 39640 samples\n",
      "   32/39640 [..............................] - ETA: 37s - loss: 6.8273 - acc: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_28144\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39640/39640 [==============================] - 0s 12us/sample - loss: 0.8084 - acc: 0.6226\n",
      "Model training complete.\n",
      "boundary points started generation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(50000, 8)\n",
      "(49835, 8)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[0.99931139 0.99850693 0.99767158 0.99850693 0.99850693 0.\n",
      "  0.99767158 0.        ]]\n",
      "[[0.59179688 0.4005127  0.29974365 0.4005127  0.4005127  0.\n",
      "  0.29974365 0.        ]]\n",
      "EUCLIDEAN DISTANCE FOR NEAREST CF 1.0041879160230396\n",
      "(1, 8)\n",
      "[[31.99953     2.0002198   6.9992642   0.9943504   4.997899    1.0212994\n",
      "   0.11540653 49.999535  ]]\n",
      "[[0.36358514 0.6364149 ]]\n",
      "DISTANCE: 0.8848709691168858\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIiUlEQVR4nO3de1yUVf4H8M8zA8wgMiMocpGbd8QLoqaiaZEpapqmpkU/L5VbbpqaubthbmltXrYsr1vtbkVuipb3WjO1UiRJIxk07ygKIog3GC4yMDPn94c1KyHKCDPPMPN5v17P67dz5sz4fc6PmA/nec4ZSQghQEREROTAFHIXQERERHQ3DCxERETk8BhYiIiIyOExsBAREZHDY2AhIiIih8fAQkRERA6PgYWIiIgcHgMLEREROTw3uQuoL2azGRcvXoS3tzckSZK7HCIiIqoFIQSKi4sRFBQEhaLmeRSnCSwXL15ESEiI3GUQERHRPcjJyUFwcHCNzztNYPH29gZw84Q1Go3M1RAREVFt6PV6hISEWD7Ha+I0geW3y0AajYaBhYiIqIG52+0cvOmWiIiIHB4DCxERETk8BhYiIiKyyqRJkyBJEhYtWlSlfcuWLZZLO3v27IEkSSgsLKz2+vDwcCxdutSqf5OBhYiIiKymVquxePFiXL9+3S7/HgMLERERWe3hhx9GQEAAFi5caJd/j4GFiIiIrKZUKrFgwQKsWLECFy5csPm/x8BCRERE9+Sxxx5D165d8frrr9fYJzg4GI0bN65yZGdnW/1vOc0+LERERGR/ixcvxkMPPYSXX375ts/v27ev2qZwDz74oNX/DgMLERER1chkNmFf9j7kFech0DsQ/UL7VXm+f//+iIuLw5w5czBp0qRqr2/ZsiWaNGlSpc3Nzfr4YfUloeTkZAwfPhxBQUGQJAlbtmyp9Wt/+OEHuLm5oWvXrtWe27hxIyIjI6FSqRAZGYnNmzdbWxoRERHVo03HNyF8WThiP41F/KZ4xH4ai/Bl4ThfdL5Kv0WLFuHLL7/E/v37bVaL1YGltLQUUVFRWLlypVWvKyoqwoQJEzBgwIBqz6WmpmLcuHEYP348MjIyMH78eIwdOxYHDhywtjwiIiKqB5uOb8KYz8fggr7qDbW5+lzsydqDi8UXLW2dO3fGU089hRUrVtisHqsDy5AhQ/C3v/0No0aNsup1zz//POLj4xETE1PtuaVLl2LgwIFISEhAREQEEhISMGDAAKs3lSEiIqK6M5lNmLFjBgREted+a/ul4BeYzCZL+5tvvgkhqvevL3ZZJfTJJ5/gzJkzNd5FnJqaikGDBlVpi4uLu+PUksFggF6vr3IQERFR3e3L3ldtZqWKx4AbY25gX/Y+S1NYWBjKy8stoeXBBx+EEKLa/SsAcO7cOcycOdOqmmweWE6fPo1XXnkFa9asqfEmm/z8fPj7+1dp8/f3R35+fo3vu3DhQmi1WssREhJSr3UTERG5qrzivHrtVx9sGlhMJhPi4+Mxf/58tGvX7o59f/+10kKIO37VdEJCAoqKiixHTk5OvdRMRETk6gK9A+FmDoRvxR8BUXNUCPQOtFtNNl3WXFxcjLS0NKSnp2PatGkAALPZDCEE3NzcsHPnTjz00EMICAioNptSUFBQbdblViqVCiqVypblExERuaSiwjYIqlgOSXjCJF1Hkfu6Ks9LkBCsCa62xNmWbBpYNBoNjhw5UqXtH//4B7777jts2LABLVu2BADExMRg165deOmllyz9du7ciT59+tiyPCIiIrpFeaUJb3x1DGsPZEOCJ8oVv6DUbVeVPhJuXv1YOngplAql3WqzOrCUlJQgMzPT8jgrKws6nQ6+vr4IDQ1FQkICcnNzsXr1aigUCnTq1KnK65s3bw61Wl2lfcaMGejfvz8WL16MESNGYOvWrdi9ezdSUlLqcGpERERUW2cul2DqmkM4kV8MSQKmPtgGYcEGzNrpiQu3rGsJ1gRj6eClGNXButXCdWV1YElLS0NsbKzl8axZswAAEydORGJiIvLy8qz+joA+ffpg3bp1mDt3Lv7617+idevWWL9+PXr16mVteURERGSl3ccuYfq6dJRVmNCssQfeG9cV/dr6AWiPUR1GVNvp1p4zK7+RhC0XTduRXq+HVqtFUVERNBqN3OUQERE1GKcvFePRlT+ga0gTLHuiK5pr1Hb7t2v7+c3vEiIiInJBRTcqofV0BwC09ffGF1Ni0CFQA6Wi5hW6crLLxnFERETkGIQQ+DwtB30XfYefzl2ztHdqoXXYsAJwhoWIiMhllBqM+OuWX7ApPRcAsP6nHNwX7itzVbXDwEJEROQCjufpMXXtIZy9XAqFBLw8qD3++EBrucuqNQYWIiIiJyaEQNLBHMz/8igMRjMCNGosfzIaPVs2jJmV3zCwEBERObHk01cwZ/PNTVxj2/thydiu8PXykLkq6zGwEBERObH+bZvh0aggdAzS4A/9WkHhwDfW3gkDCxERkRMRQuCLny9gcKcAaNTukCQJy57oescvFG4IuKyZiIjISRTdqMTUtYfw5w2HkbDxCH7bG7ahhxWAMyxEREROISOnENOSDiHn2g24KyV0D/ORu6R6xcBCRETUgAkh8PEP57Do6+OoNAmE+Hpi5ZPdEBXSRO7S6hUDCxERUQNVVFaJ2RsysOvYJQDAkE4BWDS6i2XLfWfCwEJERNRAGc1mHL5QCA+lAnOHdcD43mFOcb/K7TCwEBERNSBCCEsoadpYhX881R0qNwU6tdDKXJltcZUQERFRA3GttALPJP6EjT9fsLR1D/Nx+rACcIaFiIioQTiYdQ3Tk9KRry+HLqcQQzoHoJGH63yMu86ZEhERNUBms8D7e8/g3V2nYDILtPLzwqr4bi4VVgAGFiIiIod1pcSAl9brsO/0FQDAqOgWeHNkJ3ipXO/j2/XOmIiIqAEoLq/EsOUpyNeXQ+2uwBsjOuHx7sFOuwrobhhYiIiIHJC32h2jurXA7uOXsCq+G9r6e8tdkqwk8dsXDTRwer0eWq0WRUVF0Gg0cpdDRERktYLiclQYzQj2aQQAMJrMqDQJeHooZa7Mdmr7+c1lzURERA4g5fQVDF22D1PXHEKF0QwAcFMqnDqsWIOXhIiIiGRkNJmxdPdprNqTCSGAZo1VuFZagQCtWu7SHAoDCxERkUzyi8oxfV06DmZdAwDE9wrFa8MioXbnrMrvMbAQERHJ4PuTBXj58wxcK61AY5UbFozqjEejguQuy2ExsBAREdmZ2Szw3q5TuFZagY5BGqyK74bwZl5yl+XQGFiIiIjsTKGQsOLJaHz243m8PKg9LwHVAlcJERER2cHuY5fwwd4zlsdhTb3w6iO8X6W2OMNCRERkQxVGM/6+4wT+nZIFSbr57cr3hfvKXVaDw8BCRERkIznXyjAtKR0ZOYUAgKf7tERUcBNZa2qoGFiIiIhsYMcvefjThsMoLjdC6+mOdx6PwsBIf7nLarCsvoclOTkZw4cPR1BQECRJwpYtW+7YPyUlBX379kXTpk3h6emJiIgIvPfee1X6JCYmQpKkakd5ebm15REREclu4dfHMeWzQyguN6JbaBP8d/r9DCt1ZPUMS2lpKaKiovD0009j9OjRd+3v5eWFadOmoUuXLvDy8kJKSgqef/55eHl54bnnnrP002g0OHnyZJXXqtXc5Y+IiBqe1n6NAQDPP9AKswe1h7uSa1zqyurAMmTIEAwZMqTW/aOjoxEdHW15HB4ejk2bNmHfvn1VAoskSQgICLC2HCIiIodQWFaBJo08AACPdw9GxyANOgZpZa7Kedg98qWnp2P//v144IEHqrSXlJQgLCwMwcHBGDZsGNLT0+/4PgaDAXq9vspBRERkb+WVJszZfARDl+3D9dIKADf/CGdYqV92CyzBwcFQqVTo0aMHpk6dismTJ1uei4iIQGJiIrZt24akpCSo1Wr07dsXp0+frvH9Fi5cCK1WazlCQkLscRpEREQWZy6XYOSqH7D2QDby9OXYe+qy3CU5LUkIIe75xZKEzZs3Y+TIkXftm5WVhZKSEvz444945ZVXsHLlSjz55JO37Ws2m9GtWzf0798fy5cvv20fg8EAg8FgeazX6xESEoKioiJoNJp7Oh8iIqLa2pKeizmbj6CswoSmXh5Y+kRX9GvrJ3dZDY5er4dWq73r57fdljW3bNkSANC5c2dcunQJ8+bNqzGwKBQK3HfffXecYVGpVFCpVDaplYiIqCY3KkyYt+0o1qflAABiWjXFsie6ormGC0VsSZZ9WIQQVWZHbve8TqdD586d7VgVERHR3b276yTWp+VAkoDpD7XF9AFtoVRIcpfl9KwOLCUlJcjMzLQ8zsrKgk6ng6+vL0JDQ5GQkIDc3FysXr0aALBq1SqEhoYiIiICwM19Wd555x28+OKLlveYP38+evfujbZt20Kv12P58uXQ6XRYtWpVXc+PiIioXk17qC0OZRfi5YHt0KdNM7nLcRlWB5a0tDTExsZaHs+aNQsAMHHiRCQmJiIvLw/Z2dmW581mMxISEpCVlQU3Nze0bt0aixYtwvPPP2/pU1hYiOeeew75+fnQarWIjo5GcnIyevbsWZdzIyIiqrNSgxGb0nPxf71CIUkStJ7u2DAlBpLEWRV7qtNNt46ktjftEBER1daJfD2mrjmEM5dL8dZjnfBUrzC5S3I6DnfTLRERUUMhhMC6n3Iwb9tRGIxmBGjUaNvcW+6yXBoDCxER0S2KyysxZ/Mv+DLjIgDgwfZ+eHdsV/h6echcmWtjYCEiIvrV0YtFmLrmEM5dLYNSIeHPce3xh36toOAqINkxsBAREf2quNyI7GtlCNKqsSK+G7qH+chdEv2KgYWIiFyaEMKy4qd3q6ZY8WQ39G3T1PJFhuQY+H3XRETksg5fKMSQZfuQWVBiaXukSyDDigNiYCEiIpcjhMDHKVkY/f5+nMgvxqKvT8hdEt0FLwkREZFLKSqrxJ82ZGDnsUsAgMEdA7B4TBeZq6K7YWAhIiKXcSj7Ol5cm47cwhvwUCrw6iMdMCEmjLvWNgAMLERE5BIOZl1D/L9+hNEsENa0EVbFd0OnFlq5y6JaYmAhIiKXEB3aBFEhTRCoVWPhqM7wVrvLXRJZgYGFiIic1uELhYgI0MDDTQF3pQKfPtMTXh5KXgJqgLhKiIiInI7ZLLDq+0w89o/9+PuO/60AaqxyY1hpoDjDQkRETuVKiQGzPs9A8qnLAIBrpRUwmwW312/gGFiIiMhp/Hj2KqYnpaOg2AC1uwJvPNoJj/cI5qyKE2BgISKiBs9kFlj5XSaWfXsKZgG0bd4Yq57qhnb+3nKXRvWEgYWIiBq8vKIb+Ne+szAL4PHuwZg/oiMaefAjzpnw/5tERNTgBfs0wt/HdEF5pQmjugXLXQ7ZAAMLERE1OEaTGcu+PY1eLZvi/rbNAABDOwfKXBXZEpc1ExFRg5JfVI74fx/Aiu8yMXO9DsXllXKXRHbAGRYiImow9pwswKzPM3CttAJeHkq8NjySO9a6CAYWIiJyeJUmM5bsPIUP9p4BAEQGarDqqW5o2cxL5srIXhhYiIjIoZVVGDH+o4P4+fx1AMCEmDDMGdoBanelzJWRPTGwEBGRQ/N0VyLUtxFOXSrG30d3wRDeXOuSJCGEkLuI+qDX66HValFUVASNRiN3OUREVAcVRjPKjSZofr0/pdRgxLXSCoT4NpK5Mqpvtf385iohIiJyKDnXyvD4h6mYtV6H3/6m9lK5May4OF4SIiIih7Hjl3z8aUMGisuN0KjdcP5qGcJ5Yy2BgYWIiByAwWjCwu0nkLj/HAAgOrQJVjwZjWAfzqrQTQwsREQkq/NXSzFtbTqO5BYBAJ7v3wqz49rDXcm7Fuh/GFiIiEg2QghM+ewQjufp4dPIHUvGRuGhCH+5yyIHxPhKRESykSQJCx7rhD6tm2L7jH4MK1QjqwNLcnIyhg8fjqCgIEiShC1bttyxf0pKCvr27YumTZvC09MTEREReO+996r127hxIyIjI6FSqRAZGYnNmzdbWxoRETUAZy+X4OsjeZbH0aE+WDO5FwK1njJWRY7O6sBSWlqKqKgorFy5slb9vby8MG3aNCQnJ+P48eOYO3cu5s6di3/+85+WPqmpqRg3bhzGjx+PjIwMjB8/HmPHjsWBAwesLY+IiBzYlvRcDFuRgpnrdTiep7e0S5IkY1XUENRp4zhJkrB582aMHDnSqteNGjUKXl5e+M9//gMAGDduHPR6Pb7++mtLn8GDB8PHxwdJSUm1ek9uHEdE5LhuVJgwb9tRrE/LAQD0buWLZU9Ew1+jlrkykpvDbhyXnp6O/fv344EHHrC0paamYtCgQVX6xcXFYf/+/TW+j8FggF6vr3IQEZHjOX2pGCNWpWB9Wg4kCZgxoC3WTO7NsEJWsdsqoeDgYFy+fBlGoxHz5s3D5MmTLc/l5+fD37/qjVb+/v7Iz8+v8f0WLlyI+fPn26xeIiKqu40/X8DcLb/gRqUJft4qLBvXFX3aNJO7LGqA7DbDsm/fPqSlpeGDDz7A0qVLq13q+f31SyHEHa9pJiQkoKioyHLk5OTYpG4iIrp3F67fwI1KE+5v0wzbp/djWKF7ZrcZlpYtWwIAOnfujEuXLmHevHl48sknAQABAQHVZlMKCgqqzbrcSqVSQaVS2a5gIiK6J2azgEJx8w/OaQ+1QbCPJx6LbmFpI7oXsuzDIoSAwWCwPI6JicGuXbuq9Nm5cyf69Olj79KIiOgeCSGQdDAboz/Yj/JKEwBAqZAwunswwwrVmdUzLCUlJcjMzLQ8zsrKgk6ng6+vL0JDQ5GQkIDc3FysXr0aALBq1SqEhoYiIiICwM19Wd555x28+OKLlveYMWMG+vfvj8WLF2PEiBHYunUrdu/ejZSUlLqeHxER2UGJwYg5m45gW8ZFAMD6n3IwsU+4vEWRU7E6sKSlpSE2NtbyeNasWQCAiRMnIjExEXl5ecjOzrY8bzabkZCQgKysLLi5uaF169ZYtGgRnn/+eUufPn36YN26dZg7dy7++te/onXr1li/fj169epVl3MjIiI7+CW3CNPWHsK5q2VQKiTMHtQe43uHyV0WOZk67cPiSLgPCxGRfQkh8NmP5/HmV8dRYTIjSKvGivhodA/zlbs0akBq+/nNLz8kIqJ7svzbTLy3+xQA4OEOzfH2mCj4eHnIXBU5K375IRER3ZMxPYLRrLEKcx/pgH9N6MGwQjbFGRYiIqoVIQR+OncdPVvevOTTooknkv/8IBp58KOEbI8zLEREdFdFZZV4/j8/Y+yHqfj2+CVLO8MK2Qt/0oiI6I4OZV/Hi2vTkVt4Ax5KBa6UGO7+IqJ6xsBCRES3ZTYL/DvlLP6+4ySMZoGwpo2w8slu6Byslbs0ckEMLEREVM310gq8/EUGvjtRAAB4pEsgFo7qDI3aXebKyFUxsBARUTU/nr2K704UwMNNgdeGReKpXqF3/EJaIltjYCEiomqGdA7ErIHtMKBDc3QM4iUgkh9XCREREa6UGPDSeh0uF//vhtrpA9oyrJDD4AwLEZGL+/HsVUxPSkdBsQHF5ZX498T75C6JqBoGFiIiF2UyC6z8LhPLvj0FswDaNG+MP8VFyF0W0W0xsBARuaCC4nK8tF6HHzKvAgDGdA/GGyM6ciM4clj8ySQicjHHLuox4eODuFJigKe7En8b2QmjuwfLXRbRHTGwEBG5mNCmjaBRu6FZYw+sjO+GNs0by10S0V0xsBARuYCrJQb4enlAkiQ0Vrkh8emeaK5RQe2ulLs0olrhsmYiIie352QBBr6XjI9/OGdpC23aiGGFGhQGFiIiJ1VpMmPR1ycw6ZOfcK20AtsyLsJkFnKXRXRPeEmIiMgJXSy8gReT0vHz+esAgPG9w/DqIx2gVHB7fWqYGFiIiJzM7mOXMHtDBgrLKuGtcsOi0V3wSJdAucsiqhMGFiIiJ3Kx8Ab+uOZnVJoEOrfQYmV8NMKaesldFlGdMbAQETmRoCae+HNcBHILbyBhaARUbryxlpwDAwsRUQP3zdF8hPo2QodADQDgD/1byVwRUf1jYCEiaqAMRhMWbj+BxP3n0MrPC19Oux9eKv5aJ+fEn2wiogbo/NVSTFubjiO5RQCAARHN4a7kThXkvBhYiIgamP8ezsMrGw+j2GBEk0buWPJ4FAZ08Je7LCKbYmAhImogKoxmvPHVUXz2YzYAoEeYD5Y/GY2gJp4yV0ZkewwsREQNhFIh4ezlUgDACw+2xqyB7eDGy0DkIhhYiIgcnNksoFBIUCokLB3XFSfyi9G/nZ/cZRHZFQMLEZGDulFhwrxtR+HuJuFvIzsDAJpr1GiuUctcGZH9MbAQETmgzIJiTF2TjpOXiiFJwMSYcLT195a7LCLZWH3xMzk5GcOHD0dQUBAkScKWLVvu2H/Tpk0YOHAg/Pz8oNFoEBMTg2+++aZKn8TEREiSVO0oLy+3tjwiogZvw88XMHzFDzh5qRjNGqvw2bO9GFbI5VkdWEpLSxEVFYWVK1fWqn9ycjIGDhyI7du34+eff0ZsbCyGDx+O9PT0Kv00Gg3y8vKqHGo1pz2JyHWUVRgx63MdZn+RgRuVJvRt0xTbZ9yPvm2ayV0akeysviQ0ZMgQDBkypNb9ly5dWuXxggULsHXrVnz55ZeIjo62tEuShICAAGvLISJyCkIITPjoINLOX4dCAmY+3A5TY9tAqZDkLo3IIdh9PZzZbEZxcTF8fX2rtJeUlCAsLAzBwcEYNmxYtRmY3zMYDNDr9VUOIqKGSpIkPNe/Ffw1Kqz9Q29MH9CWYYXoFnYPLEuWLEFpaSnGjh1raYuIiEBiYiK2bduGpKQkqNVq9O3bF6dPn67xfRYuXAitVms5QkJC7FE+EVG9KTEYcfhCoeXxoI4B2DM7Fr1bNZWvKCIHJQkhxD2/WJKwefNmjBw5slb9k5KSMHnyZGzduhUPP/xwjf3MZjO6deuG/v37Y/ny5bftYzAYYDAYLI/1ej1CQkJQVFQEjUZj1XkQEdnb0YtFeHFtOq6XVWD7jH4I1HK3WnJNer0eWq32rp/fdlvWvH79ejz77LP44osv7hhWAEChUOC+++674wyLSqWCSqWq7zKJiGxKCIHPDmTjza+OocJoRqBWjaslFQwsRHdhl8CSlJSEZ555BklJSXjkkUfu2l8IAZ1Oh86dO9uhOiIi+9CXVyJh4xH890gegJvfsPzO41Hw8fKQuTIix2d1YCkpKUFmZqblcVZWFnQ6HXx9fREaGoqEhATk5uZi9erVAG6GlQkTJmDZsmXo3bs38vPzAQCenp7QarUAgPnz56N3795o27Yt9Ho9li9fDp1Oh1WrVtXHORIRye7whUJMW5uO7GtlcFNIeGVIBJ69vyUkiTfWEtWG1TfdpqWlITo62rIkedasWYiOjsZrr70GAMjLy0N2dral/4cffgij0YipU6ciMDDQcsyYMcPSp7CwEM899xw6dOiAQYMGITc3F8nJyejZs2ddz4+IyCGs/ykH2dfK0KKJJ76YEoPJ/VoxrBBZoU433TqS2t60Q0Qkh/JKE9755iRefKgttI3c5S6HyGHU9vOb30tORGQD6dnX8ZcNh2E23/ybUO2uxNxhkQwrRPeIX35IRFSPhBD4974sLN5xAkazQESgN57u21LusogaPAYWIqJ6cr20ArO/yMC3JwoAAI90DsTo7sEyV0XkHBhYiIjqQdq5a5ielI6LReXwcFPgr8Mi8X+9QnljLVE9YWAhIqqj9T9lY87mX2AyC7Rs5oWV8dHoGKSVuywip8LAQkRUR51aaKFUSBjWJRBvPdYZjVX81UpU3/hfFRHRPbhcbICf982vB+kYpMX26f3Q2s+Ll4CIbITLmomIrGAyC6z49jT6/f27Kt+03KZ5Y4YVIhviDAsRUS0VFJfjpfU6/JB5FQDwzdF8dAluIm9RRC6CgYWIqBZ+yLyCGet0uFJigKe7Em+O7IQxXLJMZDcMLEREd2AyCyz79jRWfHcaQgDt/b2xMj4abf295S6NyKUwsBAR3cGXGRex/NvTAIAn7gvB68M7wtNDKXNVRK6HgYWI6A4ejQrC7uOXMDDSHyO6tpC7HCKXxVVCRES3MJrM+FfyWZRVGAEACoWElfHdGFaIZMYZFiKiX10svIHpSelIO38dJ/KLsWRslNwlEdGvGFiIiAB8d+ISZn2egcKySjRWuSE2wk/ukojoFgwsROTSKk1mvP3NSfwz+SwAoHMLLVbGRyOsqZfMlRHRrRhYiMhlXSy8gRfWHIIupxAAMKlPOBKGRkDlxlVARI6GgYWIXJabQkLOtTJo1G74+5goDO4UIHdJRFQDBhYicikms4BScfM7f5pr1PhwfHf4a9QI8W0kc2VEdCdc1kxELuP81VI89o8fsP1InqWtR7gvwwpRA8DAQkQu4b+H8zBseQoOXyjCoq9PoNJklrskIrICLwkRkVMrrzThb/89hs9+zAYAdA/zwYono+Gu5N9rRA0JAwsROa2sK6WYuuYQjuXpAQB/fLA1Zg1sx7BC1AAxsBCRUyrQl2P4ihSUGIzw9fLAu2Oj8GD75nKXRUT3iIGFiJxSc40aY7oH41ieHsufiEaAVi13SURUBwwsROQ0MgtK4KVSIlDrCQCYM7QDFBLgxktARA0e/ysmIqew8ecLGL4iBTOSdDD+ugLIw03BsELkJDjDQkQNWlmFEa9tPYoNP18AALgpJZRWmKD1ZFAhciYMLETUYJ3ML8bUtYeQWVAChQTMfLgdpsa2sexkS0TOg4GFiBocIQQ+T8vBa1uPwmA0o7m3CsueiEZM66Zyl0ZENmL1nGlycjKGDx+OoKAgSJKELVu23LH/pk2bMHDgQPj5+UGj0SAmJgbffPNNtX4bN25EZGQkVCoVIiMjsXnzZmtLIyIXUWEy46OULBiMZvRr2wzbZ/RjWCFyclYHltLSUkRFRWHlypW16p+cnIyBAwdi+/bt+PnnnxEbG4vhw4cjPT3d0ic1NRXjxo3D+PHjkZGRgfHjx2Ps2LE4cOCAteURkQtQuSmxKr4b/jI4Ap8+3RPNGqvkLomIbEwSQoh7frEkYfPmzRg5cqRVr+vYsSPGjRuH1157DQAwbtw46PV6fP3115Y+gwcPho+PD5KSkmr1nnq9HlqtFkVFRdBoNFbVQ0SOTQiBNQeycaPChD/0byV3OURUj2r7+W33e1jMZjOKi4vh6+traUtNTcVLL71UpV9cXByWLl1a4/sYDAYYDAbLY71eX++1EpH8issr8cqmI/jv4TwoFRLub9sMHQL5RwmRq7H7ur8lS5agtLQUY8eOtbTl5+fD39+/Sj9/f3/k5+fX+D4LFy6EVqu1HCEhITarmYjkceRCEYatSMF/D+fBTSHhL4Pbo72/t9xlEZEM7BpYkpKSMG/ePKxfvx7Nm1f9Tg9JqroMUQhRre1WCQkJKCoqshw5OTk2qZmI7E8IgcQfsjD6/f04f7UMLZp44vMpMXiuf2souGSZyCXZ7ZLQ+vXr8eyzz+KLL77Aww8/XOW5gICAarMpBQUF1WZdbqVSqaBS8UY7ImcjhMCMdTpsy7gIABgY6Y93xkRB28hd5sqISE52mWFJSkrCpEmTsHbtWjzyyCPVno+JicGuXbuqtO3cuRN9+vSxR3lE5EAkSUKPcB+4KyW8NiwS/xzfnWGFiKyfYSkpKUFmZqblcVZWFnQ6HXx9fREaGoqEhATk5uZi9erVAG6GlQkTJmDZsmXo3bu3ZSbF09MTWq0WADBjxgz0798fixcvxogRI7B161bs3r0bKSkp9XGOROTghBC4XGxAc83Nb1Qe3zsM97dphlZ+jWWujIgchdUzLGlpaYiOjkZ0dDQAYNasWYiOjrYsUc7Ly0N2dral/4cffgij0YipU6ciMDDQcsyYMcPSp0+fPli3bh0++eQTdOnSBYmJiVi/fj169epV1/MjIgdXWFaBP6xOw5gPUqEvrwRwc5aFYYWIblWnfVgcCfdhIWp4fj5/DS+uTcfFonJ4KBX418QeeKCdn9xlEZEdOew+LEREZrPAh8ln8c7OkzCZBVo288LK+Gh0DNLKXRoROSgGFiKyq6slBrz8RQb2nLwMAHg0KggLRnVGYxV/HRFRzfgbgojsasH2E9hz8jJUbgrMe7Qjnrgv5I57LhERAQwsRGRnc4ZGIF9/A3MfieQW+0RUa3bfmp+IXMvlYgM+SsmyPG7aWIU1k3szrBCRVTjDQkQ2sz/zCmas1+FysQE+jdwxqluw3CURUQPFwEJE9c5kFlj27Wms+O40hADa+TdG5xZcAURE946BhYjq1SV9OWasS8ePZ68BAMb1CMG8RzvC00Mpc2VE1JAxsBBRvfkh8wqmJ6XjamkFGnkoseCxzhgZ3ULusojICTCwEFG9MZoFrpZWoEOgBqvio7m9PhHVGwYWIqoTo8kMN+XNBYcPtPPDP8d3R/92flC78xIQEdUfLmsmonv23YlLGPDuXuRcK7O0DeoYwLBCRPWOgYWIrFZpMmPB9uN4JjEN56+WYeV3mXKXREROjpeEiMgqF66X4cWkdKRnFwIAJvUJR8LQCHmLIiKnx8BCRLW282g+Zn+RAX25Ed5qN7w9pgsGdwqUuywicgEMLERUKzt+yceUz34GAEQFa7EyvhtCfBvJXBURuQoGFiKqldgIP3RuoUWvlr748+AIeLjxFjgish8GFiKq0Q+ZV9CrpS/clAqo3JT4YkoMVwARkSz4JxIRVVNeacJrW3/BU/8+gGXfnra0M6wQkVw4w0JEVWRdKcW0tYdw9KIewM3da4UQkCRJ5sqIyJUxsBCRxbaMi5iz6QhKDEb4enlgydgoxLZvLndZREQMLER08xLQ/C+PIelgNgCgZ7gvlj8ZjQCtWubKiIhuYmAhIly4fgOb0y9AkoBpsW0wY0Bby/cDERE5AgYWIkKb5o3x9zFR8Gnkjn5t/eQuh4ioGv4JReSCyiqMeGXjYaSdu2ZpezQqiGGFiBwWAwuRizl1qRgjVv6AdT/lYMY6HSqMZrlLIiK6K14SInIRQgh8kXYBr237BeWVZvh5q/DO41HcsZaIGgQGFiIXUGowYu6WX7A5PRcA0K9tM7w3riuaNVbJXBkRUe0wsBA5uaslBjz+QSrOXimFQgJeHtQef3ygNRQKbgRHRA0HAwuRk/P18kA7f2+UVZiw/Mlo9GzpK3dJRERWY2AhckLF5ZUAAG+1OyRJwuIxXWAyC/h6echcGRHRvbH6brvk5GQMHz4cQUFBkCQJW7ZsuWP/vLw8xMfHo3379lAoFJg5c2a1PomJiZAkqdpRXl5ubXlELu+X3CIMX5GCVzYdgRACAKD1dGdYIaIGzerAUlpaiqioKKxcubJW/Q0GA/z8/PDqq68iKiqqxn4ajQZ5eXlVDrWa24IT1ZYQAp/uP4dR/9iPc1fLoMsuxJWSCrnLIiKqF1ZfEhoyZAiGDBlS6/7h4eFYtmwZAODjjz+usZ8kSQgICLC2HCICUHSjEn/ZcBg7juYDAB7u4I93Hu+CJo04q0JEzsFh7mEpKSlBWFgYTCYTunbtijfffBPR0dE19jcYDDAYDJbHer3eHmUSORxdTiGmrT2EC9dvwF0pIWFIBzzdNxySxFVAROQ8HGLHqIiICCQmJmLbtm1ISkqCWq1G3759cfr06Rpfs3DhQmi1WssREhJix4qJHEOlyWwJKyG+ntgwpQ+eub8lwwoROR2HCCy9e/fG//3f/yEqKgr9+vXD559/jnbt2mHFihU1viYhIQFFRUWWIycnx44VEzkGd6UC7zwehUe6BOKrF/shKqSJ3CUREdmEw1wSupVCocB99913xxkWlUoFlYq7dJLr+fn8dVwuLsfgToEAgN6tmqJ3q6YyV0VEZFsOGViEENDpdOjcubPcpRA5DLNZ4J/7zuLtb05C5aZAW39vtPZrLHdZRER2YXVgKSkpQWZmpuVxVlYWdDodfH19ERoaioSEBOTm5mL16tWWPjqdzvLay5cvQ6fTwcPDA5GRkQCA+fPno3fv3mjbti30ej2WL18OnU6HVatW1fH0iJzDtdIKzPpchz0nLwMABnTwR3NvzjASkeuwOrCkpaUhNjbW8njWrFkAgIkTJyIxMRF5eXnIzs6u8ppbV/v8/PPPWLt2LcLCwnDu3DkAQGFhIZ577jnk5+dDq9UiOjoaycnJ6Nmz572cE5FTOZh1DdOT0pGvL4fKTYHXh3fEkz1DeGMtEbkUSfy2FWYDp9frodVqUVRUBI1GI3c5RPVi1feZWLLzJMwCaOXnhVXx3dAhkD/fROQ8avv57ZD3sBDRTcXlRpgFMCq6Bd4c2QleKv4nS0Suib/9iByM0WSGm/LmjgMvD2qHbqFNMDDSn5eAiMilOcQ+LEQEmMwC7+06hbEfpqLCaAZwc5+VQR0DGFaIyOVxhoXIARToyzF9XTp+PHsNALDzWD6GdQmSuSoiIsfBwEIks+RTl/HSeh2ullagkYcSbz3WiWGFiOh3GFiIZGI0mfHe7lP4x54zEAKICPDGyvhuaNOcm8EREf0eAwuRTOZ9eRSf/Xhzz6L4XqF4bVgk1O5KmasiInJMDCxEMpl8fyvsPlaAOY90wKNRvARERHQnDCxEdlJpMuPHs1fRr60fACC8mRf2/vlBqNw4q0JEdDdc1kxkB7mFNzDuw1RM+PggUk5fsbQzrBAR1Q5nWIhsbNexS5j9RQaKblTCW+2G8kqT3CURETU4DCxENlJhNGPxjhP4KCULABAVrMXK+G4I8W0kc2VERA0PAwuRDeRcK8O0tYeQcaEIAPDs/S3xl8ER8HDjVVgionvBwEJkAz+evYqMC0XQerrjncejMDDSX+6SiIgaNAYWIhsY0z0YBcUGjIxugRZNPOUuh4ioweP8NFE9OHelFJM/TcP10goAgCRJmBrbhmGFiKieMLAQ1dG2jIsYtiIFu49fwpv/PSZ3OURETomXhIjuUXmlCfO/PIakgze31+8Z7os/x0XIXBURkXNiYCG6B2cul2DqmkM4kV8MSQKmPtgGMx9uCzclJy2JiGyBgYXISqlnruLZT39CWYUJzRp74L1xXS3b7RMRkW0wsBBZKTJQA59GHogKboRlT3RFc41a7pKIiJweAwtRLVwsvIFArRqSJEHbyB3rn++NQK0nlApJ7tKIiFwCL7gT3YEQAp+n5eChJXuQdDDH0h7s04hhhYjIjhhYiGpQajDi5c8z8OcNh1Feacb3JwsghJC7LCIil8RLQkS3cTxPj6lrD+Hs5VIoJODlQe3xxwdaQ5I4q0JEJAcGFqJbCCGQdDAH8788CoPRjACNGsufjEbPlr5yl0ZE5NIYWIhucepSCeZuOQKzAGLb+2HJ2K7w9fKQuywiIpfHwEJ0i/YB3pg1sB3clQr8oV8rKHhjLRGRQ2BgIZcmhMBnB7LRt3VTtPJrDACY9lBbmasiIqLfY2Ahl1V0oxIJmw5j+5F8dAjUYPMLfaB2V8pdFhER3QYDC7mkjJxCTEs6hJxrN+CulPB492Co3LjKn4jIUVn9Gzo5ORnDhw9HUFAQJEnCli1b7tg/Ly8P8fHxaN++PRQKBWbOnHnbfhs3bkRkZCRUKhUiIyOxefNma0sjuishBD5KycKYD/Yj59oNhPh6YsOUPnjm/pZcskxE5MCsDiylpaWIiorCypUra9XfYDDAz88Pr776KqKiom7bJzU1FePGjcP48eORkZGB8ePHY+zYsThw4IC15RHVqMRgxHP/+RlvfnUMlSaBIZ0C8NWL/RAV0kTu0oiI6C4kUYetOyVJwubNmzFy5Mha9X/wwQfRtWtXLF26tEr7uHHjoNfr8fXXX1vaBg8eDB8fHyQlJdXqvfV6PbRaLYqKiqDRaGp7CuRCKk1mjPswFb/k6vHXYR3wf73DOKtCRCSz2n5+O8Q9LKmpqXjppZeqtMXFxVULNrcyGAwwGAyWx3q93lblUQNmNguYhYCbUgF3pQIr4rvhemkFOrXQyl0aERFZwSHuMszPz4e/v3+VNn9/f+Tn59f4moULF0Kr1VqOkJAQW5dJDcy10gpMXp2Gv39z0tLWooknwwoRUQPkEIEFQLWpeSHEHafrExISUFRUZDlycnJq7Euu52DWNQxdtg/fnSjA6tRzyC8ql7skIiKqA4e4JBQQEFBtNqWgoKDarMutVCoVVCqVrUujBsZsFnh/7xm8u+sUTGaBVn5eWBXfDQFatdylERFRHTjEDEtMTAx27dpVpW3nzp3o06ePTBVRQ3SlxICJnxzE29+chMksMCq6Bb6cdj86BPImbCKihs7qGZaSkhJkZmZaHmdlZUGn08HX1xehoaFISEhAbm4uVq9ebemj0+ksr718+TJ0Oh08PDwQGRkJAJgxYwb69++PxYsXY8SIEdi6dSt2796NlJSUOp4euQqjyYyxH6Ti7JVSqN0VeGNEJzzePZirgIiInITVy5r37NmD2NjYau0TJ05EYmIiJk2ahHPnzmHPnj3/+0du86ERFhaGc+fOWR5v2LABc+fOxdmzZ9G6dWu89dZbGDVqVK3r4rJm2qrLxarvM7Eqvhva+nvLXQ4REdVCbT+/67QPiyNhYHE9BcXlyCssr7LxW4XRDA9usU9E1GDU9vObv9mpQUo5fQVDl+3D5NVpuFz8v/14GFaIiJyTQ6wSIqoto8mMpbtPY9WeTAgBRAR4o6zCCIArxoiInBkDCzUY+UXlmL4uHQezrgEA4nuF4rVhkVC7K2WujIiIbI2BhRqEPScLMOvzDFwrrUBjlRsWjOqMR6OC5C6LiIjshIGFGoStuou4VlqBTi00WPlkN4Q385K7JCIisiMGFmoQ3hzZCeFNvTDlwVZQufESEBGRq+GSCnJIu49dwuwvMvDbqvvGKjfMeLgtwwoRkYviDAs5lAqjGYt3nMBHKVkAgD6tm2JUt2CZqyIiIrkxsJDDyLlWhmlJ6cjIKQQAPHt/SwzrwhtriYiIgYUcxI5f8vCnDYdRXG6E1tMd7zwehYGRNX9bNxERuRYGFpLdim9PY8muUwCAbqFNsPzJaAT7NJK5KiIiciS86ZZk17dtM7grJTz/QCusfz6GYYWIiKrhDAvJ4sL1Mksw6Rbqg+9nP8igQkRENeIMC9lVeaUJr24+ggFL9uJEvt7SzrBCRER3whkWspszl0swdc0hnMgvhiQBB7OuISKg5q8SJyIi+g0DC9nFlvRczNl8BGUVJjRr7IH3xnVFv7Z+cpdFREQNBAML2dSNChPmbTuK9Wk5AICYVk2x7ImuaK5Ry1wZERE1JAwsZFPrf8rG+rQcSBIwY0BbvPhQWygVktxlERFRA8PAQjY1PiYc6TmFGHdfCPq0biZ3OURE1EBxlRDVq1KDEe/uOoXyShMAQKmQsOyJaIYVIiKqE86wUL05ka/H1DWHcOZyKQrLKvDGiE5yl0RERE6CgYXqTAiBdT/lYN62ozAYzfDXqPBI50C5yyIiIifCwEJ1UmIwYs6mI9iWcREA8GB7Pyx5PApNG6tkroyIiJwJAwvds1OXivHc6jScu1oGpULCn+Pa4w/9WkHBVUBERFTPGFjonjXyUOJ6WSWCtGqsiO+G7mE+cpdEREROioGFrFJhNMPD7ebismCfRvh4Ug+09muMJo08ZK6MiIicGZc1U60dvlCIge/txXcnLlnauof5MqwQEZHNMbDQXQkh8HFKFka/vx/nr5Zh6e7TEELIXRYREbkQXhKiOyoqq8SfNmRg57GbsyqDOwZg8ZgukCTeWEtERPbDwEI1OpR9HS+uTUdu4Q14KBWYO6wDxvcOY1ghIiK7Y2Ch2zpzuQRjP0iF0SwQ1rQRVsV3Q6cWWrnLIiIiF2X1PSzJyckYPnw4goKCIEkStmzZctfX7N27F927d4darUarVq3wwQcfVHk+MTERkiRVO8rLy60tj+pJa7/GGNM9GMO6BOKrF+9nWCEiIllZPcNSWlqKqKgoPP300xg9evRd+2dlZWHo0KH4wx/+gM8++ww//PADXnjhBfj5+VV5vUajwcmTJ6u8Vq1WW1se1UHauWsIb+aFZr/uUvvmyE5wU0i8BERERLKzOrAMGTIEQ4YMqXX/Dz74AKGhoVi6dCkAoEOHDkhLS8M777xTJbBIkoSAgABry6F6YDYLvL/3DN7ddQp9WjfFp0/3hEIhwV3JRWREROQYbP6JlJqaikGDBlVpi4uLQ1paGiorKy1tJSUlCAsLQ3BwMIYNG4b09PQ7vq/BYIBer69ykPWulBgwKfEnvP3NSZjMAk29PFBhMstdFhERURU2Dyz5+fnw9/ev0ubv7w+j0YgrV64AACIiIpCYmIht27YhKSkJarUaffv2xenTp2t834ULF0Kr1VqOkJAQm56HM/rx7FUMXbYPyacuQ+2uwN9Hd8F747pC7a6UuzQiIqIq7LJK6Pf3QPy26dhv7b1790bv3r0tz/ft2xfdunXDihUrsHz58tu+Z0JCAmbNmmV5rNfrGVpqyWQWWPldJpZ9ewpmAbRt3hirnuqGdv7ecpdGRER0WzYPLAEBAcjPz6/SVlBQADc3NzRt2vS2r1EoFLjvvvvuOMOiUqmgUqnqtVZXUV5pwub0CzAL4PHuwZg/oiMaeXCFOxEROS6bf0rFxMTgyy+/rNK2c+dO9OjRA+7u7rd9jRACOp0OnTt3tnV5LslL5YaV8d1w6lIxRnULlrscIiKiu7L6HpaSkhLodDrodDoAN5ct63Q6ZGdnA7h5qWbChAmW/lOmTMH58+cxa9YsHD9+HB9//DE++ugjzJ4929Jn/vz5+Oabb3D27FnodDo8++yz0Ol0mDJlSh1PjwDAaDJjyc6T+HT/OUtbpxZahhUiImowrJ5hSUtLQ2xsrOXxb/eRTJw4EYmJicjLy7OEFwBo2bIltm/fjpdeegmrVq1CUFAQli9fXmVJc2FhIZ577jnk5+dDq9UiOjoaycnJ6NmzZ13OjQDkF5Vj+rp0HMy6BnelhAEdmiPYp5HcZREREVlFEk7ytbt6vR5arRZFRUXQaDRyl+MQ9pwswKzPM3CttAJeHkosHN0Fj0YFyV0WERGRRW0/v3mnpROqNJmxZOcpfLD3DACgY5AGK+O7oWUzL5krIyIiujcMLE7GbBb4v38fwIGsawCACTFhmDO0A/dWISKiBo2BxckoFBJiI5rj2EU9Fo/pgqGdA+UuiYiIqM4YWJxAhdGMKyUGBDXxBAA8168VRnZtgQAtvzySiIicA7/droHLuVaGxz9MxYSPD6Kswgjg5iwLwwoRETkTBpYGbMcv+Ri6fB8ycgpRoC/H6UslcpdERERkE7wk1AAZjCYs3H4Cib9uBBcd2gQrnozm/ipEROS0GFgamPNXSzFtbTqO5BYBAJ7v3wqz49rDXcnJMiIicl4MLA3M3/57HEdyi+DTyB1LxkbhoQh/uUsiIiKyOQaWBuZvIztBIQHzHu2IQK2n3OUQERHZBa8jOLgzl0vwz+Qzlsf+GjU+HN+DYYWIiFwKZ1gc2Jb0XMzZfARlFSaE+jbC4E7cBI6IiFwTA4sDulFhwrxtR7E+LQcA0LuVL6JDfWSuioiISD4MLA4ms6AYU9ek4+SlYkgSMP2htpg+oC2UCknu0oiIiGTDwOJAtupy8crGI7hRaYKftwrLxnVFnzbN5C6LiIhIdgwsDkTtrsSNShPub9MM743rCj9vldwlEREROQQGFpkZjCao3JQAgLiOAVj9TE/0bdOMl4CIiIhuwWXNMhFCIOlgNmLf3oO8ohuW9v7t/BhWiIiIfoeBRQYlBiNmrNMhYdMRXCwqx2c/npe7JCIiIofGS0J2dvRiEaatTUfWlVIoFRL+FNcez/VrJXdZREREDo2BxU6EEPjsQDbe/OoYKoxmBGnVWBEfje5hvnKXRkRE5PAYWOxk7cFs/HXLLwCAhzs0x9tjouDj5SFzVURERA0DA4udjIoOxtoD2XgsugWevb8lJIk31hIREdUWA4uNCCGw45d8xHUMgEIhwdNDia1T+8JNyfuciYiIrMVPTytNmjQJkiRh0aJFVdq3bNlimTX5asduKBQKPP9RMt7f+79vWnZTKhAeHo6lS5fas2QiIqIGj4HlHqjVaixevBjXr1+v9lx69nW8sukwAMBdqYC3mpNYREREdcXAcg8efvhhBAQEYOHChZY2IQQA4PEPUnGlxAAAWP1MT0yICZejRCIiIqfCwHIPlEolFixYgBUrVuDChQu4XlqBVd9nAgCMZoHerZoCADq20MpZJhERkdNgYLlHjz32GLp27YrXX38duYU3cOyiHgDw1mOdMGNAWwBAcHAwGjduXOXIzs6Ws2wiIqIGiYGlDhYvXoxPP/0UiqJcTOwbDgB4qleY5ebbffv2QafTVTmCgoJkrJiIiKhh4h2hd2IyAfv2AXl5QGAg0K8fAKDCaMbkT9MwfUAXxMXFYc6cOZg0aVK1l7ds2RJNmjSp0ubmxiEnIiKyltUzLMnJyRg+fDiCgoIgSRK2bNly19fs3bsX3bt3h1qtRqtWrfDBBx9U67Nx40ZERkZCpVIhMjISmzdvtra0+rVpExAeDsTGAvHxN/9veDguZ2Yj9exV7D5+CX/64jAWLFiIL7/8Evv375e3XiIiIidmdWApLS1FVFQUVq5cWav+WVlZGDp0KPr164f09HTMmTMH06dPx8aNGy19UlNTMW7cOIwfPx4ZGRkYP348xo4diwMHDlhbXv3YtAkYMwa4cMHSZJIUWBbWD8mFEgxGM9o0b4zlT0YjKqoLnnrqKaxYsUKeWomIiFyAJH5bj3svL5YkbN68GSNHjqyxz1/+8hds27YNx48ft7RNmTIFGRkZSE1NBQCMGzcOer0eX3/9taXP4MGD4ePjg6SkpFrVotfrodVqUVRUBI1Gc28nBNy8DBQeXiWsFHg1wcxhf8L+8Chc+e97CLiWg8OZh9HIUwUAOH/+PNq3bw+DwQAhBPbs2YPY2Fhcv3692iWh8PBwzJw5EzNnzrz3GomIiJxEbT+/bX7TbWpqKgYNGlSlLS4uDmlpaaisrLxjnztdZjEYDNDr9VWOerFvX5WwkqP1x9BJK7A/PAqeFeX4VAhkXjyFRgdSLX3CwsJQXl5u2YvlwQcfhBCiWlgBgHPnzjGsEBERWcnmgSU/Px/+/v5V2vz9/WE0GnHlypU79snPz6/xfRcuXAitVms5QkJC6qfgvLwqD1sUFaDTpTNof/kcvvx0JkYf/e62/YiIiMh27LJk5fffTPzbTMSt7bfrc6dvNE5ISMCsWbMsj/V6ff2ElsDAKg8VEFj25dvwMBnhaTTU2I+IiIhsx+aBJSAgoNpMSUFBAdzc3NC0adM79vn9rMutVCoVVCpV/Rfcrx8QHAzk5gK/BiutofR/z0vSzed/XeJMREREtmfzS0IxMTHYtWtXlbadO3eiR48ecHd3v2OfPn362Lq86pRKYNmym//79zM8vz1euvRmPyIiIrILqwNLSUmJZddW4OayZZ1OZ9lyPiEhARMmTLD0nzJlCs6fP49Zs2bh+PHj+Pjjj/HRRx9h9uzZlj4zZszAzp07sXjxYpw4cQKLFy/G7t275bs5ddQoYMMGoEWLqu3BwTfbR42Spy4iIiIXZfWy5t+W7P7exIkTkZiYiEmTJuHcuXPYs2eP5bm9e/fipZdewtGjRxEUFIS//OUvmDJlSpXXb9iwAXPnzsXZs2fRunVrvPXWWxhlRTCot2XNt7rdTrecWSEiIqo3tf38rtM+LI7EJoGFiIiIbMph9mEhIiIiqisGFiIiInJ4DCxERETk8BhYiIiIyOExsBAREZHDY2AhIiIih8fAQkRERA6PgYWIiIgcHgMLEREROTybf1uzvfy2Ya9er5e5EiIiIqqt3z6377bxvtMEluLiYgBASEiIzJUQERGRtYqLi6HVamt83mm+S8hsNuPixYvw9vaGJEn19r56vR4hISHIycnhdxTVEsfMOhwv63C8rMPxsg7Hy3p1HTMhBIqLixEUFASFouY7VZxmhkWhUCA4ONhm76/RaPjDayWOmXU4XtbheFmH42Udjpf16jJmd5pZ+Q1vuiUiIiKHx8BCREREDo+B5S5UKhVef/11qFQquUtpMDhm1uF4WYfjZR2Ol3U4Xtaz15g5zU23RERE5Lw4w0JEREQOj4GFiIiIHB4DCxERETk8BhYiIiJyeC4VWBYuXIj77rsP3t7eaN68OUaOHImTJ09W6VNSUoJp06YhODgYnp6e6NChA95///27vvfGjRsRGRkJlUqFyMhIbN682VanYTe2Gq+jR49i9OjRCA8PhyRJWLp0qQ3Pwn5sNV7/+te/0K9fP/j4+MDHxwcPP/wwDh48aMtTsRtbjdmmTZvQo0cPNGnSBF5eXujatSv+85//2PJU7MKWv8N+s27dOkiShJEjR9Zz9fZnq/FKTEyEJEnVjvLycluejs3Z8uersLAQU6dORWBgINRqNTp06IDt27dbV6BwIXFxceKTTz4Rv/zyi9DpdOKRRx4RoaGhoqSkxNJn8uTJonXr1uL7778XWVlZ4sMPPxRKpVJs2bKlxvfdv3+/UCqVYsGCBeL48eNiwYIFws3NTfz444/2OC2bsdV4HTx4UMyePVskJSWJgIAA8d5779nhbGzPVuMVHx8vVq1aJdLT08Xx48fF008/LbRarbhw4YI9TsumbDVm33//vdi0aZM4duyYyMzMFEuXLhVKpVLs2LHDHqdlM7Yar9+cO3dOtGjRQvTr10+MGDHChmdiH7Yar08++URoNBqRl5dX5WjobDVeBoNB9OjRQwwdOlSkpKSIc+fOiX379gmdTmdVfS4VWH6voKBAABB79+61tHXs2FG88cYbVfp169ZNzJ07t8b3GTt2rBg8eHCVtri4OPHEE0/Ub8Eyq6/xulVYWJjTBJbfs8V4CSGE0WgU3t7e4tNPP623Wh2FrcZMCCGio6Otfo2jq8/xMhqNom/fvuLf//63mDhxolMElt+rr/H65JNPhFartVWZDqO+xuv9998XrVq1EhUVFXWqx6UuCf1eUVERAMDX19fSdv/992Pbtm3Izc2FEALff/89Tp06hbi4uBrfJzU1FYMGDarSFhcXh/3799umcJnU13i5CluNV1lZGSorK6u8r7OwxZgJIfDtt9/i5MmT6N+/v03qlkt9jtcbb7wBPz8/PPvsszatWU71OV4lJSUICwtDcHAwhg0bhvT0dJvWLof6Gq9t27YhJiYGU6dOhb+/Pzp16oQFCxbAZDJZV1Cd4k4DZjabxfDhw8X9999fpd1gMIgJEyYIAMLNzU14eHiI1atX3/G93N3dxZo1a6q0rVmzRnh4eNR73XKpz/G6lbPOsNhqvIQQ4oUXXhCtW7cWN27cqM+SZVffY1ZYWCi8vLyEm5ubUKlU4qOPPrJV6bKoz/FKSUkRLVq0EJcvXxZCCKecYanP8UpNTRX/+c9/hE6nE8nJyWL06NHC09NTnDp1ypanYFf1OV7t27cXKpVKPPPMMyItLU0kJSUJX19fMX/+fKtqctnA8sILL4iwsDCRk5NTpf3tt98W7dq1E9u2bRMZGRlixYoVonHjxmLXrl01vpe7u7tYu3ZtlbbPPvtMqFQqm9Quh/ocr1s5a2Cx1XgtXrxY+Pj4iIyMDFuULav6HjOTySROnz4t0tPTxTvvvCO0Wq34/vvvbXgG9lVf46XX60V4eLjYvn27pc0ZA4ut/psU4ubPWlRUlHjxxRfru2zZ1Od4tW3bVoSEhAij0WhpW7JkiQgICLCqJpcMLNOmTRPBwcHi7NmzVdrLysqEu7u7+Oqrr6q0P/vssyIuLq7G9wsJCRHvvvtulbZ3331XhIaG1l/RMqrv8bqVMwYWW43X22+/LbRarfjpp5/qtV5HYMufsVtfM2jQoDrX6gjqc7zS09MFAKFUKi2HJElCkiShVCpFZmamzc7DXuzx8zV58uRq9zI2VPU9Xv379xcDBgyo0rZ9+3YBQBgMhlrX5VL3sAghMG3aNGzatAnfffcdWrZsWeX5yspKVFZWQqGoOixKpRJms7nG942JicGuXbuqtO3cuRN9+vSpv+JlYKvxcla2HK+3334bb775Jnbs2IEePXrUe+1ysefPmBACBoOhzjXLyRbjFRERgSNHjkCn01mORx99FLGxsdDpdAgJCbHZ+diavX6+hBDQ6XQIDAysl7rlYqvx6tu3LzIzM6v0OXXqFAIDA+Hh4WFVgS7jj3/8o9BqtWLPnj1VlqKVlZVZ+jzwwAOiY8eO4vvvvxdnz54Vn3zyiVCr1eIf//iHpc/48ePFK6+8Ynn8ww8/CKVSKRYtWiSOHz8uFi1a5BTLmm01XgaDQaSnp4v09HQRGBgoZs+eLdLT08Xp06ften71zVbjtXjxYuHh4SE2bNhQ5X2Li4vten62YKsxW7Bggdi5c6c4c+aMOH78uFiyZIlwc3MT//rXv+x6fvXNVuP1e85ySchW4zVv3jyxY8cOcebMGZGeni6efvpp4ebmJg4cOGDX86tvthqv7Oxs0bhxYzFt2jRx8uRJ8dVXX4nmzZuLv/3tb1bV51KBBcBtj08++cTSJy8vT0yaNEkEBQUJtVot2rdvL5YsWSLMZrOlzwMPPCAmTpxY5b2/+OIL0b59e+Hu7i4iIiLExo0b7XRWtmOr8crKyrrt+z7wwAP2OzkbsNV4hYWF3fZ9X3/9dfudnI3YasxeffVV0aZNG6FWq4WPj4+IiYkR69ats+OZ2YYtf4fdylkCi63Ga+bMmSI0NFR4eHgIPz8/MWjQILF//347nplt2PLna//+/aJXr15CpVKJVq1aibfeeqvKPS21If1aJBEREZHDcql7WIiIiKhhYmAhIiIih8fAQkRERA6PgYWIiIgcHgMLEREROTwGFiIiInJ4DCxERETk8BhYiIiIyOExsBAREZHDY2AhIiIih8fAQkRERA6PgYWIiIgc3v8DGhb890ghI2gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn=nn_model()\n",
    "optimal_dists, wachter_dists = [], []\n",
    "optimal_probs,  wachter_probs = [], [] \n",
    "for i in range(50):\n",
    "    X_point = dataset.iloc[i,:-1]\n",
    "    y_point = dataset.iloc[i,-1]\n",
    "    if y_point.item() == 0:\n",
    "        nn, optimal_datapt = optimal_point(dataset, nn, desired_class=1, original_class=0, threshold=25000, chosen_row=i, point_epsilon=1e-4, epsilon=1e-3)\n",
    "\n",
    "        target_class=1\n",
    "        explainer2 = Counterfactual(nn, shape=shape, target_proba=target_proba, tol=tol,\n",
    "                            target_class=target_class)\n",
    "        #print(np.reshape(X_point, (1,-1)).shape)\n",
    "        cf = explainer2.explain(np.reshape(X_point, (1,-1)))\n",
    "        cf_point = cf.data['cf']['X'] \n",
    "        cf_pt_probs = nn.predict(cf_point)\n",
    "        opt_pt_probs = nn.predict(optimal_datapt)\n",
    "        optimal_probs.append(opt_pt_probs)\n",
    "        wachter_probs.append(cf_pt_probs)\n",
    "        optimal_dists.append(euclidean_distance(X_point, optimal_datapt))\n",
    "        wachter_dists.append(euclidean_distance(X_point, cf_point))\n",
    "        # print(cf_point)\n",
    "        # print(income_nn.predict(np.reshape(X_point, (1,-1))))\n",
    "        # print(\"DISTANCE:\", euclidean_distance(X_point, cf_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89b34881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " income\n",
      "0    19820\n",
      "1    19820\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 39640 samples\n",
      "   32/39640 [..............................] - ETA: 32s - loss: 20.3008 - acc: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_28144\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39640/39640 [==============================] - 0s 12us/sample - loss: 1.1345 - acc: 0.6453\n",
      "Model training complete.\n",
      "boundary points started generation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(50000, 8)\n",
      "(49828, 8)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00281488 0.         0.         1.0025203  0.         0.\n",
      "  1.01289627 1.00217704]]\n",
      "[[-0.55255127  0.          0.         -0.65942383  0.          0.\n",
      "  -0.08514404 -0.85144043]]\n",
      "EUCLIDEAN DISTANCE FOR NEAREST CF 1.2163950796579504\n",
      "(1, 8)\n",
      "[[31.993063    1.9982318   6.9935513   0.98225963  4.998277    1.0076674\n",
      "   1.3239831  50.0078    ]]\n",
      "[[0.5802779  0.41972202]]\n",
      "DISTANCE: 0.3248002488569878\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "income_nn=nn_model()\n",
    "income_nn, optimal_datapt = optimal_point(dataset, income_nn, desired_class=1, original_class=0, threshold=50000, chosen_row=2, point_epsilon=1e-3, epsilon=1e-3)\n",
    "X_point = dataset.iloc[2,:-1]\n",
    "target_class=1\n",
    "explainer2 = Counterfactual(income_nn, shape=shape, target_proba=target_proba, tol=tol,\n",
    "                    target_class=target_class)\n",
    "print(np.reshape(X_point, (1,-1)).shape)\n",
    "cf = explainer2.explain(np.reshape(X_point, (1,-1)))\n",
    "cf_point = cf.data['cf']['X'] \n",
    "print(cf_point)\n",
    "print(income_nn.predict(np.reshape(X_point, (1,-1))))\n",
    "print(\"DISTANCE:\", euclidean_distance(X_point, cf_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5838f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50962937 0.49037063]]\n"
     ]
    }
   ],
   "source": [
    "print(income_nn.predict(cf_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0a42623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49997294 0.50002706]]\n"
     ]
    }
   ],
   "source": [
    "print(income_nn.predict(np.reshape(optimal_datapt, (1,-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe54e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " income\n",
      "0    19820\n",
      "1    19820\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 39640 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_24992\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39640/39640 [==============================] - 0s 3us/sample - loss: 5.2444 - acc: 0.4918\n",
      "Epoch 2/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.8096 - acc: 0.5339\n",
      "Epoch 3/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.6457 - acc: 0.6597\n",
      "Epoch 4/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.6335 - acc: 0.6711\n",
      "Epoch 5/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.6247 - acc: 0.6811\n",
      "Epoch 6/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.6168 - acc: 0.6859\n",
      "Epoch 7/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.6097 - acc: 0.6903\n",
      "Epoch 8/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.6031 - acc: 0.6951\n",
      "Epoch 9/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5977 - acc: 0.6975\n",
      "Epoch 10/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5927 - acc: 0.6981\n",
      "Epoch 11/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5794 - acc: 0.6987\n",
      "Epoch 12/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5667 - acc: 0.7013\n",
      "Epoch 13/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5616 - acc: 0.7037\n",
      "Epoch 14/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5579 - acc: 0.7047\n",
      "Epoch 15/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5550 - acc: 0.7077\n",
      "Epoch 16/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5528 - acc: 0.7089\n",
      "Epoch 17/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5516 - acc: 0.7097\n",
      "Epoch 18/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5503 - acc: 0.7110\n",
      "Epoch 19/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5485 - acc: 0.7128\n",
      "Epoch 20/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5473 - acc: 0.7124\n",
      "Epoch 21/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5465 - acc: 0.7132\n",
      "Epoch 22/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5456 - acc: 0.7137\n",
      "Epoch 23/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5449 - acc: 0.7139\n",
      "Epoch 24/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5440 - acc: 0.7150\n",
      "Epoch 25/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5431 - acc: 0.7165\n",
      "Epoch 26/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5424 - acc: 0.7162\n",
      "Epoch 27/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5421 - acc: 0.7169\n",
      "Epoch 28/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5409 - acc: 0.7175\n",
      "Epoch 29/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5407 - acc: 0.7184\n",
      "Epoch 30/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5399 - acc: 0.7184\n",
      "Epoch 31/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5395 - acc: 0.7178\n",
      "Epoch 32/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5383 - acc: 0.7182\n",
      "Epoch 33/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5381 - acc: 0.7189\n",
      "Epoch 34/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5372 - acc: 0.7198\n",
      "Epoch 35/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5362 - acc: 0.7202\n",
      "Epoch 36/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5354 - acc: 0.7201\n",
      "Epoch 37/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5344 - acc: 0.7209\n",
      "Epoch 38/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5349 - acc: 0.7211\n",
      "Epoch 39/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5332 - acc: 0.7203\n",
      "Epoch 40/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5326 - acc: 0.7218\n",
      "Epoch 41/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5324 - acc: 0.7212\n",
      "Epoch 42/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5314 - acc: 0.7217\n",
      "Epoch 43/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5310 - acc: 0.7230\n",
      "Epoch 44/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5306 - acc: 0.7219\n",
      "Epoch 45/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5290 - acc: 0.7226\n",
      "Epoch 46/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5287 - acc: 0.7232\n",
      "Epoch 47/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5289 - acc: 0.7225\n",
      "Epoch 48/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5275 - acc: 0.7228\n",
      "Epoch 49/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5271 - acc: 0.7227\n",
      "Epoch 50/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5258 - acc: 0.7249\n",
      "Epoch 51/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5257 - acc: 0.7240\n",
      "Epoch 52/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5250 - acc: 0.7257\n",
      "Epoch 53/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5240 - acc: 0.7258\n",
      "Epoch 54/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5231 - acc: 0.7257\n",
      "Epoch 55/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5224 - acc: 0.7273\n",
      "Epoch 56/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5212 - acc: 0.7288\n",
      "Epoch 57/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5202 - acc: 0.7288\n",
      "Epoch 58/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5195 - acc: 0.7314\n",
      "Epoch 59/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5188 - acc: 0.7314\n",
      "Epoch 60/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5183 - acc: 0.7316\n",
      "Epoch 61/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5166 - acc: 0.7332\n",
      "Epoch 62/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5168 - acc: 0.7328\n",
      "Epoch 63/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5142 - acc: 0.7353\n",
      "Epoch 64/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5131 - acc: 0.7371\n",
      "Epoch 65/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5130 - acc: 0.7365\n",
      "Epoch 66/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5113 - acc: 0.7397\n",
      "Epoch 67/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5115 - acc: 0.7419\n",
      "Epoch 68/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5090 - acc: 0.7418\n",
      "Epoch 69/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5079 - acc: 0.7434\n",
      "Epoch 70/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5085 - acc: 0.7441\n",
      "Epoch 71/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5081 - acc: 0.7447\n",
      "Epoch 72/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5059 - acc: 0.7468\n",
      "Epoch 73/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5037 - acc: 0.7489\n",
      "Epoch 74/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5026 - acc: 0.7519\n",
      "Epoch 75/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5017 - acc: 0.7523\n",
      "Epoch 76/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5010 - acc: 0.7541\n",
      "Epoch 77/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.5005 - acc: 0.7545\n",
      "Epoch 78/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4986 - acc: 0.7569\n",
      "Epoch 79/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4982 - acc: 0.7581\n",
      "Epoch 80/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4965 - acc: 0.7584\n",
      "Epoch 81/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4967 - acc: 0.7602\n",
      "Epoch 82/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4967 - acc: 0.7590\n",
      "Epoch 83/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4958 - acc: 0.7605\n",
      "Epoch 84/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4937 - acc: 0.7615\n",
      "Epoch 85/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4937 - acc: 0.7620\n",
      "Epoch 86/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4932 - acc: 0.7631\n",
      "Epoch 87/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4947 - acc: 0.7620\n",
      "Epoch 88/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4938 - acc: 0.7634\n",
      "Epoch 89/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4936 - acc: 0.7625\n",
      "Epoch 90/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4922 - acc: 0.7629\n",
      "Epoch 91/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4914 - acc: 0.7643\n",
      "Epoch 92/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4912 - acc: 0.7646\n",
      "Epoch 93/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4931 - acc: 0.7629\n",
      "Epoch 94/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4906 - acc: 0.7637\n",
      "Epoch 95/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4912 - acc: 0.7649\n",
      "Epoch 96/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4888 - acc: 0.7661\n",
      "Epoch 97/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4892 - acc: 0.7657\n",
      "Epoch 98/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4894 - acc: 0.7657\n",
      "Epoch 99/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4884 - acc: 0.7663\n",
      "Epoch 100/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4882 - acc: 0.7666\n",
      "Epoch 101/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4883 - acc: 0.7655\n",
      "Epoch 102/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4877 - acc: 0.7660\n",
      "Epoch 103/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4870 - acc: 0.7675\n",
      "Epoch 104/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4883 - acc: 0.7659\n",
      "Epoch 105/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4866 - acc: 0.7664\n",
      "Epoch 106/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4865 - acc: 0.7669\n",
      "Epoch 107/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4863 - acc: 0.7664\n",
      "Epoch 108/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4871 - acc: 0.7669\n",
      "Epoch 109/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4870 - acc: 0.7667\n",
      "Epoch 110/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4875 - acc: 0.7653\n",
      "Epoch 111/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4868 - acc: 0.7664\n",
      "Epoch 112/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4856 - acc: 0.7670\n",
      "Epoch 113/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4851 - acc: 0.7677\n",
      "Epoch 114/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4883 - acc: 0.7653\n",
      "Epoch 115/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4875 - acc: 0.7662\n",
      "Epoch 116/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4908 - acc: 0.7642\n",
      "Epoch 117/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4854 - acc: 0.7669\n",
      "Epoch 118/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4861 - acc: 0.7675\n",
      "Epoch 119/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4850 - acc: 0.7660\n",
      "Epoch 120/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4854 - acc: 0.7670\n",
      "Epoch 121/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4859 - acc: 0.7671\n",
      "Epoch 122/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4851 - acc: 0.7673\n",
      "Epoch 123/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4865 - acc: 0.7664\n",
      "Epoch 124/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4881 - acc: 0.7663\n",
      "Epoch 125/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4849 - acc: 0.7679\n",
      "Epoch 126/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4847 - acc: 0.7686\n",
      "Epoch 127/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4853 - acc: 0.7673\n",
      "Epoch 128/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4850 - acc: 0.7673\n",
      "Epoch 129/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4866 - acc: 0.7663\n",
      "Epoch 130/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4858 - acc: 0.7676\n",
      "Epoch 131/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4852 - acc: 0.7662\n",
      "Epoch 132/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4903 - acc: 0.7658\n",
      "Epoch 133/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4855 - acc: 0.7670\n",
      "Epoch 134/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4856 - acc: 0.7667\n",
      "Epoch 135/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4872 - acc: 0.7668\n",
      "Epoch 136/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4893 - acc: 0.7642\n",
      "Epoch 137/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4842 - acc: 0.7681\n",
      "Epoch 138/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4840 - acc: 0.7669\n",
      "Epoch 139/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4855 - acc: 0.7679\n",
      "Epoch 140/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4849 - acc: 0.7674\n",
      "Epoch 141/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4846 - acc: 0.7677\n",
      "Epoch 142/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4855 - acc: 0.7679\n",
      "Epoch 143/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4836 - acc: 0.7687\n",
      "Epoch 144/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4858 - acc: 0.7664\n",
      "Epoch 145/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4846 - acc: 0.7671\n",
      "Epoch 146/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4846 - acc: 0.7669\n",
      "Epoch 147/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4841 - acc: 0.7667\n",
      "Epoch 148/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4842 - acc: 0.7683\n",
      "Epoch 149/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4841 - acc: 0.7675\n",
      "Epoch 150/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4840 - acc: 0.7681\n",
      "Epoch 151/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4831 - acc: 0.7680\n",
      "Epoch 152/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4845 - acc: 0.7682\n",
      "Epoch 153/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4840 - acc: 0.7679\n",
      "Epoch 154/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4836 - acc: 0.7686\n",
      "Epoch 155/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4832 - acc: 0.7680\n",
      "Epoch 156/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4852 - acc: 0.7673\n",
      "Epoch 157/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4835 - acc: 0.7680\n",
      "Epoch 158/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4832 - acc: 0.7675\n",
      "Epoch 159/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4842 - acc: 0.7673\n",
      "Epoch 160/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4832 - acc: 0.7686\n",
      "Epoch 161/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4847 - acc: 0.7682\n",
      "Epoch 162/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4862 - acc: 0.7652\n",
      "Epoch 163/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4851 - acc: 0.7667\n",
      "Epoch 164/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4841 - acc: 0.7677\n",
      "Epoch 165/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4831 - acc: 0.7675\n",
      "Epoch 166/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4835 - acc: 0.7689\n",
      "Epoch 167/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4833 - acc: 0.7686\n",
      "Epoch 168/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4841 - acc: 0.7679\n",
      "Epoch 169/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4834 - acc: 0.7678\n",
      "Epoch 170/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4855 - acc: 0.7676\n",
      "Epoch 171/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4834 - acc: 0.7683\n",
      "Epoch 172/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4838 - acc: 0.7675\n",
      "Epoch 173/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4837 - acc: 0.7683\n",
      "Epoch 174/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4835 - acc: 0.7686\n",
      "Epoch 175/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4831 - acc: 0.7685\n",
      "Epoch 176/200\n",
      "39640/39640 [==============================] - 0s 1us/sample - loss: 0.4835 - acc: 0.7682\n",
      "Epoch 177/200\n",
      " 1000/39640 [..............................] - ETA: 0s - loss: 0.5019 - acc: 0.7550"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_point\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m         income_nn, optimal_datapt \u001b[38;5;241m=\u001b[39m optimal_point(dataset, income_nn, desired_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, original_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30000\u001b[39m, chosen_row\u001b[38;5;241m=\u001b[39mi, point_epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m     13\u001b[0m         target_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m         explainer2 \u001b[38;5;241m=\u001b[39m Counterfactual(income_nn, shape\u001b[38;5;241m=\u001b[39mshape, target_proba\u001b[38;5;241m=\u001b[39mtarget_proba, tol\u001b[38;5;241m=\u001b[39mtol,\n\u001b[0;32m     15\u001b[0m                             target_class\u001b[38;5;241m=\u001b[39mtarget_class)\n",
      "Cell \u001b[1;32mIn[11], line 95\u001b[0m, in \u001b[0;36moptimal_point\u001b[1;34m(dataset, model, desired_class, original_class, chosen_row, threshold, point_epsilon, epsilon, constraints, deltas, plot)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel training complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# STEP 2: Find decision boundary\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:856\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    855\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    858\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m    859\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    860\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    861\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m    862\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    863\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    864\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39mvalidation_split,\n\u001b[0;32m    865\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_data,\n\u001b[0;32m    866\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m    867\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weight,\n\u001b[0;32m    868\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    869\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[0;32m    870\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m    871\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m    872\u001b[0m     validation_freq\u001b[38;5;241m=\u001b[39mvalidation_freq,\n\u001b[0;32m    873\u001b[0m     max_queue_size\u001b[38;5;241m=\u001b[39mmax_queue_size,\n\u001b[0;32m    874\u001b[0m     workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[0;32m    875\u001b[0m     use_multiprocessing\u001b[38;5;241m=\u001b[39muse_multiprocessing,\n\u001b[0;32m    876\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    731\u001b[0m         )\n\u001b[0;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fit_loop(\n\u001b[0;32m    735\u001b[0m     model,\n\u001b[0;32m    736\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m    737\u001b[0m     targets\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    738\u001b[0m     sample_weights\u001b[38;5;241m=\u001b[39msample_weights,\n\u001b[0;32m    739\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    740\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m    741\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    742\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    743\u001b[0m     val_inputs\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    744\u001b[0m     val_targets\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m    745\u001b[0m     val_sample_weights\u001b[38;5;241m=\u001b[39mval_sample_weights,\n\u001b[0;32m    746\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m    747\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[0;32m    748\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m    749\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m    750\u001b[0m     validation_freq\u001b[38;5;241m=\u001b[39mvalidation_freq,\n\u001b[0;32m    751\u001b[0m     steps_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps_per_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    752\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_arrays_v1.py:397\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ins \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ins[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    396\u001b[0m         \u001b[38;5;66;03m# Do not slice the training phase flag.\u001b[39;00m\n\u001b[1;32m--> 397\u001b[0m         ins_batch \u001b[38;5;241m=\u001b[39m slice_arrays(ins[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], batch_ids) \u001b[38;5;241m+\u001b[39m [\n\u001b[0;32m    398\u001b[0m             ins[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    399\u001b[0m         ]\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m         ins_batch \u001b[38;5;241m=\u001b[39m slice_arrays(ins, batch_ids)\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\generic_utils.py:444\u001b[0m, in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(start, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    443\u001b[0m             start \u001b[38;5;241m=\u001b[39m start\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m x[start] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    452\u001b[0m     ]\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\generic_utils.py:444\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(start, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    443\u001b[0m             start \u001b[38;5;241m=\u001b[39m start\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m x[start] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    452\u001b[0m     ]\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "income_nn=nn_model()\n",
    "optimal_dists, wachter_dists = [], []\n",
    "optimal_probs,  wachter_probs = [], [] \n",
    "X_train = dataset.iloc[:,:-1]\n",
    "convert_columns(X_train)\n",
    "for i in range(50):\n",
    "    X_point = X_train.iloc[i,:]\n",
    "    y_point = dataset.iloc[i,-1]\n",
    "    if y_point.item() == 0:\n",
    "        try:\n",
    "            income_nn, optimal_datapt = optimal_point(dataset, income_nn, desired_class=1, original_class=0, threshold=30000, chosen_row=i, point_epsilon=1e-4, epsilon=1e-3)\n",
    "\n",
    "            target_class=1\n",
    "            explainer2 = Counterfactual(income_nn, shape=shape, target_proba=target_proba, tol=tol,\n",
    "                                target_class=target_class)\n",
    "            #print(np.reshape(X_point, (1,-1)).shape)\n",
    "            cf = explainer2.explain(np.reshape(X_point, (1,-1)))\n",
    "            cf_point = cf.data['cf']['X'] \n",
    "            cf_pt_probs = income_nn.predict(cf_point)\n",
    "            opt_pt_probs = income_nn.predict(optimal_datapt)\n",
    "            optimal_probs.append(opt_pt_probs)\n",
    "            wachter_probs.append(cf_pt_probs)\n",
    "            optimal_dists.append(euclidean_distance(X_point, optimal_datapt))\n",
    "            wachter_dists.append(euclidean_distance(X_point, cf_point))\n",
    "        # print(cf_point)\n",
    "        # print(income_nn.predict(np.reshape(X_point, (1,-1))))\n",
    "        # print(\"DISTANCE:\", euclidean_distance(X_point, cf_point))\n",
    "        except TypeError: \n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "753dbb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.347184081366327 1.2875562298294163\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(optimal_dists), np.mean(wachter_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4da18d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5004027 0.4995973] [0.50911397 0.490886  ]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(opt_pt_probs,axis=0), np.mean(cf_pt_probs,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b194155",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93b6339d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4104\n",
      "Class counts:\n",
      " income\n",
      "0    19820\n",
      "1    19820\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 10000 samples\n",
      "Epoch 1/100\n",
      "   32/10000 [..............................] - ETA: 9s - loss: 2.6611 - acc: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 15us/sample - loss: 0.7310 - acc: 0.6106\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5867 - acc: 0.6808\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5687 - acc: 0.6955\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5594 - acc: 0.7029\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5536 - acc: 0.7086\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5507 - acc: 0.7115\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5480 - acc: 0.7131\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5440 - acc: 0.7142\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5412 - acc: 0.7159\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5373 - acc: 0.7188\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5312 - acc: 0.7242\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5278 - acc: 0.7248\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5236 - acc: 0.7331\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5205 - acc: 0.7330\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5150 - acc: 0.7417\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5100 - acc: 0.7471\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5072 - acc: 0.7473\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5040 - acc: 0.7548\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5000 - acc: 0.7546\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.5001 - acc: 0.7584\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4968 - acc: 0.7586\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4961 - acc: 0.7642\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4934 - acc: 0.7631\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4904 - acc: 0.7677\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4938 - acc: 0.7636\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4917 - acc: 0.7670\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4889 - acc: 0.7664\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4921 - acc: 0.7655\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4888 - acc: 0.7663\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4902 - acc: 0.7640\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4889 - acc: 0.7663\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4888 - acc: 0.7651\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4913 - acc: 0.7663\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4889 - acc: 0.7674\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4896 - acc: 0.7659\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4900 - acc: 0.7650\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4881 - acc: 0.7688\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4864 - acc: 0.7677\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4894 - acc: 0.7666\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4883 - acc: 0.7665\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4871 - acc: 0.7691\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4878 - acc: 0.7681\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4882 - acc: 0.7689\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4874 - acc: 0.7684\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4871 - acc: 0.7681\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4876 - acc: 0.7674\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4857 - acc: 0.7689\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4888 - acc: 0.7683\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4871 - acc: 0.7675\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4867 - acc: 0.7678\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4870 - acc: 0.7656\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4849 - acc: 0.7717\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4879 - acc: 0.7711\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4872 - acc: 0.7656\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4850 - acc: 0.7698\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4881 - acc: 0.7675\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4837 - acc: 0.7701\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4844 - acc: 0.7728\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4847 - acc: 0.7688\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4853 - acc: 0.7679\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4855 - acc: 0.7697\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4852 - acc: 0.7702\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4830 - acc: 0.7712\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4844 - acc: 0.7711\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4852 - acc: 0.7699\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4856 - acc: 0.7697\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4832 - acc: 0.7695\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4854 - acc: 0.7704\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4836 - acc: 0.7698\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4844 - acc: 0.7693\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4830 - acc: 0.7715\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4839 - acc: 0.7729\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4833 - acc: 0.7696\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4834 - acc: 0.7699\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4838 - acc: 0.7665\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4824 - acc: 0.7715\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4842 - acc: 0.7688\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4842 - acc: 0.7682\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4845 - acc: 0.7683\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4828 - acc: 0.7710\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4834 - acc: 0.7713\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4823 - acc: 0.7697\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4834 - acc: 0.7714\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4816 - acc: 0.7678\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4833 - acc: 0.7718\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4840 - acc: 0.7687\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4824 - acc: 0.7714\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4817 - acc: 0.7713\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4840 - acc: 0.7675\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4819 - acc: 0.7694\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4822 - acc: 0.7673\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4805 - acc: 0.7711\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4809 - acc: 0.7689\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4805 - acc: 0.7735\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4801 - acc: 0.7723\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4807 - acc: 0.7723\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4823 - acc: 0.7739\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 0.4825 - acc: 0.7688\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4818 - acc: 0.7690\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 0.4807 - acc: 0.7685\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(idx)\n\u001b[0;32m     12\u001b[0m nn\u001b[38;5;241m=\u001b[39mnn_model()\n\u001b[1;32m---> 14\u001b[0m nn, optimal_datapt \u001b[38;5;241m=\u001b[39m optimal_point(dataset, nn, desired_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, original_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, chosen_row\u001b[38;5;241m=\u001b[39midx, point_epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m)\n\u001b[0;32m     16\u001b[0m target_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m explainer2 \u001b[38;5;241m=\u001b[39m Counterfactual(nn, shape\u001b[38;5;241m=\u001b[39mshape, target_proba\u001b[38;5;241m=\u001b[39mtarget_proba, tol\u001b[38;5;241m=\u001b[39mtol,\n\u001b[0;32m     18\u001b[0m                         target_class\u001b[38;5;241m=\u001b[39mtarget_class)\n",
      "Cell \u001b[1;32mIn[55], line 105\u001b[0m, in \u001b[0;36moptimal_point\u001b[1;34m(dataset, model, desired_class, original_class, chosen_row, threshold, point_epsilon, epsilon, constraints, deltas, plot)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboundary points started generation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# This step uses binary interpolation to get points close to the decision boundary\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m boundary_points \u001b[38;5;241m=\u001b[39m find_decision_boundary(model, X_train, y_train,\n\u001b[0;32m    106\u001b[0m                                          threshold\u001b[38;5;241m=\u001b[39mthreshold, epsilon\u001b[38;5;241m=\u001b[39mpoint_epsilon)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboundary points finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(boundary_points\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[10], line 185\u001b[0m, in \u001b[0;36mfind_decision_boundary\u001b[1;34m(model, X, y, epsilon, threshold)\u001b[0m\n\u001b[0;32m    183\u001b[0m point \u001b[38;5;241m=\u001b[39m correct_a[a_indices[idx]]\n\u001b[0;32m    184\u001b[0m match_point \u001b[38;5;241m=\u001b[39m correct_b[b_indices[idx]]\n\u001b[1;32m--> 185\u001b[0m alpha \u001b[38;5;241m=\u001b[39m alpha_binary_search(model, point, match_point, label_a, epsilon\u001b[38;5;241m=\u001b[39mepsilon)\n\u001b[0;32m    186\u001b[0m boundary \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha) \u001b[38;5;241m*\u001b[39m point \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m match_point\n\u001b[0;32m    187\u001b[0m boundary_points\u001b[38;5;241m.\u001b[39mappend(boundary)\n",
      "Cell \u001b[1;32mIn[10], line 65\u001b[0m, in \u001b[0;36malpha_binary_search\u001b[1;34m(model, point, opp_point, point_target, epsilon, max_iter)\u001b[0m\n\u001b[0;32m     63\u001b[0m mid \u001b[38;5;241m=\u001b[39m (start \u001b[38;5;241m+\u001b[39m end) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \n\u001b[0;32m     64\u001b[0m mid_point \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m mid) \u001b[38;5;241m*\u001b[39m point \u001b[38;5;241m+\u001b[39m mid \u001b[38;5;241m*\u001b[39m opp_point         \n\u001b[1;32m---> 65\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(mid_point\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     66\u001b[0m pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred \u001b[38;5;241m==\u001b[39m point_target: \n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:1059\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1058\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m-> 1059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1061\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m   1062\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1063\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1064\u001b[0m     steps\u001b[38;5;241m=\u001b[39msteps,\n\u001b[0;32m   1065\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1066\u001b[0m     max_queue_size\u001b[38;5;241m=\u001b[39mmax_queue_size,\n\u001b[0;32m   1067\u001b[0m     workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[0;32m   1068\u001b[0m     use_multiprocessing\u001b[38;5;241m=\u001b[39muse_multiprocessing,\n\u001b[0;32m   1069\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_arrays_v1.py:801\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.predict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    797\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_validate_or_infer_batch_size(batch_size, steps, x)\n\u001b[0;32m    798\u001b[0m x, _, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_standardize_user_data(\n\u001b[0;32m    799\u001b[0m     x, check_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, steps_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39msteps\n\u001b[0;32m    800\u001b[0m )\n\u001b[1;32m--> 801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predict_loop(\n\u001b[0;32m    802\u001b[0m     model,\n\u001b[0;32m    803\u001b[0m     x,\n\u001b[0;32m    804\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    805\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    806\u001b[0m     steps\u001b[38;5;241m=\u001b[39msteps,\n\u001b[0;32m    807\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    808\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(\n\u001b[0;32m    417\u001b[0m     mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_index, batch_logs\n\u001b[0;32m    418\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m f(ins_batch)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    423\u001b[0m     batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:4609\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4600\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4601\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4605\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[0;32m   4606\u001b[0m ):\n\u001b[0;32m   4607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4609\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn(\u001b[38;5;241m*\u001b[39marray_vals, run_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_metadata)\n\u001b[0;32m   4610\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n\u001b[0;32m   4611\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4612\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4613\u001b[0m     fetched[: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[0;32m   4614\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   4615\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1505\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1504\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1505\u001b[0m   ret \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_SessionRunCallable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39m_session,\n\u001b[0;32m   1506\u001b[0m                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle, args,\n\u001b[0;32m   1507\u001b[0m                                          run_metadata_ptr)\n\u001b[0;32m   1508\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1509\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimal_dists, wachter_dists = [], []\n",
    "optimal_probs,  wachter_probs = [], [] \n",
    "convert_columns(dataset)\n",
    "sub_dataset = dataset[dataset['income'] == 0]\n",
    "random_integers = random.sample(range(0, sub_dataset.shape[0]-1), 25)\n",
    "\n",
    "for i in random_integers:\n",
    "    real_idx = sub_dataset.index[i]\n",
    "    X_point = dataset.iloc[real_idx,:-1]\n",
    "    idx = dataset.index[real_idx]\n",
    "    print(idx)\n",
    "    nn=nn_model()\n",
    "\n",
    "    nn, optimal_datapt = optimal_point(dataset, nn, desired_class=1, original_class=0, threshold=10000, chosen_row=idx, point_epsilon=1e-3, epsilon=1e-2)\n",
    "\n",
    "    target_class=1\n",
    "    explainer2 = Counterfactual(nn, shape=shape, target_proba=target_proba, tol=tol,\n",
    "                            target_class=target_class)\n",
    "    #print(np.reshape(X_point, (1,-1)).shape)\n",
    "    cf = explainer2.explain(np.reshape(X_point, (1,-1)))\n",
    "    cf_point = cf.data['cf']['X'] \n",
    "    cf_pt_probs = nn.predict(cf_point)\n",
    "    opt_pt_probs = nn.predict(optimal_datapt)\n",
    "    optimal_probs.append(opt_pt_probs)\n",
    "    wachter_probs.append(cf_pt_probs)\n",
    "    optimal_dists.append(euclidean_distance(X_point, optimal_datapt))\n",
    "    wachter_dists.append(euclidean_distance(X_point, cf_point))\n",
    "    # print(cf_point)\n",
    "    # print(income_nn.predict(np.reshape(X_point, (1,-1))))\n",
    "    # print(\"DISTANCE:\", euclidean_distance(X_point, cf_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1995f1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.80614062004767 1.6352341867911546\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(optimal_dists), np.mean(wachter_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ffd1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5016694 0.4983306] [0.49990672 0.5000933 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(opt_pt_probs,axis=0), np.mean(cf_pt_probs,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45ecf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv(\n",
    "'../heart.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39cd48c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     52.0  1.0  0.0     125.0  212.0  0.0      1.0    168.0    0.0      1.0   \n",
       "1     53.0  1.0  0.0     140.0  203.0  1.0      0.0    155.0    1.0      3.1   \n",
       "2     70.0  1.0  0.0     145.0  174.0  0.0      1.0    125.0    1.0      2.6   \n",
       "3     61.0  1.0  0.0     148.0  203.0  0.0      1.0    161.0    0.0      0.0   \n",
       "4     62.0  0.0  0.0     138.0  294.0  1.0      1.0    106.0    0.0      1.9   \n",
       "...    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "1020  59.0  1.0  1.0     140.0  221.0  0.0      1.0    164.0    1.0      0.0   \n",
       "1021  60.0  1.0  0.0     125.0  258.0  0.0      0.0    141.0    1.0      2.8   \n",
       "1022  47.0  1.0  0.0     110.0  275.0  0.0      0.0    118.0    1.0      1.0   \n",
       "1023  50.0  0.0  0.0     110.0  254.0  0.0      0.0    159.0    0.0      0.0   \n",
       "1024  54.0  1.0  0.0     120.0  188.0  0.0      1.0    113.0    0.0      1.4   \n",
       "\n",
       "      slope   ca  thal  target  \n",
       "0       2.0  2.0   3.0     0.0  \n",
       "1       0.0  0.0   3.0     0.0  \n",
       "2       0.0  0.0   3.0     0.0  \n",
       "3       2.0  1.0   3.0     0.0  \n",
       "4       1.0  3.0   2.0     0.0  \n",
       "...     ...  ...   ...     ...  \n",
       "1020    2.0  0.0   2.0     1.0  \n",
       "1021    1.0  1.0   3.0     0.0  \n",
       "1022    1.0  1.0   2.0     0.0  \n",
       "1023    2.0  0.0   2.0     1.0  \n",
       "1024    1.0  1.0   3.0     0.0  \n",
       "\n",
       "[1025 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4a9d3a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1,heart_disease.shape[1]-1)\n",
    "target_proba = 0.5\n",
    "tol = 0.0001 # want counterfactuals with p(class)>0.99\n",
    "target_class = 'other' # any class other than 7 will do\n",
    "max_iter = 1000\n",
    "lam_init = 1e-1\n",
    "max_lam_steps = 10\n",
    "learning_rate_init = 0.1\n",
    "feature_range = (heart_disease.min(),heart_disease.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9453637a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091bc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    x_in = Input(shape=(13,))\n",
    "\n",
    "    x = Flatten()(x_in)\n",
    "    x = Dense(8, activation='relu')(x)\n",
    "    x = Dense(10, activation='relu')(x) \n",
    "    probs = Dense(2, activation='softmax')(x)\n",
    "    nn = Model(inputs=x_in, outputs=probs)\n",
    "    nn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b2e1eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()  # For TensorFlow 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b13a26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "45fea3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 49us/sample - loss: 76.9421 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 16.8254 - acc: 0.5105\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 2.4906 - acc: 0.5903\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.5532 - acc: 0.5646\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.2112 - acc: 0.5684\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 1.0336 - acc: 0.5779\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.8706 - acc: 0.6198\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.6991 - acc: 0.6816\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5893 - acc: 0.7129\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5495 - acc: 0.7386\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5304 - acc: 0.7557\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.5293 - acc: 0.7557\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.5008 - acc: 0.7529\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.5177 - acc: 0.7462\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4789 - acc: 0.7766\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4795 - acc: 0.7557\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4656 - acc: 0.7738\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4790 - acc: 0.7662\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.5119 - acc: 0.7452\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4634 - acc: 0.7690\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4556 - acc: 0.7880\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4352 - acc: 0.8004\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4508 - acc: 0.7918\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4436 - acc: 0.7956\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4478 - acc: 0.7861\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4313 - acc: 0.8004\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4229 - acc: 0.8042\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4460 - acc: 0.7814\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4491 - acc: 0.8023\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4226 - acc: 0.8061\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4356 - acc: 0.7966\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4296 - acc: 0.7947\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4061 - acc: 0.8175\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4151 - acc: 0.8127\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4177 - acc: 0.8118\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4265 - acc: 0.8089\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4502 - acc: 0.7909\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4085 - acc: 0.8241\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4398 - acc: 0.7909\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4759 - acc: 0.7766\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4075 - acc: 0.8127\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4119 - acc: 0.8137\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3944 - acc: 0.8213\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4242 - acc: 0.8156\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3925 - acc: 0.8260\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3859 - acc: 0.8413\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4053 - acc: 0.8203\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4031 - acc: 0.8251\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3967 - acc: 0.8289\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3866 - acc: 0.8317\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4393 - acc: 0.7928\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4387 - acc: 0.8051\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4314 - acc: 0.7937\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4206 - acc: 0.7937\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3914 - acc: 0.8327\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3887 - acc: 0.8308\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4953 - acc: 0.7728\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3983 - acc: 0.8251\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3970 - acc: 0.8137\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3842 - acc: 0.8337\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4495 - acc: 0.7861\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4083 - acc: 0.8118\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4023 - acc: 0.8241\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4114 - acc: 0.8184\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3969 - acc: 0.8127\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4053 - acc: 0.8108\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4014 - acc: 0.8222\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3799 - acc: 0.8413\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3895 - acc: 0.8251\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3749 - acc: 0.8460\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4118 - acc: 0.8137\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4027 - acc: 0.8308\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3797 - acc: 0.8346\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4102 - acc: 0.8260\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3847 - acc: 0.8308\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4110 - acc: 0.8165\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4357 - acc: 0.7966\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3970 - acc: 0.8213\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4089 - acc: 0.8108\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4183 - acc: 0.8194\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3689 - acc: 0.8460\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4056 - acc: 0.8089\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3801 - acc: 0.8356\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3703 - acc: 0.8517\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4006 - acc: 0.8222\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3888 - acc: 0.8460\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4326 - acc: 0.8023\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4080 - acc: 0.8175\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3832 - acc: 0.8432\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3773 - acc: 0.8460\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3828 - acc: 0.8308\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3779 - acc: 0.8394\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3958 - acc: 0.8260\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4123 - acc: 0.8222\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3889 - acc: 0.8241\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3776 - acc: 0.8432\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4009 - acc: 0.8260\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4016 - acc: 0.8289\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4027 - acc: 0.8194\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4214 - acc: 0.8042\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00536525 0.         1.00077284 1.0102875  1.00963666 1.01341009\n",
      "  1.01101101 1.00940872 1.01143912 1.00873083 1.01143912 1.00661279\n",
      "  1.01101101]]\n",
      "[[ 0.21691895  0.          0.10845947 -3.51409912  2.77874756 -0.29718018\n",
      "  -1.          1.70715332 -0.70281982  0.7947937  -0.70281982  0.29718018\n",
      "  -1.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 48us/sample - loss: 24.8287 - acc: 0.4990\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 2.9452 - acc: 0.5399\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.9095 - acc: 0.5865\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.5456 - acc: 0.5875\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.2155 - acc: 0.6036\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.9520 - acc: 0.6169\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.7990 - acc: 0.6302\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.7017 - acc: 0.6587\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.6935 - acc: 0.6768\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.6450 - acc: 0.6825\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.6315 - acc: 0.6854\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.6207 - acc: 0.6958\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.6141 - acc: 0.6901\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.6022 - acc: 0.7120\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.6059 - acc: 0.6939\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.6013 - acc: 0.6797\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.6235 - acc: 0.6702\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5981 - acc: 0.6958\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.6004 - acc: 0.6873\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.6194 - acc: 0.6730\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.5736 - acc: 0.7262\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5785 - acc: 0.7015\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.5790 - acc: 0.7072\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5659 - acc: 0.6977\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5826 - acc: 0.6873\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5673 - acc: 0.7072\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5832 - acc: 0.7006\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.5669 - acc: 0.7110\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5633 - acc: 0.7186\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5639 - acc: 0.7082\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5855 - acc: 0.6844\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5667 - acc: 0.7110\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5444 - acc: 0.7319\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5957 - acc: 0.7053\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5522 - acc: 0.7091\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5372 - acc: 0.7215\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.5384 - acc: 0.7262\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5655 - acc: 0.7072\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5506 - acc: 0.7082\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5881 - acc: 0.6873\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5404 - acc: 0.7262\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5396 - acc: 0.7234\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5408 - acc: 0.7348\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5396 - acc: 0.7196\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5536 - acc: 0.7110\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5213 - acc: 0.7443\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5337 - acc: 0.7367\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5117 - acc: 0.7291\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5304 - acc: 0.7243\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5183 - acc: 0.7310\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5123 - acc: 0.7367\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5104 - acc: 0.7329\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5089 - acc: 0.7414\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5063 - acc: 0.7433\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5361 - acc: 0.7262\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5171 - acc: 0.7414\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4972 - acc: 0.7529\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.5019 - acc: 0.7462\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5241 - acc: 0.7424\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4852 - acc: 0.7414\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5143 - acc: 0.7443\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4775 - acc: 0.7519\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4819 - acc: 0.7652\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4864 - acc: 0.7490\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4788 - acc: 0.7700\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4693 - acc: 0.7567\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4926 - acc: 0.7538\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4547 - acc: 0.7624\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4542 - acc: 0.7633\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4759 - acc: 0.7633\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4947 - acc: 0.7500\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4592 - acc: 0.7681\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4407 - acc: 0.7662\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4339 - acc: 0.7871\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4281 - acc: 0.7880\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4383 - acc: 0.7909\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4346 - acc: 0.7747\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4364 - acc: 0.7757\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4321 - acc: 0.7937\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4338 - acc: 0.7909\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4168 - acc: 0.8061\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4297 - acc: 0.7852\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4187 - acc: 0.7966\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4514 - acc: 0.7719\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4156 - acc: 0.8108\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4155 - acc: 0.8099\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4120 - acc: 0.7956\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4043 - acc: 0.8089\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4036 - acc: 0.8118\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4125 - acc: 0.8061\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4171 - acc: 0.7890\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4002 - acc: 0.8061\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4036 - acc: 0.8203\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3905 - acc: 0.8184\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3939 - acc: 0.8317\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4079 - acc: 0.8137\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3915 - acc: 0.8213\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3865 - acc: 0.8346\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3867 - acc: 0.8203\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3933 - acc: 0.8260\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00957751 1.00846884 1.01076733 1.00990021 1.02719049 1.00704997\n",
      "  1.01101101 1.0101748  0.         1.00631516 0.         1.00939143\n",
      "  1.00846884]]\n",
      "[[ 2.3895874   0.65863037 -1.31726074 10.12054443 -0.05975342  0.34136963\n",
      "  -1.         -5.7791748   0.          0.2730957   0.          1.65863037\n",
      "   0.65863037]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 57us/sample - loss: 126.9342 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 75.0457 - acc: 0.5000\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 35.6413 - acc: 0.5000\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 4.3952 - acc: 0.5713\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.5256 - acc: 0.5637\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.2542 - acc: 0.5932\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.0834 - acc: 0.6207\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.9934 - acc: 0.6378\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.9529 - acc: 0.6407\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.9057 - acc: 0.6635\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.8697 - acc: 0.6768\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.8271 - acc: 0.6806\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.7973 - acc: 0.6949\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.7816 - acc: 0.6816\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.7491 - acc: 0.7025\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.7075 - acc: 0.7044\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.6892 - acc: 0.7025\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.6570 - acc: 0.7072\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.6290 - acc: 0.7120\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.5931 - acc: 0.7091\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5772 - acc: 0.7110\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5604 - acc: 0.7110\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5615 - acc: 0.7243\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5318 - acc: 0.7348\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5254 - acc: 0.7310\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.5070 - acc: 0.7348\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4998 - acc: 0.7471\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5066 - acc: 0.7462\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4894 - acc: 0.7548\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4751 - acc: 0.7624\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4653 - acc: 0.7605\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4631 - acc: 0.7757\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4609 - acc: 0.7785\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4688 - acc: 0.7700\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4419 - acc: 0.7909\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4375 - acc: 0.7956\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4370 - acc: 0.7985\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4520 - acc: 0.7880\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4501 - acc: 0.7814\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4567 - acc: 0.7880\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4294 - acc: 0.8032\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4357 - acc: 0.7975\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4323 - acc: 0.7928\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4133 - acc: 0.8165\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4206 - acc: 0.8061\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4276 - acc: 0.8042\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4233 - acc: 0.7947\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4148 - acc: 0.8089\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4419 - acc: 0.7842\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4061 - acc: 0.8241\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4061 - acc: 0.8251\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4002 - acc: 0.8365\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3987 - acc: 0.8298\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.4078 - acc: 0.8156\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4111 - acc: 0.8241\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3928 - acc: 0.8260\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3957 - acc: 0.8308\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3963 - acc: 0.8222\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3869 - acc: 0.8460\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3954 - acc: 0.8298\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3905 - acc: 0.8308\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3952 - acc: 0.8175\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3832 - acc: 0.8432\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3925 - acc: 0.8222\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4046 - acc: 0.8089\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3887 - acc: 0.8346\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3917 - acc: 0.8203\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3918 - acc: 0.8298\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3866 - acc: 0.8241\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4023 - acc: 0.8089\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4015 - acc: 0.8251\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3821 - acc: 0.8337\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3825 - acc: 0.8451\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4005 - acc: 0.8165\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3901 - acc: 0.8327\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3830 - acc: 0.8346\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3803 - acc: 0.8365\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3787 - acc: 0.8375\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3936 - acc: 0.8375\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3838 - acc: 0.8403\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3815 - acc: 0.8317\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3893 - acc: 0.8270\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4210 - acc: 0.8099\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3782 - acc: 0.8298\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3875 - acc: 0.8251\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3759 - acc: 0.8451\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3787 - acc: 0.8451\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3944 - acc: 0.8213\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3807 - acc: 0.8403\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3750 - acc: 0.8375\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3818 - acc: 0.8394\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3778 - acc: 0.8365\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4205 - acc: 0.8070\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4018 - acc: 0.8156\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3889 - acc: 0.8327\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3950 - acc: 0.8308\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4139 - acc: 0.8232\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3848 - acc: 0.8327\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 12us/sample - loss: 0.3838 - acc: 0.8260\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3750 - acc: 0.8346\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00948739 1.00899101 1.01083383 1.01087635 1.01076006 0.\n",
      "  1.00899101 1.00925962 0.         1.00911194 1.00899101 1.00916755\n",
      "  1.00833646]]\n",
      "[[ 1.96929932  1.         -1.21228027 -1.15350342 -1.32983398  0.\n",
      "   1.          1.36315918  0.          1.13631592  1.          1.21228027\n",
      "   0.60614014]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 58us/sample - loss: 26.7375 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 6.1663 - acc: 0.5247\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 3.7694 - acc: 0.5684\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 2.5219 - acc: 0.6122\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 1.8738 - acc: 0.6426\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 1.6646 - acc: 0.6549\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.5899 - acc: 0.6644\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.4786 - acc: 0.6787\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.4066 - acc: 0.6825\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 1.3485 - acc: 0.6806\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.2426 - acc: 0.6968\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.1746 - acc: 0.6977\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 1.1534 - acc: 0.6939\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.0977 - acc: 0.6949\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.0449 - acc: 0.7015\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 1.0132 - acc: 0.6939\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.9806 - acc: 0.7015\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.8696 - acc: 0.7101\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.8356 - acc: 0.7243\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.8189 - acc: 0.7110\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.7722 - acc: 0.7215\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.7218 - acc: 0.7310\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.6812 - acc: 0.7376\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.6913 - acc: 0.7148\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.6322 - acc: 0.7510\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.6053 - acc: 0.7443\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5796 - acc: 0.7529\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5661 - acc: 0.7481\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5389 - acc: 0.7519\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5187 - acc: 0.7633\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.5236 - acc: 0.7624\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4971 - acc: 0.7785\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4972 - acc: 0.7624\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4918 - acc: 0.7719\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4691 - acc: 0.7814\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4678 - acc: 0.7823\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4608 - acc: 0.7861\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4230 - acc: 0.8004\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4349 - acc: 0.7937\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4178 - acc: 0.8061\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4396 - acc: 0.7937\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4088 - acc: 0.7956\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4026 - acc: 0.8089\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4003 - acc: 0.8118\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4020 - acc: 0.7947\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3934 - acc: 0.8222\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3990 - acc: 0.8080\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3969 - acc: 0.8156\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3910 - acc: 0.8108\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3906 - acc: 0.8194\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3834 - acc: 0.8251\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3792 - acc: 0.8279\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3887 - acc: 0.8222\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3901 - acc: 0.8156\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3860 - acc: 0.8203\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3866 - acc: 0.8165\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4037 - acc: 0.8099\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4008 - acc: 0.8108\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3817 - acc: 0.8279\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3710 - acc: 0.8327\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3889 - acc: 0.8222\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3901 - acc: 0.8260\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3853 - acc: 0.8222\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3757 - acc: 0.8327\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3826 - acc: 0.8241\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3766 - acc: 0.8251\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4122 - acc: 0.8099\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.4089 - acc: 0.8194\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3833 - acc: 0.8222\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3786 - acc: 0.8298\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3757 - acc: 0.8384\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3845 - acc: 0.8289\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3844 - acc: 0.8241\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3910 - acc: 0.8194\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4086 - acc: 0.8260\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3791 - acc: 0.8365\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3845 - acc: 0.8232\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3663 - acc: 0.8413\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3751 - acc: 0.8365\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3628 - acc: 0.8308\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3713 - acc: 0.8422\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3645 - acc: 0.8413\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3703 - acc: 0.8317\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3742 - acc: 0.8356\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3799 - acc: 0.8375\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3722 - acc: 0.8394\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3884 - acc: 0.8251\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3865 - acc: 0.8260\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3670 - acc: 0.8375\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3594 - acc: 0.8365\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3842 - acc: 0.8317\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3868 - acc: 0.8222\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3646 - acc: 0.8422\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 13us/sample - loss: 0.3717 - acc: 0.8317\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3679 - acc: 0.8441\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3662 - acc: 0.8527\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3780 - acc: 0.8327\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4053 - acc: 0.8127\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3836 - acc: 0.8298\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3712 - acc: 0.8470\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.0106121  1.00816815 1.01091843 1.0096331  1.01036717 1.01183852\n",
      "  0.         1.00938864 1.00816815 1.00885431 0.         0.\n",
      "  1.00816815]]\n",
      "[[-1.65106201  0.550354   -1.10070801  2.75177002 -2.75177002 -0.550354\n",
      "   0.          1.65106201  0.550354    0.88056641  0.          0.\n",
      "   0.550354  ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 74us/sample - loss: 9.2550 - acc: 0.5504\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 2.3762 - acc: 0.6483\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 2.1802 - acc: 0.6559\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 2.1161 - acc: 0.6511\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 1.8702 - acc: 0.6663\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 1.7280 - acc: 0.6768\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 1.5580 - acc: 0.6854\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 1.4060 - acc: 0.6835\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 1.2437 - acc: 0.6892\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 1.1782 - acc: 0.6644\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.9421 - acc: 0.7072\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.8416 - acc: 0.7044\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6955 - acc: 0.7253\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.6473 - acc: 0.7338\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5642 - acc: 0.7538\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4754 - acc: 0.7795\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4791 - acc: 0.7814\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4539 - acc: 0.7937\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4970 - acc: 0.7757\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4196 - acc: 0.8042\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4551 - acc: 0.7937\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4149 - acc: 0.8080\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4213 - acc: 0.8051\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4361 - acc: 0.8146\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4190 - acc: 0.8013\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4126 - acc: 0.8070\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4002 - acc: 0.8051\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4186 - acc: 0.8061\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4185 - acc: 0.8061\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4056 - acc: 0.8051\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3969 - acc: 0.8156\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3966 - acc: 0.8251\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4046 - acc: 0.8089\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4173 - acc: 0.8156\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3836 - acc: 0.8356\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3848 - acc: 0.8317\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3829 - acc: 0.8194\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3906 - acc: 0.8194\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3979 - acc: 0.8194\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4609 - acc: 0.7975\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4140 - acc: 0.8184\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4034 - acc: 0.8127\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3805 - acc: 0.8365\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3818 - acc: 0.8346\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3807 - acc: 0.8375\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3860 - acc: 0.8251\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3771 - acc: 0.8308\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3794 - acc: 0.8327\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3909 - acc: 0.8165\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4121 - acc: 0.8165\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3830 - acc: 0.8213\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3935 - acc: 0.8127\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3767 - acc: 0.8365\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3716 - acc: 0.8346\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4178 - acc: 0.8146\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3735 - acc: 0.8508\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3819 - acc: 0.8279\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3717 - acc: 0.8337\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3808 - acc: 0.8327\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3812 - acc: 0.8317\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3767 - acc: 0.8298\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4091 - acc: 0.8032\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3890 - acc: 0.8213\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4423 - acc: 0.7994\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4668 - acc: 0.7985\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3983 - acc: 0.8194\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3679 - acc: 0.8517\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3659 - acc: 0.8346\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4119 - acc: 0.8146\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3714 - acc: 0.8317\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3729 - acc: 0.8394\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3887 - acc: 0.8270\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3605 - acc: 0.8460\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3802 - acc: 0.8308\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3804 - acc: 0.8356\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3771 - acc: 0.8356\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3852 - acc: 0.8365\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4179 - acc: 0.8156\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3789 - acc: 0.8337\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3797 - acc: 0.8460\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3647 - acc: 0.8394\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3818 - acc: 0.8375\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3694 - acc: 0.8365\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3617 - acc: 0.8451\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3634 - acc: 0.8536\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3847 - acc: 0.8289\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3890 - acc: 0.8337\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3837 - acc: 0.8279\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3677 - acc: 0.8470\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3675 - acc: 0.8451\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3750 - acc: 0.8317\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3817 - acc: 0.8384\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3679 - acc: 0.8422\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3852 - acc: 0.8356\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4243 - acc: 0.8080\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4758 - acc: 0.7795\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3723 - acc: 0.8356\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3916 - acc: 0.8260\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3640 - acc: 0.8517\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3590 - acc: 0.8489\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01046361 1.0078219  1.01109258 1.00983496 1.00981416 0.\n",
      "  1.00934343 1.00982054 1.0078219  1.00739424 0.         1.0078219\n",
      "  1.0078219 ]]\n",
      "[[-2.17956543  0.46270752 -0.92541504  6.11877441  5.43371582  0.\n",
      "   1.53729248  5.6270752   0.46270752  0.38660278  0.          0.46270752\n",
      "   0.46270752]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 86us/sample - loss: 5.1534 - acc: 0.5618\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 1.8098 - acc: 0.6226\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 1.5452 - acc: 0.6388\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 1.4677 - acc: 0.6644\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 1.3639 - acc: 0.6663\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.2750 - acc: 0.6730\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 1.2037 - acc: 0.6740\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.1434 - acc: 0.6825\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 1.1223 - acc: 0.6882\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 1.0175 - acc: 0.6977\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.9791 - acc: 0.6806\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.9322 - acc: 0.6797\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.8627 - acc: 0.7082\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.8572 - acc: 0.6977\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.7857 - acc: 0.6977\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.7502 - acc: 0.7082\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.7142 - acc: 0.7034\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.7058 - acc: 0.7025\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6624 - acc: 0.7072\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.6410 - acc: 0.7148\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.7142 - acc: 0.6854\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6354 - acc: 0.6996\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.6289 - acc: 0.7234\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5775 - acc: 0.7272\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5641 - acc: 0.7272\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5908 - acc: 0.7148\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.5568 - acc: 0.7158\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5354 - acc: 0.7272\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.5326 - acc: 0.7424\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5097 - acc: 0.7510\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5186 - acc: 0.7424\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5005 - acc: 0.7462\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4849 - acc: 0.7633\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.5152 - acc: 0.7481\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5248 - acc: 0.7348\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4803 - acc: 0.7510\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4658 - acc: 0.7804\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4845 - acc: 0.7567\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4616 - acc: 0.7576\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4621 - acc: 0.7671\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4591 - acc: 0.7833\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4658 - acc: 0.7709\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4535 - acc: 0.7795\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4476 - acc: 0.7871\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4428 - acc: 0.7852\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4345 - acc: 0.7833\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4606 - acc: 0.7766\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4577 - acc: 0.7700\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4310 - acc: 0.7966\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4256 - acc: 0.7937\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4388 - acc: 0.7880\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4166 - acc: 0.8137\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4378 - acc: 0.8004\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4140 - acc: 0.8051\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4204 - acc: 0.7937\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4136 - acc: 0.8127\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4206 - acc: 0.7956\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4394 - acc: 0.7842\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4188 - acc: 0.7947\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3992 - acc: 0.8213\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4117 - acc: 0.8127\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3958 - acc: 0.8394\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3995 - acc: 0.8213\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4215 - acc: 0.8004\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4232 - acc: 0.7985\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3978 - acc: 0.8175\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3930 - acc: 0.8394\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3966 - acc: 0.8232\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3956 - acc: 0.8365\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3925 - acc: 0.8260\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3986 - acc: 0.8184\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4114 - acc: 0.8127\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4068 - acc: 0.8165\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4266 - acc: 0.7852\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4131 - acc: 0.8184\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3863 - acc: 0.8346\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3951 - acc: 0.8146\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3927 - acc: 0.8270\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4035 - acc: 0.8175\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4004 - acc: 0.8175\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4067 - acc: 0.8127\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4382 - acc: 0.7966\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4130 - acc: 0.8194\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3943 - acc: 0.8165\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3928 - acc: 0.8260\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3767 - acc: 0.8394\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3973 - acc: 0.8222\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4165 - acc: 0.8042\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4001 - acc: 0.8194\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3971 - acc: 0.8175\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3955 - acc: 0.8146\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4132 - acc: 0.8080\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3784 - acc: 0.8384\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3787 - acc: 0.8403\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3950 - acc: 0.8175\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3823 - acc: 0.8365\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4058 - acc: 0.8023\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3741 - acc: 0.8498\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3952 - acc: 0.8260\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3726 - acc: 0.8422\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01139519 0.         1.01183914 0.99968586 1.01058174 1.01101101\n",
      "  1.00920852 1.01287009 0.         1.00957406 1.01183914 1.00877762\n",
      "  1.01368498]]\n",
      "[[-0.72491455  0.         -0.5501709   0.09692383 -1.73718262 -1.\n",
      "   1.27508545 -0.35290527  0.          2.37023926 -0.5501709   0.82525635\n",
      "  -0.27508545]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 71us/sample - loss: 39.6895 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 6.7260 - acc: 0.5323\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 2.6001 - acc: 0.6065\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 2.1327 - acc: 0.6122\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 1.8399 - acc: 0.6217\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 1.5992 - acc: 0.6179\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 1.3894 - acc: 0.6217\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 1.1923 - acc: 0.6217\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 1.0273 - acc: 0.6331\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.8742 - acc: 0.6445\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.7408 - acc: 0.6435\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6791 - acc: 0.6702\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6121 - acc: 0.6873\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.5911 - acc: 0.6854\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.5784 - acc: 0.7034\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.5708 - acc: 0.7034\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5541 - acc: 0.7082\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5769 - acc: 0.6949\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5590 - acc: 0.7063\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.5380 - acc: 0.7243\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5426 - acc: 0.7015\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.5343 - acc: 0.7234\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5398 - acc: 0.7234\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5147 - acc: 0.7424\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5387 - acc: 0.7158\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5131 - acc: 0.7395\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5188 - acc: 0.7405\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4989 - acc: 0.7510\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4982 - acc: 0.7481\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.5167 - acc: 0.7405\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5000 - acc: 0.7452\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4939 - acc: 0.7510\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4982 - acc: 0.7424\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4951 - acc: 0.7567\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4768 - acc: 0.7519\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4955 - acc: 0.7538\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4757 - acc: 0.7557\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4700 - acc: 0.7652\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4728 - acc: 0.7652\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4694 - acc: 0.7728\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4576 - acc: 0.7823\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4524 - acc: 0.7833\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4549 - acc: 0.7605\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4616 - acc: 0.7662\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4523 - acc: 0.7747\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4738 - acc: 0.7652\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4439 - acc: 0.7833\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4431 - acc: 0.7899\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4555 - acc: 0.7738\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4523 - acc: 0.7709\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4395 - acc: 0.7880\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4637 - acc: 0.7766\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4471 - acc: 0.7833\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4347 - acc: 0.7776\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4332 - acc: 0.7804\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4364 - acc: 0.7833\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4245 - acc: 0.8032\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4314 - acc: 0.7947\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4258 - acc: 0.7928\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4265 - acc: 0.8013\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4191 - acc: 0.8004\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4231 - acc: 0.8013\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4349 - acc: 0.7899\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4169 - acc: 0.7975\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4156 - acc: 0.7985\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4137 - acc: 0.8146\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4283 - acc: 0.7956\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4261 - acc: 0.7985\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4111 - acc: 0.8070\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4227 - acc: 0.7956\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4225 - acc: 0.7956\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4149 - acc: 0.7966\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4391 - acc: 0.7890\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4181 - acc: 0.7975\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4169 - acc: 0.7947\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4078 - acc: 0.8108\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3987 - acc: 0.8137\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4180 - acc: 0.8089\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4129 - acc: 0.8070\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3984 - acc: 0.8232\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3977 - acc: 0.8184\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4017 - acc: 0.8184\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4168 - acc: 0.8023\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4074 - acc: 0.8099\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3957 - acc: 0.8241\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3989 - acc: 0.8232\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3952 - acc: 0.8232\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4081 - acc: 0.8099\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4151 - acc: 0.8061\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4106 - acc: 0.8203\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4131 - acc: 0.8032\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4026 - acc: 0.8203\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4140 - acc: 0.8108\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3923 - acc: 0.8184\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3935 - acc: 0.8279\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4220 - acc: 0.7994\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4448 - acc: 0.7861\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3933 - acc: 0.8146\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3903 - acc: 0.8289\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3915 - acc: 0.8175\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.0105108  1.00800566 1.00796193 1.01104511 1.00961621 1.00800566\n",
      "  1.00796193 1.01065711 1.00800566 1.0093558  1.01067135 0.\n",
      "  1.00800566]]\n",
      "[[-1.97827148  0.50543213  0.49456787 -0.96740723  2.63061523  0.50543213\n",
      "   0.49456787 -1.5380249   0.50543213  1.5668396  -1.50543213  0.\n",
      "   0.50543213]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 95us/sample - loss: 10.5962 - acc: 0.4981\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 1.1246 - acc: 0.5048\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.6818 - acc: 0.6008\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6520 - acc: 0.6264\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6442 - acc: 0.6293\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.6390 - acc: 0.6407\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.6354 - acc: 0.6445\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.6177 - acc: 0.6721\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.6157 - acc: 0.6549\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.6088 - acc: 0.6578\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.6006 - acc: 0.6568\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.5888 - acc: 0.6768\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5778 - acc: 0.6977\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.5564 - acc: 0.7310\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.5539 - acc: 0.7243\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5475 - acc: 0.7338\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.5370 - acc: 0.7471\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.5278 - acc: 0.7196\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.5162 - acc: 0.7490\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5092 - acc: 0.7567\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4946 - acc: 0.7709\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4951 - acc: 0.7576\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4796 - acc: 0.7576\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4827 - acc: 0.7519\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4724 - acc: 0.7795\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4661 - acc: 0.7890\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4561 - acc: 0.7738\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4561 - acc: 0.7747\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4764 - acc: 0.7757\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4393 - acc: 0.7861\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4607 - acc: 0.7823\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4409 - acc: 0.7909\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4317 - acc: 0.8089\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4298 - acc: 0.8061\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4263 - acc: 0.8146\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4146 - acc: 0.8203\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4237 - acc: 0.7994\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4225 - acc: 0.7994\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4126 - acc: 0.8184\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4107 - acc: 0.8127\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4106 - acc: 0.8156\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4352 - acc: 0.8070\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4028 - acc: 0.8232\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4121 - acc: 0.8070\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3999 - acc: 0.8184\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3971 - acc: 0.8298\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4009 - acc: 0.8279\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4194 - acc: 0.8051\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4057 - acc: 0.8013\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4031 - acc: 0.8184\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4124 - acc: 0.7956\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4061 - acc: 0.8184\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4028 - acc: 0.8137\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3906 - acc: 0.8317\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3958 - acc: 0.8203\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3952 - acc: 0.8289\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3881 - acc: 0.8337\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3900 - acc: 0.8279\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3848 - acc: 0.8375\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3968 - acc: 0.8232\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4140 - acc: 0.8089\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3871 - acc: 0.8337\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4115 - acc: 0.8127\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3768 - acc: 0.8365\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3913 - acc: 0.8270\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4046 - acc: 0.8118\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3927 - acc: 0.8289\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3788 - acc: 0.8394\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4020 - acc: 0.8080\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3912 - acc: 0.8327\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3774 - acc: 0.8375\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3933 - acc: 0.8241\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3815 - acc: 0.8346\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3961 - acc: 0.8241\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3873 - acc: 0.8241\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3800 - acc: 0.8375\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3759 - acc: 0.8403\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3937 - acc: 0.8175\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3935 - acc: 0.8260\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3843 - acc: 0.8298\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3756 - acc: 0.8384\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3869 - acc: 0.8298\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3702 - acc: 0.8337\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3828 - acc: 0.8460\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3783 - acc: 0.8470\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3734 - acc: 0.8413\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3697 - acc: 0.8441\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3927 - acc: 0.8222\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3861 - acc: 0.8337\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3675 - acc: 0.8451\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3793 - acc: 0.8384\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4056 - acc: 0.8213\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3718 - acc: 0.8451\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3733 - acc: 0.8432\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3704 - acc: 0.8489\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3898 - acc: 0.8308\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4080 - acc: 0.8032\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3857 - acc: 0.8298\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3684 - acc: 0.8479\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3697 - acc: 0.8413\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00894924 1.01687027 1.01050525 0.         1.01036297 0.\n",
      "  1.00881593 1.01021659 0.         1.00810804 1.01342349 1.00659956\n",
      "  0.        ]]\n",
      "[[ 0.96020508 -0.14801025 -2.          0.         -2.78356934  0.\n",
      "   0.85198975 -4.66418457  0.          0.53283691 -0.29602051  0.29602051\n",
      "   0.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 72us/sample - loss: 4.0459 - acc: 0.6112\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 2.4880 - acc: 0.6331\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 2.1526 - acc: 0.6312\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 1.9607 - acc: 0.6435\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 1.8074 - acc: 0.6606\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 1.6477 - acc: 0.6692\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 1.5072 - acc: 0.6778\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.4000 - acc: 0.6730\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.2877 - acc: 0.6768\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.1774 - acc: 0.6806\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.0863 - acc: 0.6920\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.9723 - acc: 0.6911\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.8964 - acc: 0.6920\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.8303 - acc: 0.6949\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.8400 - acc: 0.7044\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.7484 - acc: 0.7110\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.7181 - acc: 0.7082\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6878 - acc: 0.7110\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6163 - acc: 0.7177\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5648 - acc: 0.7262\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5633 - acc: 0.7291\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5805 - acc: 0.7253\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5047 - acc: 0.7471\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5323 - acc: 0.7376\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4735 - acc: 0.7738\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4587 - acc: 0.7681\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4927 - acc: 0.7529\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4769 - acc: 0.7652\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4501 - acc: 0.7871\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4400 - acc: 0.7880\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4585 - acc: 0.7738\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4588 - acc: 0.7690\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4802 - acc: 0.7671\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4413 - acc: 0.7975\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4351 - acc: 0.7852\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4416 - acc: 0.7899\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4346 - acc: 0.8023\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4195 - acc: 0.8023\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4179 - acc: 0.8004\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4644 - acc: 0.7795\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4148 - acc: 0.8099\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4130 - acc: 0.8222\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4203 - acc: 0.8137\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4476 - acc: 0.8013\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4311 - acc: 0.7918\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3982 - acc: 0.8194\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4112 - acc: 0.8032\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4360 - acc: 0.7880\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3949 - acc: 0.8308\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4252 - acc: 0.8023\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4072 - acc: 0.8146\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4268 - acc: 0.7871\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4123 - acc: 0.8175\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3995 - acc: 0.8175\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4751 - acc: 0.7795\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4229 - acc: 0.8051\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3997 - acc: 0.8270\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3893 - acc: 0.8184\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4066 - acc: 0.8080\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4531 - acc: 0.7909\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3926 - acc: 0.8222\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4053 - acc: 0.8165\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4051 - acc: 0.8232\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4588 - acc: 0.7804\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4534 - acc: 0.7842\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4807 - acc: 0.7709\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4065 - acc: 0.8165\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4143 - acc: 0.8099\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3910 - acc: 0.8175\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3861 - acc: 0.8270\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3923 - acc: 0.8203\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4190 - acc: 0.8061\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4256 - acc: 0.7937\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4010 - acc: 0.8108\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3967 - acc: 0.8165\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3786 - acc: 0.8432\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4281 - acc: 0.8051\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4012 - acc: 0.8232\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3992 - acc: 0.8184\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3741 - acc: 0.8403\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4237 - acc: 0.8042\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4011 - acc: 0.8156\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3764 - acc: 0.8422\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3994 - acc: 0.8165\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4236 - acc: 0.8042\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4328 - acc: 0.8023\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3928 - acc: 0.8241\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4028 - acc: 0.8127\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3850 - acc: 0.8270\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4034 - acc: 0.8289\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3933 - acc: 0.8184\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4018 - acc: 0.8175\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3829 - acc: 0.8384\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3792 - acc: 0.8422\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3998 - acc: 0.8184\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3996 - acc: 0.8222\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3772 - acc: 0.8413\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3752 - acc: 0.8365\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3883 - acc: 0.8317\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3698 - acc: 0.8498\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00964853 0.         1.01101101 1.01028511 1.00958105 0.\n",
      "  1.01101101 1.01042874 1.00516906 1.00848535 1.0148776  1.00757874\n",
      "  1.01101101]]\n",
      "[[ 2.87261963  0.         -1.         -3.54351807  2.40979004  0.\n",
      "  -1.         -2.35675049  0.20806885  0.66582031 -0.20806885  0.4161377\n",
      "  -1.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 73us/sample - loss: 2.8770 - acc: 0.3973\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.8754 - acc: 0.4240\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.3813 - acc: 0.4173\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.0924 - acc: 0.4734\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 1.0073 - acc: 0.5133\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.8595 - acc: 0.5380\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.7855 - acc: 0.5856\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.7222 - acc: 0.5951\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.6697 - acc: 0.6464\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.6321 - acc: 0.6492\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6008 - acc: 0.6901\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5763 - acc: 0.6977\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5542 - acc: 0.7072\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5482 - acc: 0.7395\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5677 - acc: 0.7120\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5431 - acc: 0.7196\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5172 - acc: 0.7367\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5253 - acc: 0.7338\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5457 - acc: 0.7177\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4903 - acc: 0.7452\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4784 - acc: 0.7567\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4856 - acc: 0.7462\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4891 - acc: 0.7567\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4640 - acc: 0.7747\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4801 - acc: 0.7538\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4652 - acc: 0.7690\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4673 - acc: 0.7510\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4563 - acc: 0.7643\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4690 - acc: 0.7614\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4380 - acc: 0.8004\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4561 - acc: 0.7738\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4346 - acc: 0.7833\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4220 - acc: 0.7947\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4524 - acc: 0.7719\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4556 - acc: 0.7823\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4189 - acc: 0.8004\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4127 - acc: 0.7994\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4138 - acc: 0.8042\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4181 - acc: 0.7937\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4221 - acc: 0.8080\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4114 - acc: 0.7985\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4091 - acc: 0.8070\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4022 - acc: 0.8108\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4179 - acc: 0.8013\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4024 - acc: 0.8099\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3975 - acc: 0.8137\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3957 - acc: 0.8270\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4196 - acc: 0.7994\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3956 - acc: 0.8089\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4118 - acc: 0.7880\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3902 - acc: 0.8213\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3935 - acc: 0.8099\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3882 - acc: 0.8184\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3973 - acc: 0.8232\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3908 - acc: 0.8232\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4055 - acc: 0.8118\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3944 - acc: 0.8222\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3958 - acc: 0.8137\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3890 - acc: 0.8241\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3796 - acc: 0.8222\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4047 - acc: 0.8080\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4150 - acc: 0.8042\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3765 - acc: 0.8279\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3926 - acc: 0.8260\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3835 - acc: 0.8279\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3754 - acc: 0.8394\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3955 - acc: 0.8298\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3923 - acc: 0.8203\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3875 - acc: 0.8165\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3948 - acc: 0.8165\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3744 - acc: 0.8308\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3799 - acc: 0.8184\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3840 - acc: 0.8194\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3681 - acc: 0.8365\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3729 - acc: 0.8279\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3776 - acc: 0.8213\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3886 - acc: 0.8127\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3731 - acc: 0.8203\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4023 - acc: 0.8203\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3680 - acc: 0.8451\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3924 - acc: 0.8270\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3658 - acc: 0.8337\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8394\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4239 - acc: 0.7871\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3720 - acc: 0.8175\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3748 - acc: 0.8232\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3905 - acc: 0.8222\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3623 - acc: 0.8536\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3704 - acc: 0.8403\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3721 - acc: 0.8479\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3640 - acc: 0.8517\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3796 - acc: 0.8222\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3714 - acc: 0.8251\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3749 - acc: 0.8270\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3880 - acc: 0.8203\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.3729 - acc: 0.8384\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3688 - acc: 0.8489\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3646 - acc: 0.8403\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3775 - acc: 0.8289\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3778 - acc: 0.8317\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00970102 0.         1.00949525 1.00989901 1.01028735 1.00731165\n",
      "  0.         1.01072621 0.         1.00934896 1.01073524 1.00946188\n",
      "  0.        ]]\n",
      "[[ 3.37713623  0.          2.         10.         -3.51586914  0.37469482\n",
      "   0.         -1.39178467  0.          1.55036621 -1.37469482  1.87591553\n",
      "   0.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 77us/sample - loss: 56.6399 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 17.2794 - acc: 0.5029\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 2.3874 - acc: 0.5418\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.7862 - acc: 0.5618\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.6279 - acc: 0.5637\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.5072 - acc: 0.5504\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 1.3741 - acc: 0.5637\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 1.2764 - acc: 0.5570\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 1.1584 - acc: 0.5675\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.1087 - acc: 0.5542\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.9805 - acc: 0.5656\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.9202 - acc: 0.5675\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.9128 - acc: 0.5846\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.8000 - acc: 0.5808\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.7553 - acc: 0.5865\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.7204 - acc: 0.6036\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6704 - acc: 0.6321\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.6441 - acc: 0.6521\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5987 - acc: 0.6702\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5769 - acc: 0.6835\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5808 - acc: 0.7101\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5719 - acc: 0.6911\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5102 - acc: 0.7490\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.5003 - acc: 0.7643\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.5081 - acc: 0.7671\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4971 - acc: 0.7643\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4825 - acc: 0.7738\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4653 - acc: 0.7852\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4503 - acc: 0.7937\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4474 - acc: 0.7956\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4598 - acc: 0.7909\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4390 - acc: 0.7937\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4355 - acc: 0.7985\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4328 - acc: 0.8203\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4403 - acc: 0.7985\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4731 - acc: 0.7728\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4177 - acc: 0.8137\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4224 - acc: 0.8099\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4308 - acc: 0.8023\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4200 - acc: 0.8061\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4168 - acc: 0.8108\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4115 - acc: 0.8194\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4336 - acc: 0.7880\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4341 - acc: 0.7966\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4042 - acc: 0.8232\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4085 - acc: 0.8070\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4132 - acc: 0.8146\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4134 - acc: 0.8108\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4078 - acc: 0.8165\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4203 - acc: 0.7966\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4164 - acc: 0.8032\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4076 - acc: 0.8184\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3992 - acc: 0.8308\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4008 - acc: 0.8289\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3925 - acc: 0.8346\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3908 - acc: 0.8317\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3960 - acc: 0.8241\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3957 - acc: 0.8156\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4048 - acc: 0.8203\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4051 - acc: 0.8156\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4075 - acc: 0.8279\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3935 - acc: 0.8384\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3965 - acc: 0.8251\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3937 - acc: 0.8251\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4102 - acc: 0.8032\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4155 - acc: 0.7985\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4063 - acc: 0.8137\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3858 - acc: 0.8384\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3943 - acc: 0.8232\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3801 - acc: 0.8384\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3845 - acc: 0.8394\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3893 - acc: 0.8337\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3924 - acc: 0.8260\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3831 - acc: 0.8289\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3879 - acc: 0.8260\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4155 - acc: 0.8175\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4167 - acc: 0.8042\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3913 - acc: 0.8308\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3819 - acc: 0.8298\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4131 - acc: 0.8042\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3899 - acc: 0.8289\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3757 - acc: 0.8470\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3736 - acc: 0.8422\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3781 - acc: 0.8375\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3764 - acc: 0.8356\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3842 - acc: 0.8298\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3813 - acc: 0.8260\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3938 - acc: 0.8413\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3762 - acc: 0.8413\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3739 - acc: 0.8422\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3773 - acc: 0.8327\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3732 - acc: 0.8403\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3799 - acc: 0.8413\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3771 - acc: 0.8422\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4022 - acc: 0.8165\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3779 - acc: 0.8356\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3788 - acc: 0.8270\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3705 - acc: 0.8451\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3695 - acc: 0.8479\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3757 - acc: 0.8337\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01079842 1.00651726 1.01071077 1.01011968 1.0114871  1.00651726\n",
      "  0.         1.0097461  1.00651726 1.00804491 1.01101101 0.\n",
      "  1.00651726]]\n",
      "[[-1.26599121  0.28900146 -1.42199707 -8.43994141 -0.68017578  0.28900146\n",
      "   0.          3.97698975  0.28900146  0.51560059 -1.          0.\n",
      "   0.28900146]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 82us/sample - loss: 18.4226 - acc: 0.5048\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 2.2103 - acc: 0.5846\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.5521 - acc: 0.5837\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.2243 - acc: 0.5675\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 1.0203 - acc: 0.5561\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.8901 - acc: 0.5865\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.8186 - acc: 0.5884\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.7814 - acc: 0.6169\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.7399 - acc: 0.6397\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.7264 - acc: 0.6454\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.7025 - acc: 0.6530\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6781 - acc: 0.6673\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.6648 - acc: 0.6578\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.6682 - acc: 0.6692\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.6559 - acc: 0.6597\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6330 - acc: 0.6806\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.6234 - acc: 0.6816\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6428 - acc: 0.6721\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.6374 - acc: 0.6663\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5954 - acc: 0.7148\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5995 - acc: 0.6977\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5955 - acc: 0.7110\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5878 - acc: 0.7025\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.6303 - acc: 0.6692\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.6038 - acc: 0.6996\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.6081 - acc: 0.7072\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5653 - acc: 0.7310\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5604 - acc: 0.7319\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.5637 - acc: 0.7072\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5422 - acc: 0.7367\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5474 - acc: 0.7310\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.5480 - acc: 0.7338\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5415 - acc: 0.7348\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5174 - acc: 0.7452\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5351 - acc: 0.7272\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5096 - acc: 0.7452\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4994 - acc: 0.7643\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4988 - acc: 0.7500\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5042 - acc: 0.7519\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4877 - acc: 0.7700\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4987 - acc: 0.7538\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4869 - acc: 0.7690\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4772 - acc: 0.7785\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.5507 - acc: 0.7243\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4771 - acc: 0.7690\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4817 - acc: 0.7700\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4556 - acc: 0.7928\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4562 - acc: 0.7871\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4639 - acc: 0.7880\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4480 - acc: 0.8013\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4527 - acc: 0.7994\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4505 - acc: 0.7909\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4393 - acc: 0.7890\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4497 - acc: 0.7795\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4330 - acc: 0.7880\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4473 - acc: 0.7861\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4335 - acc: 0.8070\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4766 - acc: 0.7728\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4535 - acc: 0.7966\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4198 - acc: 0.8099\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4415 - acc: 0.8004\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4150 - acc: 0.8203\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4073 - acc: 0.8279\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4135 - acc: 0.8127\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4019 - acc: 0.8184\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4114 - acc: 0.8089\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4182 - acc: 0.8175\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4093 - acc: 0.8213\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.4006 - acc: 0.8213\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4013 - acc: 0.8213\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4003 - acc: 0.8099\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4004 - acc: 0.8127\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3976 - acc: 0.8289\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4287 - acc: 0.7890\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4431 - acc: 0.7899\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3895 - acc: 0.8213\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4091 - acc: 0.8260\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3932 - acc: 0.8279\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4226 - acc: 0.8042\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4156 - acc: 0.8118\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3928 - acc: 0.8356\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3826 - acc: 0.8337\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3799 - acc: 0.8327\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.4120 - acc: 0.7966\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3922 - acc: 0.8279\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4112 - acc: 0.8070\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4470 - acc: 0.7880\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4423 - acc: 0.8061\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4095 - acc: 0.8118\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3830 - acc: 0.8241\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 14us/sample - loss: 0.3820 - acc: 0.8270\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4059 - acc: 0.8004\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3752 - acc: 0.8432\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3943 - acc: 0.8279\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3824 - acc: 0.8279\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3697 - acc: 0.8422\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3758 - acc: 0.8451\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.3814 - acc: 0.8241\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 15us/sample - loss: 0.4110 - acc: 0.8146\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 16us/sample - loss: 0.3800 - acc: 0.8470\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00907762 0.         1.01149963 1.00928898 1.00921277 0.\n",
      "  1.00690659 1.01056393 1.00850481 1.01161729 0.         0.\n",
      "  1.00850481]]\n",
      "[[ 1.09399414  0.         -0.67449951  1.41949463  1.28198242  0.\n",
      "   0.32550049 -1.79199219  0.67449951 -0.62550049  0.          0.\n",
      "   0.67449951]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 125us/sample - loss: 2.0459 - acc: 0.5741\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.9451 - acc: 0.5760\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.7215 - acc: 0.5741\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6702 - acc: 0.5789\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6642 - acc: 0.5751\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6636 - acc: 0.5713\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6616 - acc: 0.5694\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6556 - acc: 0.5760\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6798 - acc: 0.5703\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6688 - acc: 0.5580\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6471 - acc: 0.5779\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6447 - acc: 0.5713\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6378 - acc: 0.5760\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6415 - acc: 0.5865\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6326 - acc: 0.6046\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6287 - acc: 0.6378\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.6281 - acc: 0.6293\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6173 - acc: 0.6625\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6162 - acc: 0.6702\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6189 - acc: 0.6625\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6151 - acc: 0.6616\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6214 - acc: 0.6445\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6135 - acc: 0.6597\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6142 - acc: 0.6702\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6118 - acc: 0.6654\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6061 - acc: 0.6683\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6119 - acc: 0.6692\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.6071 - acc: 0.6702\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6030 - acc: 0.6683\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.6025 - acc: 0.6673\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.6059 - acc: 0.6635\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6048 - acc: 0.6816\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5998 - acc: 0.6730\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6001 - acc: 0.6683\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5876 - acc: 0.6797\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5921 - acc: 0.6844\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5896 - acc: 0.6854\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5902 - acc: 0.6730\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5905 - acc: 0.6854\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6018 - acc: 0.6825\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5886 - acc: 0.6863\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5787 - acc: 0.6987\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5858 - acc: 0.7044\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5793 - acc: 0.6930\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5814 - acc: 0.6977\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5808 - acc: 0.7072\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5812 - acc: 0.6930\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5723 - acc: 0.6996\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5829 - acc: 0.6901\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5691 - acc: 0.7053\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5733 - acc: 0.7044\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5760 - acc: 0.7063\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5668 - acc: 0.7158\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5674 - acc: 0.7072\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5608 - acc: 0.7234\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5768 - acc: 0.7063\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5651 - acc: 0.7110\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5590 - acc: 0.7129\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5559 - acc: 0.7196\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5558 - acc: 0.7129\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5661 - acc: 0.7167\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5655 - acc: 0.7120\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5594 - acc: 0.7129\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5451 - acc: 0.7186\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5468 - acc: 0.7234\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5464 - acc: 0.7253\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.5602 - acc: 0.7167\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5517 - acc: 0.7158\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5469 - acc: 0.7272\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5454 - acc: 0.7272\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5357 - acc: 0.7205\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5299 - acc: 0.7338\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5312 - acc: 0.7205\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5212 - acc: 0.7281\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5232 - acc: 0.7395\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.5148 - acc: 0.7367\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5182 - acc: 0.7348\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5217 - acc: 0.7281\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5160 - acc: 0.7272\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5104 - acc: 0.7367\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5135 - acc: 0.7567\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5034 - acc: 0.7395\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5068 - acc: 0.7395\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4923 - acc: 0.7348\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4926 - acc: 0.7395\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4899 - acc: 0.7576\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4905 - acc: 0.7386\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4876 - acc: 0.7586\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4772 - acc: 0.7529\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4730 - acc: 0.7519\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4817 - acc: 0.7500\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4657 - acc: 0.7557\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4608 - acc: 0.7614\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4570 - acc: 0.7671\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4498 - acc: 0.7690\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4446 - acc: 0.7700\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4392 - acc: 0.7804\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4442 - acc: 0.7842\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4520 - acc: 0.7833\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4346 - acc: 0.7985\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01214111 1.0086988  1.01130456 1.00964321 1.01055734 0.\n",
      "  0.         1.00824209 1.0086988  1.01091902 0.         1.00899101\n",
      "  1.0086988 ]]\n",
      "[[-0.47271729  0.77520752 -0.77520752  2.82977295 -1.81317139  0.\n",
      "   0.          0.57354736  0.77520752 -1.1         0.          1.\n",
      "   0.77520752]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 114us/sample - loss: 15.8113 - acc: 0.4591\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 4.3881 - acc: 0.4087\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 1.1053 - acc: 0.5589\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6161 - acc: 0.7110\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5892 - acc: 0.7072\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5737 - acc: 0.7329\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5669 - acc: 0.7253\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5622 - acc: 0.7262\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5465 - acc: 0.7338\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5463 - acc: 0.7291\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5601 - acc: 0.7348\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5610 - acc: 0.7215\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5818 - acc: 0.6844\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5362 - acc: 0.7319\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5247 - acc: 0.7405\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5381 - acc: 0.7272\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4904 - acc: 0.7652\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5190 - acc: 0.7414\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4824 - acc: 0.7576\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4885 - acc: 0.7576\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4969 - acc: 0.7424\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4983 - acc: 0.7405\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4744 - acc: 0.7709\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4593 - acc: 0.7814\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4886 - acc: 0.7538\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4492 - acc: 0.7928\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4661 - acc: 0.7738\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4526 - acc: 0.7795\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4787 - acc: 0.7690\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4477 - acc: 0.7842\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4376 - acc: 0.7823\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4375 - acc: 0.7909\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4286 - acc: 0.7890\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4229 - acc: 0.8051\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4224 - acc: 0.8004\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4615 - acc: 0.7757\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4341 - acc: 0.7956\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4540 - acc: 0.7747\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4349 - acc: 0.7795\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4368 - acc: 0.7861\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4251 - acc: 0.7985\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4276 - acc: 0.8013\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4117 - acc: 0.8203\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4100 - acc: 0.8165\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4232 - acc: 0.7985\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4097 - acc: 0.8108\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4024 - acc: 0.8222\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4383 - acc: 0.7880\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4070 - acc: 0.8108\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4086 - acc: 0.8156\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3978 - acc: 0.8222\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4159 - acc: 0.8080\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4270 - acc: 0.8013\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4113 - acc: 0.8032\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3968 - acc: 0.8279\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3962 - acc: 0.8118\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4370 - acc: 0.7994\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4706 - acc: 0.7776\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4380 - acc: 0.7852\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4231 - acc: 0.8070\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4150 - acc: 0.8042\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3882 - acc: 0.8337\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4082 - acc: 0.8070\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4032 - acc: 0.8118\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3936 - acc: 0.8337\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3991 - acc: 0.8222\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3804 - acc: 0.8394\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3871 - acc: 0.8403\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3818 - acc: 0.8413\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3841 - acc: 0.8289\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4002 - acc: 0.8118\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3883 - acc: 0.8337\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3899 - acc: 0.8279\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3884 - acc: 0.8298\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3758 - acc: 0.8365\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3830 - acc: 0.8317\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3973 - acc: 0.8222\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3740 - acc: 0.8403\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3789 - acc: 0.8384\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4090 - acc: 0.8241\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3865 - acc: 0.8203\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4067 - acc: 0.8241\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3957 - acc: 0.8251\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3843 - acc: 0.8317\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3888 - acc: 0.8356\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3864 - acc: 0.8375\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4281 - acc: 0.7814\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4077 - acc: 0.8080\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3857 - acc: 0.8327\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3782 - acc: 0.8356\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3894 - acc: 0.8317\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3807 - acc: 0.8403\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4258 - acc: 0.8070\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4020 - acc: 0.8203\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3786 - acc: 0.8260\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3775 - acc: 0.8384\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4064 - acc: 0.8042\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3768 - acc: 0.8413\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3915 - acc: 0.8194\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3735 - acc: 0.8384\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00811965 0.         1.00960221 1.01032805 1.00917703 1.00899101\n",
      "  0.         1.01030576 1.00348352 1.01058145 1.01087598 1.00880757\n",
      "  1.00912553]]\n",
      "[[ 0.53613281  0.          2.5380249  -3.07983398  1.22625732  1.\n",
      "   0.         -3.30419922  0.1539917  -1.7380249  -1.1539917   0.8460083\n",
      "   1.1539917 ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 129us/sample - loss: 4.4316 - acc: 0.5048\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 1.5805 - acc: 0.5770\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.9739 - acc: 0.5998\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.7897 - acc: 0.6274\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.7515 - acc: 0.6255\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.7160 - acc: 0.6559\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.7144 - acc: 0.6188\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7009 - acc: 0.6283\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6879 - acc: 0.6264\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6722 - acc: 0.6388\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6673 - acc: 0.6245\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6641 - acc: 0.6416\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.6722 - acc: 0.6160\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6480 - acc: 0.6473\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6408 - acc: 0.6464\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6406 - acc: 0.6473\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6313 - acc: 0.6673\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6321 - acc: 0.6350\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6230 - acc: 0.6759\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6177 - acc: 0.6759\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6198 - acc: 0.6654\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6353 - acc: 0.6473\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6187 - acc: 0.6511\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6125 - acc: 0.6464\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6097 - acc: 0.6606\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6164 - acc: 0.6483\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6035 - acc: 0.6597\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6039 - acc: 0.6426\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6052 - acc: 0.6464\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5940 - acc: 0.6721\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5903 - acc: 0.6911\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5929 - acc: 0.6768\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6033 - acc: 0.6911\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5937 - acc: 0.6625\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5811 - acc: 0.6968\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5795 - acc: 0.6901\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5780 - acc: 0.6835\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5766 - acc: 0.6901\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5973 - acc: 0.6606\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5676 - acc: 0.7034\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5716 - acc: 0.7025\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5664 - acc: 0.6920\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5562 - acc: 0.7053\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5564 - acc: 0.7091\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5592 - acc: 0.7101\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5514 - acc: 0.7063\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5417 - acc: 0.7139\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5540 - acc: 0.7072\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5624 - acc: 0.7006\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5379 - acc: 0.7234\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5403 - acc: 0.7167\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5481 - acc: 0.7101\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5300 - acc: 0.7319\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5371 - acc: 0.7253\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5288 - acc: 0.7281\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5238 - acc: 0.7291\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5233 - acc: 0.7243\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5187 - acc: 0.7215\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5208 - acc: 0.7281\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5128 - acc: 0.7291\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5142 - acc: 0.7338\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5669 - acc: 0.7139\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5449 - acc: 0.7167\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4992 - acc: 0.7405\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4964 - acc: 0.7519\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5069 - acc: 0.7433\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4949 - acc: 0.7462\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5004 - acc: 0.7557\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4877 - acc: 0.7557\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4871 - acc: 0.7462\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4845 - acc: 0.7500\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4935 - acc: 0.7462\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4871 - acc: 0.7519\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4828 - acc: 0.7595\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4660 - acc: 0.7681\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4670 - acc: 0.7662\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4821 - acc: 0.7652\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4637 - acc: 0.7662\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4508 - acc: 0.7690\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4533 - acc: 0.7614\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4527 - acc: 0.7662\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4478 - acc: 0.7747\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4530 - acc: 0.7652\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4549 - acc: 0.7719\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4502 - acc: 0.7814\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4463 - acc: 0.7823\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4337 - acc: 0.7795\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4543 - acc: 0.7643\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4293 - acc: 0.7852\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4404 - acc: 0.7861\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4208 - acc: 0.8070\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4154 - acc: 0.8061\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4164 - acc: 0.8070\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4081 - acc: 0.8194\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4069 - acc: 0.8156\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4216 - acc: 0.7975\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4069 - acc: 0.8051\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4056 - acc: 0.8156\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4201 - acc: 0.7937\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4003 - acc: 0.8175\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00947738 0.         0.         1.00964064 1.00952091 0.\n",
      "  1.01578471 1.01047954 1.0042808  1.00726847 1.01578471 1.00808638\n",
      "  1.0042808 ]]\n",
      "[[ 1.93157959  0.          0.          2.80957031  2.10717773  0.\n",
      "  -0.17559814 -2.10717773  0.17559814  0.3687561  -0.17559814  0.52679443\n",
      "   0.17559814]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 124us/sample - loss: 32.4644 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 5.1185 - acc: 0.5722\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 1.6839 - acc: 0.6245\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.1704 - acc: 0.6198\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 1.0392 - acc: 0.6359\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.9692 - acc: 0.6340\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.8936 - acc: 0.6188\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.8268 - acc: 0.6350\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.7733 - acc: 0.6397\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7500 - acc: 0.6673\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.7251 - acc: 0.6778\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6997 - acc: 0.6863\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6761 - acc: 0.7006\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6658 - acc: 0.7034\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6493 - acc: 0.7253\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6230 - acc: 0.7443\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6175 - acc: 0.7281\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.5907 - acc: 0.7557\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5701 - acc: 0.7519\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5542 - acc: 0.7567\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5415 - acc: 0.7795\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5200 - acc: 0.7662\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5067 - acc: 0.7814\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4875 - acc: 0.7747\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4964 - acc: 0.7567\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4678 - acc: 0.7937\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4518 - acc: 0.7918\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4393 - acc: 0.7994\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4484 - acc: 0.7985\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4294 - acc: 0.8070\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4295 - acc: 0.8156\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4398 - acc: 0.8032\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4286 - acc: 0.8080\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4188 - acc: 0.8108\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4056 - acc: 0.8279\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4042 - acc: 0.8213\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4273 - acc: 0.7956\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4574 - acc: 0.7823\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4056 - acc: 0.8308\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3971 - acc: 0.8270\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4246 - acc: 0.8108\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4288 - acc: 0.8118\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4163 - acc: 0.8070\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3978 - acc: 0.8270\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3971 - acc: 0.8317\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3911 - acc: 0.8298\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3912 - acc: 0.8203\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3854 - acc: 0.8460\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3838 - acc: 0.8422\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3874 - acc: 0.8298\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3823 - acc: 0.8432\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3984 - acc: 0.8146\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3963 - acc: 0.8213\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3853 - acc: 0.8365\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4083 - acc: 0.8175\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3813 - acc: 0.8451\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3816 - acc: 0.8460\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3766 - acc: 0.8517\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3817 - acc: 0.8394\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3746 - acc: 0.8432\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3709 - acc: 0.8365\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3979 - acc: 0.8308\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3831 - acc: 0.8384\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3947 - acc: 0.8232\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3862 - acc: 0.8317\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3775 - acc: 0.8337\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3779 - acc: 0.8394\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3838 - acc: 0.8241\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3868 - acc: 0.8270\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3857 - acc: 0.8413\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3734 - acc: 0.8470\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3777 - acc: 0.8451\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3728 - acc: 0.8432\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3978 - acc: 0.8194\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4071 - acc: 0.8118\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3721 - acc: 0.8508\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3708 - acc: 0.8441\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3922 - acc: 0.8241\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3911 - acc: 0.8270\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3795 - acc: 0.8337\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3736 - acc: 0.8460\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3755 - acc: 0.8413\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3720 - acc: 0.8498\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3762 - acc: 0.8422\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3707 - acc: 0.8413\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3614 - acc: 0.8565\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3681 - acc: 0.8403\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3845 - acc: 0.8384\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3685 - acc: 0.8479\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3827 - acc: 0.8241\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3704 - acc: 0.8422\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3896 - acc: 0.8222\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3908 - acc: 0.8289\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3662 - acc: 0.8422\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3617 - acc: 0.8451\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3743 - acc: 0.8508\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3693 - acc: 0.8451\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3758 - acc: 0.8375\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3734 - acc: 0.8365\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3802 - acc: 0.8394\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01029359 1.0072445  1.01042714 1.01027638 1.00958342 0.\n",
      "  1.01277062 1.00958147 0.         1.0110958  1.01277062 1.0072445\n",
      "  0.        ]]\n",
      "[[-3.44122314  0.36553955 -2.36553955 -3.65539551  2.42352295  0.\n",
      "  -0.36553955  2.41223145  0.         -0.92270508 -0.36553955  0.36553955\n",
      "   0.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 133us/sample - loss: 2.1447 - acc: 0.5865\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.7830 - acc: 0.6587\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6618 - acc: 0.6673\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6199 - acc: 0.6625\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5963 - acc: 0.6759\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5869 - acc: 0.6797\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5726 - acc: 0.6939\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5662 - acc: 0.6911\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5686 - acc: 0.6844\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5615 - acc: 0.6930\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5530 - acc: 0.6987\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5490 - acc: 0.6996\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5470 - acc: 0.7015\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5439 - acc: 0.7034\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5552 - acc: 0.6949\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5464 - acc: 0.7148\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5318 - acc: 0.7243\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5275 - acc: 0.7158\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5266 - acc: 0.7300\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5211 - acc: 0.7319\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5181 - acc: 0.7310\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5175 - acc: 0.7395\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5143 - acc: 0.7395\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5061 - acc: 0.7424\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5007 - acc: 0.7519\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4941 - acc: 0.7443\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4826 - acc: 0.7500\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4719 - acc: 0.7662\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4969 - acc: 0.7357\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4639 - acc: 0.7690\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4746 - acc: 0.7681\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4558 - acc: 0.7643\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4663 - acc: 0.7757\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4452 - acc: 0.7861\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4423 - acc: 0.7719\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4330 - acc: 0.7757\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4356 - acc: 0.7918\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4247 - acc: 0.7956\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4173 - acc: 0.8023\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4208 - acc: 0.7937\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4131 - acc: 0.8080\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4143 - acc: 0.8099\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4094 - acc: 0.8156\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4140 - acc: 0.8023\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4013 - acc: 0.8289\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4011 - acc: 0.8089\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3976 - acc: 0.8184\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4001 - acc: 0.8241\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4007 - acc: 0.8137\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3850 - acc: 0.8394\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3798 - acc: 0.8251\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3978 - acc: 0.8241\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3797 - acc: 0.8308\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3770 - acc: 0.8356\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3702 - acc: 0.8327\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3725 - acc: 0.8365\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3761 - acc: 0.8289\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3652 - acc: 0.8479\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3651 - acc: 0.8565\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3754 - acc: 0.8375\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3737 - acc: 0.8365\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3673 - acc: 0.8394\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3675 - acc: 0.8317\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3725 - acc: 0.8394\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3823 - acc: 0.8298\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3616 - acc: 0.8451\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3672 - acc: 0.8489\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3646 - acc: 0.8517\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3512 - acc: 0.8527\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3604 - acc: 0.8375\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3492 - acc: 0.8479\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3553 - acc: 0.8527\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3569 - acc: 0.8489\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3621 - acc: 0.8460\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3602 - acc: 0.8574\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3512 - acc: 0.8451\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3584 - acc: 0.8508\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3562 - acc: 0.8470\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3529 - acc: 0.8498\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3478 - acc: 0.8565\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3421 - acc: 0.8622\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3508 - acc: 0.8432\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3474 - acc: 0.8536\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3508 - acc: 0.8517\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3512 - acc: 0.8555\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3623 - acc: 0.8403\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3597 - acc: 0.8536\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3536 - acc: 0.8441\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3645 - acc: 0.8375\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3464 - acc: 0.8508\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3559 - acc: 0.8403\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3467 - acc: 0.8565\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3453 - acc: 0.8612\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3553 - acc: 0.8517\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3422 - acc: 0.8546\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3382 - acc: 0.8565\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3379 - acc: 0.8612\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3412 - acc: 0.8574\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3411 - acc: 0.8555\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3348 - acc: 0.8603\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01032539 0.         1.01312128 1.00922268 1.00970016 0.\n",
      "  1.01626192 1.01049002 1.01120711 1.00967599 1.0105499  1.00381478\n",
      "  0.        ]]\n",
      "[[-3.10498047  0.         -0.32458496  1.29833984  3.36743164  0.\n",
      "  -0.16229248 -2.06213379 -0.83770752  3.11622925 -1.83770752  0.16229248\n",
      "   0.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 135us/sample - loss: 11.8260 - acc: 0.4990\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 1.2015 - acc: 0.5228\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6752 - acc: 0.5989\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6438 - acc: 0.6274\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6294 - acc: 0.6435\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6182 - acc: 0.6473\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6311 - acc: 0.6217\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6241 - acc: 0.6188\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6137 - acc: 0.6331\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5992 - acc: 0.6549\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6038 - acc: 0.6397\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5946 - acc: 0.6597\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6034 - acc: 0.6454\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5890 - acc: 0.6578\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5831 - acc: 0.6644\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5832 - acc: 0.6587\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5786 - acc: 0.6787\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5717 - acc: 0.6787\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5716 - acc: 0.6740\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5688 - acc: 0.6892\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5711 - acc: 0.6663\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5649 - acc: 0.6778\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5574 - acc: 0.6882\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5506 - acc: 0.6806\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5541 - acc: 0.6844\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5591 - acc: 0.6730\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5402 - acc: 0.6730\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5284 - acc: 0.6768\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5062 - acc: 0.6930\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5120 - acc: 0.7243\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4899 - acc: 0.7814\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4814 - acc: 0.7814\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4833 - acc: 0.7757\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4652 - acc: 0.8051\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4699 - acc: 0.7975\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4637 - acc: 0.7985\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4564 - acc: 0.8051\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4447 - acc: 0.8108\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4791 - acc: 0.7795\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4667 - acc: 0.7956\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4441 - acc: 0.8222\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4370 - acc: 0.8213\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4347 - acc: 0.8146\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4325 - acc: 0.8137\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4347 - acc: 0.8194\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4265 - acc: 0.8270\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4252 - acc: 0.8232\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4242 - acc: 0.8184\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4151 - acc: 0.8260\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4311 - acc: 0.8194\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4043 - acc: 0.8375\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4150 - acc: 0.8260\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4050 - acc: 0.8298\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4021 - acc: 0.8232\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4185 - acc: 0.8251\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4307 - acc: 0.8203\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4104 - acc: 0.8184\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4070 - acc: 0.8279\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3989 - acc: 0.8308\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3921 - acc: 0.8356\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3947 - acc: 0.8289\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3862 - acc: 0.8432\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3883 - acc: 0.8394\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3841 - acc: 0.8413\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3900 - acc: 0.8365\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3829 - acc: 0.8451\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3776 - acc: 0.8451\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3965 - acc: 0.8289\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3799 - acc: 0.8422\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3736 - acc: 0.8508\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3757 - acc: 0.8536\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3703 - acc: 0.8574\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3650 - acc: 0.8546\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3899 - acc: 0.8327\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3719 - acc: 0.8555\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3785 - acc: 0.8365\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3793 - acc: 0.8403\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3643 - acc: 0.8508\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3720 - acc: 0.8555\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3651 - acc: 0.8498\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3763 - acc: 0.8460\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3680 - acc: 0.8536\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3724 - acc: 0.8489\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3696 - acc: 0.8536\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3594 - acc: 0.8641\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3646 - acc: 0.8593\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3849 - acc: 0.8394\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3655 - acc: 0.8508\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3518 - acc: 0.8745\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3586 - acc: 0.8536\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3670 - acc: 0.8622\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3638 - acc: 0.8555\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3720 - acc: 0.8384\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3562 - acc: 0.8717\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3585 - acc: 0.8546\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3468 - acc: 0.8726\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3540 - acc: 0.8603\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3549 - acc: 0.8679\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3650 - acc: 0.8460\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3654 - acc: 0.8555\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.0097226  1.00899101 1.01101101 1.01046195 1.01041658 0.\n",
      "  1.00871776 1.00857252 0.         1.01168614 0.         1.00528737\n",
      "  1.00871776]]\n",
      "[[ 3.63995361  1.         -1.         -2.18737793 -2.42547607  0.\n",
      "   0.78668213  0.70654297  0.         -0.6         0.          0.21331787\n",
      "   0.78668213]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 139us/sample - loss: 32.4078 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 4.0102 - acc: 0.5751\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 2.0199 - acc: 0.6141\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.7263 - acc: 0.6350\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 1.4502 - acc: 0.6283\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 1.1981 - acc: 0.6378\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 1.0168 - acc: 0.6426\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.8663 - acc: 0.6483\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7679 - acc: 0.6502\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7191 - acc: 0.6597\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.7044 - acc: 0.6454\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6820 - acc: 0.6597\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.7037 - acc: 0.6464\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6669 - acc: 0.6806\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6881 - acc: 0.6683\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6672 - acc: 0.6673\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6690 - acc: 0.6587\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6301 - acc: 0.6968\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6294 - acc: 0.6797\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6225 - acc: 0.6920\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6484 - acc: 0.6616\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5919 - acc: 0.7082\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5895 - acc: 0.7044\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5923 - acc: 0.6958\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5764 - acc: 0.7025\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5786 - acc: 0.7120\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5851 - acc: 0.7082\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5545 - acc: 0.7186\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5675 - acc: 0.7234\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5433 - acc: 0.7272\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5430 - acc: 0.7424\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5638 - acc: 0.7281\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5681 - acc: 0.7148\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5214 - acc: 0.7357\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5133 - acc: 0.7414\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5153 - acc: 0.7500\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5138 - acc: 0.7395\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5271 - acc: 0.7367\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5017 - acc: 0.7500\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5046 - acc: 0.7529\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4874 - acc: 0.7633\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4889 - acc: 0.7690\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4965 - acc: 0.7538\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4933 - acc: 0.7652\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4873 - acc: 0.7538\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4656 - acc: 0.7804\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4815 - acc: 0.7595\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5221 - acc: 0.7452\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4659 - acc: 0.7823\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4742 - acc: 0.7785\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4531 - acc: 0.7899\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4527 - acc: 0.7852\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4508 - acc: 0.7890\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4648 - acc: 0.7728\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4612 - acc: 0.7719\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4630 - acc: 0.7814\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4403 - acc: 0.7937\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4633 - acc: 0.7624\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4669 - acc: 0.7709\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4582 - acc: 0.7814\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4512 - acc: 0.7880\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4240 - acc: 0.8013\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4280 - acc: 0.7956\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4329 - acc: 0.8023\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4381 - acc: 0.7928\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4203 - acc: 0.8108\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4383 - acc: 0.7937\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4164 - acc: 0.8108\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4192 - acc: 0.8118\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4277 - acc: 0.7918\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4301 - acc: 0.7880\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4029 - acc: 0.8165\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4228 - acc: 0.8108\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4018 - acc: 0.8232\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3989 - acc: 0.8260\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4153 - acc: 0.8070\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4177 - acc: 0.7899\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4412 - acc: 0.7975\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4325 - acc: 0.8004\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4321 - acc: 0.7890\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3892 - acc: 0.8394\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3933 - acc: 0.8213\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3966 - acc: 0.8270\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3863 - acc: 0.8384\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3878 - acc: 0.8317\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4085 - acc: 0.8184\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3878 - acc: 0.8279\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3955 - acc: 0.8070\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3893 - acc: 0.8279\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3920 - acc: 0.8270\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3918 - acc: 0.8279\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3854 - acc: 0.8375\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3937 - acc: 0.8441\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3881 - acc: 0.8156\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3833 - acc: 0.8413\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3792 - acc: 0.8337\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3875 - acc: 0.8270\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3939 - acc: 0.8356\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3888 - acc: 0.8327\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3847 - acc: 0.8413\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00889159 1.00668206 1.01166719 1.00977812 1.01001376 0.\n",
      "  0.         1.01006528 0.         1.00585598 0.         1.00889159\n",
      "  1.01333988]]\n",
      "[[  0.91021729   0.30340576  -0.60681152   4.55108643 -73.42419434\n",
      "    0.           0.         -15.47369385   0.           0.24272461\n",
      "    0.           0.91021729  -0.30340576]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 141us/sample - loss: 16.5941 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 9.2513 - acc: 0.5000\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 4.9690 - acc: 0.4990\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 2.0617 - acc: 0.4800\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.8310 - acc: 0.4487\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6909 - acc: 0.5494\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6347 - acc: 0.6549\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6177 - acc: 0.6549\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6115 - acc: 0.6616\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6075 - acc: 0.6740\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6055 - acc: 0.6768\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6033 - acc: 0.6797\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6014 - acc: 0.6740\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5997 - acc: 0.6816\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5976 - acc: 0.6873\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5909 - acc: 0.6920\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5888 - acc: 0.6958\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5850 - acc: 0.6987\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5832 - acc: 0.7082\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5809 - acc: 0.7015\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5793 - acc: 0.7072\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5734 - acc: 0.7129\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5715 - acc: 0.7158\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5671 - acc: 0.7205\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5645 - acc: 0.7253\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5615 - acc: 0.7215\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5565 - acc: 0.7253\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5545 - acc: 0.7329\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5517 - acc: 0.7338\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5509 - acc: 0.7338\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5460 - acc: 0.7376\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5431 - acc: 0.7253\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5478 - acc: 0.7272\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5400 - acc: 0.7300\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5305 - acc: 0.7433\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5350 - acc: 0.7405\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5342 - acc: 0.7376\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5247 - acc: 0.7529\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5251 - acc: 0.7386\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5193 - acc: 0.7443\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5172 - acc: 0.7424\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5228 - acc: 0.7376\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5117 - acc: 0.7510\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5084 - acc: 0.7519\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5043 - acc: 0.7481\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5046 - acc: 0.7538\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5027 - acc: 0.7414\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4978 - acc: 0.7490\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4922 - acc: 0.7490\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4855 - acc: 0.7633\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4852 - acc: 0.7595\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4834 - acc: 0.7624\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4779 - acc: 0.7643\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4743 - acc: 0.7719\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4715 - acc: 0.7700\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4662 - acc: 0.7652\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4650 - acc: 0.7814\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4610 - acc: 0.7738\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4543 - acc: 0.7700\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4525 - acc: 0.7842\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4485 - acc: 0.7918\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4510 - acc: 0.7795\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4416 - acc: 0.7909\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4361 - acc: 0.8042\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4349 - acc: 0.7956\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4299 - acc: 0.8099\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4256 - acc: 0.8042\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4231 - acc: 0.8004\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4190 - acc: 0.8156\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4228 - acc: 0.8099\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4164 - acc: 0.8127\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4094 - acc: 0.8175\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4076 - acc: 0.8184\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4065 - acc: 0.8127\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4015 - acc: 0.8241\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4003 - acc: 0.8165\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4022 - acc: 0.8194\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3969 - acc: 0.8327\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4012 - acc: 0.8118\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3947 - acc: 0.8232\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3901 - acc: 0.8194\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3911 - acc: 0.8251\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3872 - acc: 0.8184\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3851 - acc: 0.8260\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3873 - acc: 0.8232\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3870 - acc: 0.8298\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4023 - acc: 0.8175\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3840 - acc: 0.8403\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3831 - acc: 0.8375\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3797 - acc: 0.8384\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3790 - acc: 0.8394\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3820 - acc: 0.8384\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3813 - acc: 0.8298\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3773 - acc: 0.8403\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3834 - acc: 0.8375\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3738 - acc: 0.8384\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3707 - acc: 0.8403\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3750 - acc: 0.8394\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3806 - acc: 0.8394\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3781 - acc: 0.8346\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00934875 0.98667294 0.         0.99820021 1.00976006 0.\n",
      "  0.98667294 1.00761778 0.         1.01507538 0.98667294 0.98667294\n",
      "  0.98667294]]\n",
      "[[ 1.54986572  0.04229736  0.          0.08459473  4.20837402  0.\n",
      "   0.04229736  0.42297363  0.         -0.2         0.04229736  0.04229736\n",
      "   0.04229736]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 152us/sample - loss: 2.2609 - acc: 0.5010\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.0808 - acc: 0.5960\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.9178 - acc: 0.5884\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.8073 - acc: 0.6226\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.7382 - acc: 0.6264\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.7104 - acc: 0.6359\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6751 - acc: 0.6445\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6620 - acc: 0.6435\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6345 - acc: 0.6578\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6415 - acc: 0.6483\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6126 - acc: 0.6806\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6009 - acc: 0.6816\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5856 - acc: 0.7034\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5883 - acc: 0.7015\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6069 - acc: 0.6768\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5765 - acc: 0.6977\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5689 - acc: 0.7148\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5527 - acc: 0.7167\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5700 - acc: 0.7034\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5492 - acc: 0.7148\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5478 - acc: 0.7101\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5409 - acc: 0.7262\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5348 - acc: 0.7329\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5302 - acc: 0.7405\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5218 - acc: 0.7471\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5039 - acc: 0.7576\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4949 - acc: 0.7595\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4848 - acc: 0.7814\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4829 - acc: 0.7757\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4965 - acc: 0.7424\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4781 - acc: 0.7652\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5033 - acc: 0.7405\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4644 - acc: 0.7757\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4795 - acc: 0.7662\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4610 - acc: 0.7757\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4549 - acc: 0.7719\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4529 - acc: 0.7852\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4517 - acc: 0.7795\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4509 - acc: 0.7975\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4555 - acc: 0.7852\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4313 - acc: 0.7966\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4274 - acc: 0.8127\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4360 - acc: 0.7947\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4274 - acc: 0.7975\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4180 - acc: 0.7975\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4164 - acc: 0.8099\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4225 - acc: 0.7975\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4148 - acc: 0.8108\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4192 - acc: 0.8137\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4017 - acc: 0.8289\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4050 - acc: 0.8222\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4113 - acc: 0.8013\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4285 - acc: 0.7928\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4157 - acc: 0.8023\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3912 - acc: 0.8241\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3902 - acc: 0.8260\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3818 - acc: 0.8298\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3889 - acc: 0.8289\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4059 - acc: 0.8203\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4121 - acc: 0.8089\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3869 - acc: 0.8327\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3825 - acc: 0.8203\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4029 - acc: 0.8146\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3706 - acc: 0.8451\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3807 - acc: 0.8375\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3711 - acc: 0.8489\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3823 - acc: 0.8298\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3786 - acc: 0.8422\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3692 - acc: 0.8365\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4152 - acc: 0.8032\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4185 - acc: 0.7909\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3826 - acc: 0.8365\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3728 - acc: 0.8470\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3696 - acc: 0.8375\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3695 - acc: 0.8394\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3963 - acc: 0.8165\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3781 - acc: 0.8317\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3661 - acc: 0.8375\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3670 - acc: 0.8384\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3650 - acc: 0.8479\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3766 - acc: 0.8337\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3707 - acc: 0.8470\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3612 - acc: 0.8479\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3735 - acc: 0.8337\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3669 - acc: 0.8508\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3705 - acc: 0.8365\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3659 - acc: 0.8384\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3619 - acc: 0.8441\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3620 - acc: 0.8375\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3584 - acc: 0.8631\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3627 - acc: 0.8298\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3618 - acc: 0.8470\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3761 - acc: 0.8356\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3676 - acc: 0.8327\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3558 - acc: 0.8403\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3539 - acc: 0.8536\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3809 - acc: 0.8270\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3695 - acc: 0.8403\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3677 - acc: 0.8441\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3653 - acc: 0.8384\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00949233 1.00815054 1.0106541  1.01111137 1.00925626 0.\n",
      "  1.01185626 1.01296524 1.00815054 1.00261153 1.00778458 1.00907442\n",
      "  1.00815054]]\n",
      "[[ 1.98846436  0.54510498 -1.54510498 -0.90979004  1.35699463  0.\n",
      "  -0.54510498 -0.34161377  0.54510498  0.13569946  0.45489502  1.09020996\n",
      "   0.54510498]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 113us/sample - loss: 0.9659 - acc: 0.5903\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.7874 - acc: 0.6416\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.7203 - acc: 0.6483\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7023 - acc: 0.6644\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6524 - acc: 0.6768\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6333 - acc: 0.6816\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6363 - acc: 0.6749\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6272 - acc: 0.6711\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.6152 - acc: 0.6806\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6195 - acc: 0.6892\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6091 - acc: 0.6863\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5790 - acc: 0.7148\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5721 - acc: 0.7205\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5763 - acc: 0.7167\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5665 - acc: 0.7158\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5669 - acc: 0.7129\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5635 - acc: 0.7139\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5639 - acc: 0.7120\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5484 - acc: 0.7177\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5500 - acc: 0.7129\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5522 - acc: 0.7196\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5528 - acc: 0.7281\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5396 - acc: 0.7196\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5387 - acc: 0.7338\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5373 - acc: 0.7300\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5404 - acc: 0.7110\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5775 - acc: 0.7025\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5381 - acc: 0.7272\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5196 - acc: 0.7357\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5182 - acc: 0.7405\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5125 - acc: 0.7367\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5130 - acc: 0.7519\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5041 - acc: 0.7424\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5130 - acc: 0.7405\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5008 - acc: 0.7395\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4872 - acc: 0.7519\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4870 - acc: 0.7481\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4923 - acc: 0.7548\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4928 - acc: 0.7529\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4698 - acc: 0.7690\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4683 - acc: 0.7804\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4805 - acc: 0.7576\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4678 - acc: 0.7728\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4615 - acc: 0.7823\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4540 - acc: 0.7852\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4559 - acc: 0.7823\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4461 - acc: 0.7899\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4332 - acc: 0.8023\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4433 - acc: 0.7956\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4414 - acc: 0.7918\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4264 - acc: 0.8099\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4248 - acc: 0.8032\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4246 - acc: 0.8127\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4147 - acc: 0.8156\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4168 - acc: 0.8184\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4165 - acc: 0.8156\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4154 - acc: 0.8061\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4132 - acc: 0.8137\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4128 - acc: 0.8175\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4024 - acc: 0.8127\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4059 - acc: 0.8260\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4122 - acc: 0.8042\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4020 - acc: 0.8241\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4079 - acc: 0.8241\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4055 - acc: 0.8194\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4006 - acc: 0.8260\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3988 - acc: 0.8222\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4062 - acc: 0.8260\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3904 - acc: 0.8365\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3860 - acc: 0.8432\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3884 - acc: 0.8432\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4018 - acc: 0.8289\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3885 - acc: 0.8403\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3886 - acc: 0.8289\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3849 - acc: 0.8375\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4424 - acc: 0.7966\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3889 - acc: 0.8337\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4004 - acc: 0.8241\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3834 - acc: 0.8394\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3817 - acc: 0.8327\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3886 - acc: 0.8356\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3891 - acc: 0.8346\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3834 - acc: 0.8422\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3815 - acc: 0.8413\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3789 - acc: 0.8451\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3870 - acc: 0.8356\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4022 - acc: 0.8241\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4156 - acc: 0.8118\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3997 - acc: 0.8260\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3887 - acc: 0.8279\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3835 - acc: 0.8394\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3868 - acc: 0.8346\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3876 - acc: 0.8251\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3765 - acc: 0.8403\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3836 - acc: 0.8422\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3751 - acc: 0.8460\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3727 - acc: 0.8479\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3751 - acc: 0.8536\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3881 - acc: 0.8422\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3901 - acc: 0.8365\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00982924 1.00885175 1.00942555 1.00585722 1.00969311 0.\n",
      "  1.01838878 1.01009549 0.         1.01104994 1.01417704 1.00973125\n",
      "  0.        ]]\n",
      "[[  5.91357422   0.87860107   1.75720215   0.24279785   3.2901001\n",
      "    0.          -0.12139893 -10.57818604   0.          -0.96296387\n",
      "   -0.24279785   3.75720215   0.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 119us/sample - loss: 5.1653 - acc: 0.4810\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.9118 - acc: 0.5105\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7271 - acc: 0.6055\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6998 - acc: 0.6226\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6806 - acc: 0.6321\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6717 - acc: 0.6426\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6620 - acc: 0.6587\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6586 - acc: 0.6464\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6516 - acc: 0.6578\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6447 - acc: 0.6711\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6413 - acc: 0.6521\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6326 - acc: 0.6711\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6250 - acc: 0.6721\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6261 - acc: 0.6702\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6155 - acc: 0.6778\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6053 - acc: 0.6892\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5997 - acc: 0.6977\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5991 - acc: 0.6901\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5949 - acc: 0.6768\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5800 - acc: 0.6930\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5748 - acc: 0.6911\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5738 - acc: 0.6911\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5624 - acc: 0.7053\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5617 - acc: 0.6977\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5667 - acc: 0.6977\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5519 - acc: 0.7186\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5522 - acc: 0.7120\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5589 - acc: 0.6958\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5408 - acc: 0.7196\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5482 - acc: 0.7158\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5372 - acc: 0.7196\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5293 - acc: 0.7205\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5197 - acc: 0.7319\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5141 - acc: 0.7291\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5165 - acc: 0.7395\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5055 - acc: 0.7481\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4963 - acc: 0.7529\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5026 - acc: 0.7395\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4901 - acc: 0.7538\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4806 - acc: 0.7538\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4759 - acc: 0.7671\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4731 - acc: 0.7633\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4752 - acc: 0.7728\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4658 - acc: 0.7700\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4648 - acc: 0.7614\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4757 - acc: 0.7681\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4591 - acc: 0.7652\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4565 - acc: 0.7671\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 17us/sample - loss: 0.4520 - acc: 0.7852\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4487 - acc: 0.7871\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4612 - acc: 0.7728\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4440 - acc: 0.7842\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4406 - acc: 0.7842\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4270 - acc: 0.7937\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4250 - acc: 0.8051\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4250 - acc: 0.7966\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4190 - acc: 0.8051\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4235 - acc: 0.8070\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4283 - acc: 0.7918\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4156 - acc: 0.8099\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4117 - acc: 0.8165\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4030 - acc: 0.8213\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4332 - acc: 0.7861\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4002 - acc: 0.8270\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4029 - acc: 0.8289\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3987 - acc: 0.8270\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4026 - acc: 0.8251\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3983 - acc: 0.8184\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4027 - acc: 0.8308\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3927 - acc: 0.8365\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3891 - acc: 0.8365\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3867 - acc: 0.8375\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3900 - acc: 0.8222\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3902 - acc: 0.8317\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3850 - acc: 0.8432\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3902 - acc: 0.8241\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3828 - acc: 0.8346\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3879 - acc: 0.8289\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3817 - acc: 0.8413\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3883 - acc: 0.8308\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3900 - acc: 0.8279\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3950 - acc: 0.8270\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3930 - acc: 0.8327\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4031 - acc: 0.8213\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3821 - acc: 0.8441\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3862 - acc: 0.8270\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3795 - acc: 0.8346\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3894 - acc: 0.8279\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3955 - acc: 0.8251\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3937 - acc: 0.8251\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3839 - acc: 0.8432\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3893 - acc: 0.8365\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3796 - acc: 0.8460\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3868 - acc: 0.8251\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3778 - acc: 0.8460\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3790 - acc: 0.8298\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3825 - acc: 0.8289\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3876 - acc: 0.8317\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3866 - acc: 0.8222\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3776 - acc: 0.8337\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00979426 1.00899101 1.02011101 1.00927632 1.01462022 0.\n",
      "  1.01101101 1.0093496  1.00008746 1.00688129 1.02011101 1.00501929\n",
      "  0.        ]]\n",
      "[[ 4.90802002  1.         -0.10089111  1.39465332 -0.21960449  0.\n",
      "  -1.          1.55187988  0.10089111  0.32285156 -0.10089111  0.20178223\n",
      "   0.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 121us/sample - loss: 2.2957 - acc: 0.4762\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.8290 - acc: 0.6084\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6827 - acc: 0.6312\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6421 - acc: 0.6511\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6294 - acc: 0.6502\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6260 - acc: 0.6721\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6235 - acc: 0.6397\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6152 - acc: 0.6920\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6127 - acc: 0.6759\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6180 - acc: 0.6635\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6140 - acc: 0.6797\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6019 - acc: 0.7072\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6030 - acc: 0.6759\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5961 - acc: 0.7044\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5961 - acc: 0.6901\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5944 - acc: 0.6901\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5938 - acc: 0.6949\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5854 - acc: 0.7082\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5822 - acc: 0.6996\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5848 - acc: 0.6987\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5781 - acc: 0.7101\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5783 - acc: 0.6977\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5711 - acc: 0.7120\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5706 - acc: 0.7205\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5692 - acc: 0.7063\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5678 - acc: 0.7139\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5638 - acc: 0.7329\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5625 - acc: 0.7234\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5536 - acc: 0.7234\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5682 - acc: 0.7082\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5544 - acc: 0.7367\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5532 - acc: 0.7376\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5519 - acc: 0.7357\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5476 - acc: 0.7300\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5454 - acc: 0.7319\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5423 - acc: 0.7405\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5391 - acc: 0.7338\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5361 - acc: 0.7243\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5342 - acc: 0.7367\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5363 - acc: 0.7281\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.5295 - acc: 0.7405\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5262 - acc: 0.7319\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5252 - acc: 0.7310\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5143 - acc: 0.7395\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5097 - acc: 0.7471\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5055 - acc: 0.7490\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5008 - acc: 0.7433\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4996 - acc: 0.7519\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4892 - acc: 0.7567\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4792 - acc: 0.7671\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4781 - acc: 0.7595\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4669 - acc: 0.7757\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4542 - acc: 0.7852\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4414 - acc: 0.8013\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4237 - acc: 0.8127\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4108 - acc: 0.8279\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3997 - acc: 0.8232\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3892 - acc: 0.8317\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3876 - acc: 0.8203\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3801 - acc: 0.8375\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3890 - acc: 0.8279\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3823 - acc: 0.8270\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3771 - acc: 0.8337\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3832 - acc: 0.8279\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3797 - acc: 0.8337\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3746 - acc: 0.8384\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3752 - acc: 0.8346\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3696 - acc: 0.8327\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3670 - acc: 0.8432\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3659 - acc: 0.8270\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3833 - acc: 0.8260\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3777 - acc: 0.8222\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3616 - acc: 0.8508\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3620 - acc: 0.8460\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3664 - acc: 0.8346\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3613 - acc: 0.8403\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3702 - acc: 0.8365\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3755 - acc: 0.8317\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3689 - acc: 0.8375\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3657 - acc: 0.8394\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3623 - acc: 0.8346\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3619 - acc: 0.8451\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3518 - acc: 0.8546\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3532 - acc: 0.8489\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3549 - acc: 0.8479\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3837 - acc: 0.8289\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3659 - acc: 0.8356\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3623 - acc: 0.8451\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3645 - acc: 0.8384\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3646 - acc: 0.8403\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3692 - acc: 0.8384\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3569 - acc: 0.8460\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3494 - acc: 0.8508\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3590 - acc: 0.8308\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3464 - acc: 0.8432\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3584 - acc: 0.8375\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3477 - acc: 0.8517\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3567 - acc: 0.8365\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3485 - acc: 0.8470\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3526 - acc: 0.8413\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00941899 1.00899101 1.00933087 1.00931559 1.12286517 0.\n",
      "  0.         1.01029947 1.01134092 1.00545474 1.00866263 0.\n",
      "  1.00590743]]\n",
      "[[ 1.73736572  1.          1.50842285  1.47473145 -0.00994873  0.\n",
      "   0.         -3.37365723 -0.75421143  0.22120972  0.75421143  0.\n",
      "   0.24578857]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 123us/sample - loss: 1.8601 - acc: 0.5770\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 1.1966 - acc: 0.5989\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.9775 - acc: 0.5913\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.8543 - acc: 0.6084\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.7890 - acc: 0.6065\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7371 - acc: 0.6207\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.7042 - acc: 0.6017\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6935 - acc: 0.6122\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6721 - acc: 0.6236\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6666 - acc: 0.6036\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6640 - acc: 0.6036\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6644 - acc: 0.5979\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6540 - acc: 0.6112\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6522 - acc: 0.6188\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6501 - acc: 0.6027\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6489 - acc: 0.6141\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6536 - acc: 0.5970\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6439 - acc: 0.6169\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6435 - acc: 0.6179\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6513 - acc: 0.6160\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6424 - acc: 0.6188\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6371 - acc: 0.6264\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6362 - acc: 0.6302\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6368 - acc: 0.6350\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6367 - acc: 0.6179\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6270 - acc: 0.6521\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6227 - acc: 0.6559\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6200 - acc: 0.6388\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6170 - acc: 0.6502\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6133 - acc: 0.6673\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6109 - acc: 0.6702\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.6018 - acc: 0.6892\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5965 - acc: 0.6996\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5950 - acc: 0.6930\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5837 - acc: 0.7120\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5743 - acc: 0.7186\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5638 - acc: 0.7338\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5654 - acc: 0.7101\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5490 - acc: 0.7329\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5402 - acc: 0.7348\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5310 - acc: 0.7357\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5237 - acc: 0.7529\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5193 - acc: 0.7395\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5092 - acc: 0.7500\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5099 - acc: 0.7357\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5029 - acc: 0.7405\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4976 - acc: 0.7319\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4909 - acc: 0.7624\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4876 - acc: 0.7586\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4728 - acc: 0.7662\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4731 - acc: 0.7719\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4654 - acc: 0.7652\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4531 - acc: 0.7833\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.4551 - acc: 0.7709\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4447 - acc: 0.7871\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4604 - acc: 0.7633\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4403 - acc: 0.7880\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4388 - acc: 0.7937\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4328 - acc: 0.7947\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4303 - acc: 0.7966\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4318 - acc: 0.7880\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4308 - acc: 0.8023\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4280 - acc: 0.7937\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4276 - acc: 0.7966\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4180 - acc: 0.8051\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4223 - acc: 0.8042\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4292 - acc: 0.7937\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4131 - acc: 0.8070\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4105 - acc: 0.8203\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4097 - acc: 0.8165\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4146 - acc: 0.8146\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4241 - acc: 0.8013\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4050 - acc: 0.8184\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4116 - acc: 0.8061\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4190 - acc: 0.8032\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4228 - acc: 0.8023\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4175 - acc: 0.8051\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4087 - acc: 0.8232\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4020 - acc: 0.8251\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3995 - acc: 0.8232\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4044 - acc: 0.8137\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3948 - acc: 0.8213\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3999 - acc: 0.8298\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3980 - acc: 0.8184\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4080 - acc: 0.7985\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 18us/sample - loss: 0.3976 - acc: 0.8222\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3897 - acc: 0.8241\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3914 - acc: 0.8146\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3997 - acc: 0.8184\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3962 - acc: 0.8165\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3873 - acc: 0.8203\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3962 - acc: 0.8222\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3890 - acc: 0.8270\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3861 - acc: 0.8251\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3858 - acc: 0.8213\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3832 - acc: 0.8327\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3890 - acc: 0.8308\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3946 - acc: 0.8118\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3812 - acc: 0.8213\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3853 - acc: 0.8298\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01103278 0.         1.0143346  1.00948988 1.01084867 1.00836571\n",
      "  0.         1.0105865  1.00836571 1.00883211 1.00949525 1.00918219\n",
      "  1.00836571]]\n",
      "[[-0.97894287  0.         -0.23400879  1.97894287 -1.19110107  0.61700439\n",
      "   0.         -1.7230835   0.61700439  0.86380615  2.          1.23400879\n",
      "   0.61700439]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 128us/sample - loss: 16.3334 - acc: 0.4810\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 1.7042 - acc: 0.4753\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.7703 - acc: 0.5485\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7038 - acc: 0.6084\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6774 - acc: 0.6198\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6449 - acc: 0.6540\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6289 - acc: 0.6587\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6236 - acc: 0.6711\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6024 - acc: 0.6806\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5969 - acc: 0.6768\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5788 - acc: 0.6968\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5708 - acc: 0.7025\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5420 - acc: 0.7291\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5436 - acc: 0.7243\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5323 - acc: 0.7348\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5634 - acc: 0.6977\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5224 - acc: 0.7281\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5065 - acc: 0.7452\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5155 - acc: 0.7519\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5090 - acc: 0.7471\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5138 - acc: 0.7471\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5077 - acc: 0.7490\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4826 - acc: 0.7576\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4852 - acc: 0.7490\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4905 - acc: 0.7452\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4738 - acc: 0.7595\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4824 - acc: 0.7624\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4749 - acc: 0.7614\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4849 - acc: 0.7643\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5094 - acc: 0.7443\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4638 - acc: 0.7766\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4989 - acc: 0.7443\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4557 - acc: 0.7709\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4676 - acc: 0.7690\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4596 - acc: 0.7757\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4537 - acc: 0.7842\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4520 - acc: 0.7795\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4381 - acc: 0.7861\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4288 - acc: 0.7833\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4275 - acc: 0.7966\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4345 - acc: 0.7842\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4279 - acc: 0.7947\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4473 - acc: 0.7823\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4572 - acc: 0.7766\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4373 - acc: 0.7871\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5007 - acc: 0.7538\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4334 - acc: 0.7890\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4315 - acc: 0.7861\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4194 - acc: 0.8013\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4353 - acc: 0.7814\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4212 - acc: 0.7975\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4203 - acc: 0.8013\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4017 - acc: 0.8127\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4146 - acc: 0.7994\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4427 - acc: 0.7804\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5370 - acc: 0.7386\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4411 - acc: 0.7928\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4183 - acc: 0.8118\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3994 - acc: 0.8089\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4119 - acc: 0.7994\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4088 - acc: 0.7985\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4288 - acc: 0.7975\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4435 - acc: 0.7804\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4171 - acc: 0.7918\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3918 - acc: 0.8241\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3906 - acc: 0.8203\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4077 - acc: 0.8146\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4043 - acc: 0.8137\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4000 - acc: 0.8118\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3900 - acc: 0.8260\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3999 - acc: 0.8127\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3834 - acc: 0.8308\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3900 - acc: 0.8165\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3933 - acc: 0.8165\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4100 - acc: 0.8080\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3859 - acc: 0.8298\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3951 - acc: 0.8156\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4028 - acc: 0.7975\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3889 - acc: 0.8156\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3800 - acc: 0.8298\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3902 - acc: 0.8194\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3849 - acc: 0.8194\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4058 - acc: 0.8165\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4055 - acc: 0.8251\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4493 - acc: 0.7852\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3924 - acc: 0.8270\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4082 - acc: 0.8127\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3892 - acc: 0.8146\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4133 - acc: 0.8080\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3974 - acc: 0.8156\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3904 - acc: 0.8317\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4240 - acc: 0.7975\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3880 - acc: 0.8317\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3792 - acc: 0.8346\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3818 - acc: 0.8317\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3954 - acc: 0.8137\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4171 - acc: 0.8061\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4106 - acc: 0.8127\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3810 - acc: 0.8365\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4261 - acc: 0.7880\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01020446 1.00795992 1.01204835 0.         1.00974454 1.00795992\n",
      "  1.01204835 1.01008518 1.00795992 1.00934101 1.01102314 1.01102314\n",
      "  1.00795992]]\n",
      "[[ -4.9407959    0.49407959  -0.49407959   0.           3.95263672\n",
      "    0.49407959  -0.49407959 -11.85791016   0.49407959   1.53164673\n",
      "   -0.98815918  -0.98815918   0.49407959]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 124us/sample - loss: 76.8237 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 30.0373 - acc: 0.5000\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 3.0683 - acc: 0.4734\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 1.3179 - acc: 0.4183\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.8622 - acc: 0.5143\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.7388 - acc: 0.6055\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6754 - acc: 0.6264\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6092 - acc: 0.6987\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5782 - acc: 0.7148\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5560 - acc: 0.7395\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5647 - acc: 0.7158\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5292 - acc: 0.7433\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5156 - acc: 0.7510\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5133 - acc: 0.7529\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5171 - acc: 0.7357\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4927 - acc: 0.7690\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4995 - acc: 0.7595\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4777 - acc: 0.7842\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4720 - acc: 0.7861\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4642 - acc: 0.7947\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4811 - acc: 0.7728\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4565 - acc: 0.7890\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4537 - acc: 0.7804\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4522 - acc: 0.7918\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4888 - acc: 0.7709\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4544 - acc: 0.7785\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4633 - acc: 0.7833\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4476 - acc: 0.7947\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4306 - acc: 0.7928\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.4735 - acc: 0.7614\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4439 - acc: 0.7985\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4196 - acc: 0.7956\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4446 - acc: 0.7795\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4254 - acc: 0.8032\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4144 - acc: 0.8089\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4362 - acc: 0.7795\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4346 - acc: 0.8004\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4285 - acc: 0.7994\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4080 - acc: 0.8108\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4316 - acc: 0.7966\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4568 - acc: 0.7842\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4092 - acc: 0.8127\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4542 - acc: 0.7852\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4263 - acc: 0.8032\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4068 - acc: 0.8232\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4004 - acc: 0.8251\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4287 - acc: 0.8023\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4013 - acc: 0.8137\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3943 - acc: 0.8146\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3968 - acc: 0.8194\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4017 - acc: 0.8213\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4091 - acc: 0.8080\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4066 - acc: 0.8222\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3889 - acc: 0.8241\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4073 - acc: 0.8194\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3996 - acc: 0.8270\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4037 - acc: 0.8194\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3953 - acc: 0.8260\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4042 - acc: 0.8108\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4589 - acc: 0.7823\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4132 - acc: 0.7956\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3993 - acc: 0.8156\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3824 - acc: 0.8270\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3957 - acc: 0.8213\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3862 - acc: 0.8327\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4166 - acc: 0.8184\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4507 - acc: 0.7814\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3983 - acc: 0.8279\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3815 - acc: 0.8317\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3791 - acc: 0.8346\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3852 - acc: 0.8289\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3887 - acc: 0.8317\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3889 - acc: 0.8232\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3941 - acc: 0.8232\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4125 - acc: 0.8080\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3976 - acc: 0.8260\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3809 - acc: 0.8384\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3811 - acc: 0.8375\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3777 - acc: 0.8375\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3823 - acc: 0.8156\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3988 - acc: 0.8260\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3830 - acc: 0.8289\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3889 - acc: 0.8356\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3754 - acc: 0.8403\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3851 - acc: 0.8260\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3918 - acc: 0.8146\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3772 - acc: 0.8337\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3688 - acc: 0.8394\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.3789 - acc: 0.8356\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3771 - acc: 0.8479\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3848 - acc: 0.8298\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3852 - acc: 0.8327\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3734 - acc: 0.8413\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3923 - acc: 0.8184\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3712 - acc: 0.8375\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4009 - acc: 0.8137\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3739 - acc: 0.8384\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3742 - acc: 0.8384\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3774 - acc: 0.8375\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3788 - acc: 0.8222\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00978011 1.01530615 1.01264612 1.00976013 1.01048008 0.\n",
      "  1.01530615 1.01018855 0.         1.00914936 1.01264612 1.01530615\n",
      "  1.00474902]]\n",
      "[[ 4.59228516 -0.19134521 -0.38269043  4.20959473 -2.10479736  0.\n",
      "  -0.19134521 -5.35766602  0.          1.18634033 -0.38269043 -0.19134521\n",
      "   0.19134521]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 141us/sample - loss: 37.7944 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 4.1661 - acc: 0.5760\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 1.5040 - acc: 0.6502\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.3187 - acc: 0.6587\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 1.2090 - acc: 0.6625\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.1140 - acc: 0.6663\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 1.0354 - acc: 0.6702\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.9840 - acc: 0.6578\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.9336 - acc: 0.6625\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.9023 - acc: 0.6559\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.8600 - acc: 0.6540\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.8117 - acc: 0.6578\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.7919 - acc: 0.6673\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.7621 - acc: 0.6587\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7353 - acc: 0.6625\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7079 - acc: 0.6721\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.7285 - acc: 0.6625\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6901 - acc: 0.6683\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6532 - acc: 0.6806\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6442 - acc: 0.6778\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6444 - acc: 0.6806\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6100 - acc: 0.6873\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6046 - acc: 0.7110\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5892 - acc: 0.6987\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5770 - acc: 0.7044\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5671 - acc: 0.7101\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5458 - acc: 0.7234\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5197 - acc: 0.7443\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4949 - acc: 0.7586\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4887 - acc: 0.7586\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4770 - acc: 0.7700\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4811 - acc: 0.7643\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4620 - acc: 0.7804\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4592 - acc: 0.7833\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4543 - acc: 0.7814\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4559 - acc: 0.7833\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4410 - acc: 0.7937\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4369 - acc: 0.8013\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4509 - acc: 0.7776\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4439 - acc: 0.7861\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4245 - acc: 0.8108\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4198 - acc: 0.8061\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4135 - acc: 0.8194\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4157 - acc: 0.8203\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4115 - acc: 0.8127\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.4104 - acc: 0.7956\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4042 - acc: 0.8156\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4335 - acc: 0.7947\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4267 - acc: 0.8004\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4117 - acc: 0.8213\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3993 - acc: 0.8194\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4021 - acc: 0.8146\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4017 - acc: 0.8289\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3868 - acc: 0.8365\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3897 - acc: 0.8308\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4070 - acc: 0.8194\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4006 - acc: 0.8146\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3901 - acc: 0.8203\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3966 - acc: 0.8137\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3929 - acc: 0.8346\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3917 - acc: 0.8232\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3874 - acc: 0.8203\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3841 - acc: 0.8232\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4042 - acc: 0.8222\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4065 - acc: 0.8184\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3814 - acc: 0.8346\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3781 - acc: 0.8308\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3827 - acc: 0.8289\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3824 - acc: 0.8146\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4036 - acc: 0.8165\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3739 - acc: 0.8298\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3764 - acc: 0.8356\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4170 - acc: 0.8070\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3857 - acc: 0.8184\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3736 - acc: 0.8394\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3675 - acc: 0.8327\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3834 - acc: 0.8298\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3880 - acc: 0.8270\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3794 - acc: 0.8260\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3724 - acc: 0.8346\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3613 - acc: 0.8337\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3775 - acc: 0.8365\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3782 - acc: 0.8194\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3692 - acc: 0.8337\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3706 - acc: 0.8317\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3671 - acc: 0.8375\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3708 - acc: 0.8317\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3690 - acc: 0.8346\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3647 - acc: 0.8346\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3823 - acc: 0.8346\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3654 - acc: 0.8365\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3725 - acc: 0.8298\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3790 - acc: 0.8308\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.3997 - acc: 0.8146\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4211 - acc: 0.8165\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3744 - acc: 0.8156\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3678 - acc: 0.8422\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3645 - acc: 0.8356\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3581 - acc: 0.8403\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3639 - acc: 0.8279\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00703411 1.01305051 1.01151445 1.0106226  1.00930452 0.\n",
      "  0.         1.00939481 1.00849008 1.00784947 0.         0.\n",
      "  1.00849008]]\n",
      "[[ 0.33953857 -0.33209229 -0.66790771 -1.62322998  1.45123291  0.\n",
      "   0.          1.66790771  0.66790771  0.46865234  0.          0.\n",
      "   0.66790771]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 130us/sample - loss: 1.2715 - acc: 0.6207\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.7146 - acc: 0.6797\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6326 - acc: 0.6844\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6098 - acc: 0.6844\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6016 - acc: 0.6930\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5999 - acc: 0.6654\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6009 - acc: 0.6806\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5982 - acc: 0.6806\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5883 - acc: 0.6949\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5878 - acc: 0.7025\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5840 - acc: 0.6901\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5927 - acc: 0.6920\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5903 - acc: 0.6835\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5891 - acc: 0.6863\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5810 - acc: 0.7053\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5788 - acc: 0.6987\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5762 - acc: 0.7034\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5826 - acc: 0.6949\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5741 - acc: 0.7101\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5771 - acc: 0.6939\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5725 - acc: 0.7120\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5683 - acc: 0.7091\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5682 - acc: 0.7044\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5686 - acc: 0.6987\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5702 - acc: 0.7072\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5687 - acc: 0.6996\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5653 - acc: 0.7044\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5656 - acc: 0.7053\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5636 - acc: 0.7129\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5648 - acc: 0.7139\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5680 - acc: 0.7082\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5665 - acc: 0.7129\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5685 - acc: 0.7082\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5582 - acc: 0.7262\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5708 - acc: 0.7063\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5568 - acc: 0.7281\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5556 - acc: 0.7158\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5593 - acc: 0.7300\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5580 - acc: 0.7129\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5545 - acc: 0.7186\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5515 - acc: 0.7196\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 19us/sample - loss: 0.5500 - acc: 0.7291\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5503 - acc: 0.7253\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5464 - acc: 0.7234\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5449 - acc: 0.7291\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5448 - acc: 0.7395\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5547 - acc: 0.7177\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5447 - acc: 0.7234\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5424 - acc: 0.7310\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5413 - acc: 0.7319\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5476 - acc: 0.7300\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5545 - acc: 0.7234\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5382 - acc: 0.7367\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5385 - acc: 0.7386\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5326 - acc: 0.7310\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.5326 - acc: 0.7319\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5303 - acc: 0.7414\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5270 - acc: 0.7376\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5283 - acc: 0.7272\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5336 - acc: 0.7348\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5228 - acc: 0.7395\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5303 - acc: 0.7338\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5208 - acc: 0.7471\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5243 - acc: 0.7348\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5221 - acc: 0.7367\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5273 - acc: 0.7281\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5208 - acc: 0.7414\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5255 - acc: 0.7310\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5164 - acc: 0.7452\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5173 - acc: 0.7433\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5106 - acc: 0.7395\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5109 - acc: 0.7386\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5103 - acc: 0.7529\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5131 - acc: 0.7357\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5026 - acc: 0.7548\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5144 - acc: 0.7538\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5034 - acc: 0.7567\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4975 - acc: 0.7481\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4990 - acc: 0.7538\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4944 - acc: 0.7510\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4930 - acc: 0.7576\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4919 - acc: 0.7557\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4917 - acc: 0.7586\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4920 - acc: 0.7529\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4875 - acc: 0.7614\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4978 - acc: 0.7557\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4849 - acc: 0.7529\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4788 - acc: 0.7567\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4831 - acc: 0.7548\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4782 - acc: 0.7576\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4731 - acc: 0.7662\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4745 - acc: 0.7671\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4778 - acc: 0.7709\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4656 - acc: 0.7614\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4753 - acc: 0.7671\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4699 - acc: 0.7738\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4656 - acc: 0.7709\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4588 - acc: 0.7709\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4607 - acc: 0.7766\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4572 - acc: 0.7842\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00987802 0.         1.01101101 1.0107101  0.99754288 0.\n",
      "  1.01705479 1.01015113 0.         1.00946386 1.01118151 1.00921386\n",
      "  1.01070782]]\n",
      "[[ 8.2791748   0.         -1.         -1.42333984  0.08007812  0.\n",
      "  -0.14416504 -6.6842041   0.          1.88283691 -0.85583496  1.28375244\n",
      "  -1.42791748]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 140us/sample - loss: 23.1293 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 7.5292 - acc: 0.5019\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.8871 - acc: 0.5019\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6705 - acc: 0.6027\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6613 - acc: 0.6046\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6582 - acc: 0.6226\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6524 - acc: 0.6217\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6547 - acc: 0.6017\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6490 - acc: 0.6150\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6488 - acc: 0.6122\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6447 - acc: 0.6112\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6322 - acc: 0.6359\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6300 - acc: 0.6255\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6566 - acc: 0.6179\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6176 - acc: 0.6483\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6159 - acc: 0.6578\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6113 - acc: 0.6597\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6003 - acc: 0.6730\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6025 - acc: 0.6549\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5942 - acc: 0.6683\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5877 - acc: 0.6702\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5907 - acc: 0.6873\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5880 - acc: 0.6778\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5729 - acc: 0.6968\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5728 - acc: 0.6996\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5668 - acc: 0.6930\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5637 - acc: 0.7053\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5660 - acc: 0.6911\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5516 - acc: 0.7253\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5490 - acc: 0.7243\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5440 - acc: 0.7367\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5441 - acc: 0.7291\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5346 - acc: 0.7272\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5402 - acc: 0.7167\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5300 - acc: 0.7196\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5252 - acc: 0.7319\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5169 - acc: 0.7310\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5329 - acc: 0.7300\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5149 - acc: 0.7319\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5040 - acc: 0.7424\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5097 - acc: 0.7471\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5104 - acc: 0.7481\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4989 - acc: 0.7357\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4957 - acc: 0.7510\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4838 - acc: 0.7452\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4822 - acc: 0.7510\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4807 - acc: 0.7529\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4772 - acc: 0.7519\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4799 - acc: 0.7690\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4700 - acc: 0.7643\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4682 - acc: 0.7595\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4609 - acc: 0.7576\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4731 - acc: 0.7567\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4722 - acc: 0.7681\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4539 - acc: 0.7652\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4509 - acc: 0.7643\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4440 - acc: 0.7785\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4372 - acc: 0.7747\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4373 - acc: 0.7880\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4344 - acc: 0.7871\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4336 - acc: 0.7766\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4348 - acc: 0.7937\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4292 - acc: 0.7861\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4393 - acc: 0.7842\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4201 - acc: 0.7937\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4264 - acc: 0.7861\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4202 - acc: 0.7994\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4096 - acc: 0.8080\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4107 - acc: 0.7947\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4087 - acc: 0.8089\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4335 - acc: 0.7871\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4097 - acc: 0.8032\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4184 - acc: 0.8070\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4062 - acc: 0.8080\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3977 - acc: 0.8118\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4111 - acc: 0.8146\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3988 - acc: 0.8260\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3942 - acc: 0.8222\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4141 - acc: 0.8080\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4065 - acc: 0.8080\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3896 - acc: 0.8222\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3940 - acc: 0.8232\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3965 - acc: 0.8175\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3871 - acc: 0.8298\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4017 - acc: 0.8146\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3914 - acc: 0.8298\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3924 - acc: 0.8184\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4062 - acc: 0.8032\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3990 - acc: 0.8137\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3895 - acc: 0.8317\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3860 - acc: 0.8222\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3826 - acc: 0.8422\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3966 - acc: 0.8137\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3817 - acc: 0.8317\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3932 - acc: 0.8127\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3810 - acc: 0.8308\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3907 - acc: 0.8270\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3862 - acc: 0.8232\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3777 - acc: 0.8394\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3839 - acc: 0.8356\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00889226 0.         1.01333786 1.008671   0.         0.\n",
      "  0.         1.01111017 1.00338981 1.0072352  0.         1.00338981\n",
      "  0.        ]]\n",
      "[[ 0.9107666   0.         -0.30358887  0.75897217  0.          0.\n",
      "   0.         -0.9107666   0.15179443  0.36430664  0.          0.15179443\n",
      "   0.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 139us/sample - loss: 1.6808 - acc: 0.4895\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.7210 - acc: 0.4810\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6939 - acc: 0.5029\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6922 - acc: 0.5029\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6919 - acc: 0.5029\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6910 - acc: 0.5029\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6899 - acc: 0.5029\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6894 - acc: 0.5029\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6890 - acc: 0.4962\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6883 - acc: 0.5200\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6881 - acc: 0.5247\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6872 - acc: 0.5171\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6869 - acc: 0.5494\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6866 - acc: 0.5504\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6860 - acc: 0.5694\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6858 - acc: 0.5760\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6850 - acc: 0.5722\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6852 - acc: 0.5741\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6854 - acc: 0.5713\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6851 - acc: 0.5665\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6840 - acc: 0.5722\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6836 - acc: 0.5817\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6833 - acc: 0.5732\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6830 - acc: 0.5770\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6827 - acc: 0.5722\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6824 - acc: 0.5665\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6839 - acc: 0.5675\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6826 - acc: 0.5675\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6817 - acc: 0.5741\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6814 - acc: 0.5732\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6812 - acc: 0.5722\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6810 - acc: 0.5751\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6805 - acc: 0.5751\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6812 - acc: 0.5770\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6800 - acc: 0.5713\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6796 - acc: 0.5875\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6803 - acc: 0.5779\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6788 - acc: 0.5779\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6789 - acc: 0.5865\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6780 - acc: 0.5798\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6780 - acc: 0.5837\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6774 - acc: 0.5798\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6782 - acc: 0.5903\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6773 - acc: 0.5856\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6764 - acc: 0.5884\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6769 - acc: 0.5875\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6752 - acc: 0.5817\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6755 - acc: 0.6017\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6749 - acc: 0.5894\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6756 - acc: 0.5894\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6731 - acc: 0.5922\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6725 - acc: 0.5960\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6716 - acc: 0.6074\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6713 - acc: 0.6065\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6708 - acc: 0.6036\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6701 - acc: 0.6065\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6702 - acc: 0.6084\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6686 - acc: 0.6169\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6684 - acc: 0.6036\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6677 - acc: 0.6122\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6661 - acc: 0.6217\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6647 - acc: 0.6160\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6629 - acc: 0.6226\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6637 - acc: 0.6169\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6621 - acc: 0.6217\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6614 - acc: 0.6198\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6610 - acc: 0.6255\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6597 - acc: 0.6245\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6576 - acc: 0.6283\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6567 - acc: 0.6321\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6547 - acc: 0.6369\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6534 - acc: 0.6331\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6555 - acc: 0.6293\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6534 - acc: 0.6293\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6507 - acc: 0.6397\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6505 - acc: 0.6340\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6472 - acc: 0.6473\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6466 - acc: 0.6407\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6456 - acc: 0.6511\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6438 - acc: 0.6502\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6409 - acc: 0.6549\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6402 - acc: 0.6473\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6367 - acc: 0.6597\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.6363 - acc: 0.6673\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6316 - acc: 0.6663\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6289 - acc: 0.6673\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6270 - acc: 0.6683\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6247 - acc: 0.6663\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6210 - acc: 0.6663\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6168 - acc: 0.6768\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6129 - acc: 0.6721\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6072 - acc: 0.6730\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6040 - acc: 0.6806\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5997 - acc: 0.6825\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5964 - acc: 0.6797\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5914 - acc: 0.6901\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5878 - acc: 0.6987\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5818 - acc: 0.7063\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5771 - acc: 0.7015\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5716 - acc: 0.7072\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01014289 1.01197831 1.00901374 1.01090635 1.01048834 0.\n",
      "  1.00899101 1.00967307 1.00793652 1.00781092 1.01207195 1.00931124\n",
      "  1.01207195]]\n",
      "[[-7.06921387 -0.51153564  1.02307129 -1.11535645 -2.06921387  0.\n",
      "   1.          3.08831787  0.48846436  0.46038208 -0.48846436  1.46539307\n",
      "  -0.48846436]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 143us/sample - loss: 30.1598 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 6.5521 - acc: 0.4724\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.2056 - acc: 0.5114\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.9662 - acc: 0.5589\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.8923 - acc: 0.5865\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.8494 - acc: 0.6008\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.8145 - acc: 0.6093\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.7794 - acc: 0.6179\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.7428 - acc: 0.6264\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.7073 - acc: 0.6530\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.7035 - acc: 0.6464\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6786 - acc: 0.6473\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6487 - acc: 0.6778\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6280 - acc: 0.6873\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6159 - acc: 0.6863\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6191 - acc: 0.6996\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6033 - acc: 0.6911\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5826 - acc: 0.7120\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5811 - acc: 0.7158\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.5761 - acc: 0.7148\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5683 - acc: 0.7167\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5633 - acc: 0.7053\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5544 - acc: 0.7272\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5506 - acc: 0.7186\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.5463 - acc: 0.7414\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5314 - acc: 0.7291\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5299 - acc: 0.7243\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5223 - acc: 0.7262\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5288 - acc: 0.7319\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5203 - acc: 0.7272\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5063 - acc: 0.7338\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5085 - acc: 0.7405\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5126 - acc: 0.7414\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4967 - acc: 0.7433\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5065 - acc: 0.7319\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4957 - acc: 0.7481\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5009 - acc: 0.7529\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4904 - acc: 0.7605\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5092 - acc: 0.7462\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5102 - acc: 0.7367\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4749 - acc: 0.7595\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4736 - acc: 0.7605\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4678 - acc: 0.7557\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4642 - acc: 0.7700\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4647 - acc: 0.7719\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4576 - acc: 0.7500\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4496 - acc: 0.7652\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4904 - acc: 0.7557\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4563 - acc: 0.7652\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4514 - acc: 0.7652\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4409 - acc: 0.7814\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4428 - acc: 0.7880\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4414 - acc: 0.7785\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4332 - acc: 0.7852\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4211 - acc: 0.8032\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4233 - acc: 0.7909\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4211 - acc: 0.8032\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4449 - acc: 0.7899\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4201 - acc: 0.8089\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4205 - acc: 0.8061\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4209 - acc: 0.7899\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4146 - acc: 0.8032\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4050 - acc: 0.8184\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4084 - acc: 0.8184\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4156 - acc: 0.8032\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4234 - acc: 0.7985\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4040 - acc: 0.8137\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4250 - acc: 0.7842\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4310 - acc: 0.7899\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4296 - acc: 0.7956\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3969 - acc: 0.8270\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3873 - acc: 0.8308\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3982 - acc: 0.8222\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4045 - acc: 0.8070\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3881 - acc: 0.8251\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3842 - acc: 0.8298\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4519 - acc: 0.7814\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3884 - acc: 0.8327\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3832 - acc: 0.8356\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3917 - acc: 0.8184\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3861 - acc: 0.8308\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3909 - acc: 0.8289\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3934 - acc: 0.8289\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3808 - acc: 0.8317\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3779 - acc: 0.8394\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4259 - acc: 0.7937\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3798 - acc: 0.8337\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3772 - acc: 0.8403\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3873 - acc: 0.8251\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3801 - acc: 0.8298\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3923 - acc: 0.8241\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3723 - acc: 0.8394\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3876 - acc: 0.8279\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3833 - acc: 0.8365\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3719 - acc: 0.8413\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3708 - acc: 0.8479\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3712 - acc: 0.8422\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3901 - acc: 0.8251\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3812 - acc: 0.8365\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3673 - acc: 0.8508\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00961874 1.00529809 1.01050525 1.0092133  1.02064433 0.\n",
      "  1.01128631 1.00337658 1.00529809 1.00798133 1.01101101 0.\n",
      "  1.0147461 ]]\n",
      "[[ 2.64813232  0.21380615 -2.          1.28283691 -0.09588623  0.\n",
      "  -0.78619385  0.15148926  0.21380615  0.49932861 -1.          0.\n",
      "  -0.21380615]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 146us/sample - loss: 31.7114 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 9.5431 - acc: 0.4895\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 1.9918 - acc: 0.4819\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 1.5360 - acc: 0.5228\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 1.3307 - acc: 0.5399\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.1610 - acc: 0.5608\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 1.0369 - acc: 0.5856\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.9641 - acc: 0.6198\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.8461 - acc: 0.6264\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.7827 - acc: 0.6388\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.7286 - acc: 0.6635\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.7135 - acc: 0.6730\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6730 - acc: 0.6882\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6350 - acc: 0.6958\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6212 - acc: 0.7101\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6084 - acc: 0.7158\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6186 - acc: 0.7053\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5527 - acc: 0.7215\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5517 - acc: 0.7234\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5240 - acc: 0.7348\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5149 - acc: 0.7490\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5056 - acc: 0.7576\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5063 - acc: 0.7548\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4951 - acc: 0.7614\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4811 - acc: 0.7690\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4756 - acc: 0.7557\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.4739 - acc: 0.7652\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4522 - acc: 0.7909\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4543 - acc: 0.7700\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4542 - acc: 0.7899\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4370 - acc: 0.7871\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4402 - acc: 0.7871\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4462 - acc: 0.7861\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4587 - acc: 0.7804\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4552 - acc: 0.7833\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4243 - acc: 0.8051\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4222 - acc: 0.7880\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4239 - acc: 0.8080\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4127 - acc: 0.8118\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4155 - acc: 0.8070\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4075 - acc: 0.8222\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4290 - acc: 0.7937\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.4083 - acc: 0.8080\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4037 - acc: 0.8118\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4129 - acc: 0.8118\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4001 - acc: 0.8203\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4236 - acc: 0.7985\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4058 - acc: 0.8213\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4120 - acc: 0.8013\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4015 - acc: 0.8137\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3920 - acc: 0.8289\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3968 - acc: 0.8146\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4069 - acc: 0.8051\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4446 - acc: 0.7842\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3936 - acc: 0.8251\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4008 - acc: 0.8289\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3888 - acc: 0.8270\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3842 - acc: 0.8308\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3865 - acc: 0.8337\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3809 - acc: 0.8337\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3894 - acc: 0.8289\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3932 - acc: 0.8260\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3896 - acc: 0.8241\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3785 - acc: 0.8356\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3968 - acc: 0.8289\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3779 - acc: 0.8356\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3769 - acc: 0.8337\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3859 - acc: 0.8260\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3819 - acc: 0.8289\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3757 - acc: 0.8479\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4073 - acc: 0.8099\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4013 - acc: 0.8194\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3829 - acc: 0.8317\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3757 - acc: 0.8289\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3964 - acc: 0.8289\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4072 - acc: 0.8127\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3797 - acc: 0.8384\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3806 - acc: 0.8260\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3798 - acc: 0.8279\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3882 - acc: 0.8251\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3798 - acc: 0.8241\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3695 - acc: 0.8441\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3897 - acc: 0.8298\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3769 - acc: 0.8489\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.3868 - acc: 0.8241\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3784 - acc: 0.8289\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3973 - acc: 0.8289\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3697 - acc: 0.8346\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3739 - acc: 0.8356\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3761 - acc: 0.8308\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4028 - acc: 0.8156\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3687 - acc: 0.8441\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3651 - acc: 0.8346\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3768 - acc: 0.8356\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3674 - acc: 0.8460\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3990 - acc: 0.8327\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3785 - acc: 0.8298\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3720 - acc: 0.8394\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4168 - acc: 0.8061\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4101 - acc: 0.8127\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00954404 1.00668339 1.01077542 1.00847477 1.01152985 0.\n",
      "  0.         1.00962096 1.00668339 1.00752485 1.01101101 1.00833897\n",
      "  1.00668339]]\n",
      "[[ 2.21411133  0.30352783 -1.30352783  0.66119385 -0.66119385  0.\n",
      "   0.          2.66363525  0.30352783  0.40705566 -1.          0.60705566\n",
      "   0.30352783]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 160us/sample - loss: 55.8309 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 12.6421 - acc: 0.5171\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 4.5472 - acc: 0.5922\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 3.2983 - acc: 0.5856\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 2.4009 - acc: 0.5380\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 1.6712 - acc: 0.5437\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 1.2311 - acc: 0.5209\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.9472 - acc: 0.5390\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.7692 - acc: 0.5998\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6901 - acc: 0.6388\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6288 - acc: 0.6692\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5890 - acc: 0.6987\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5677 - acc: 0.7025\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5620 - acc: 0.7224\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5410 - acc: 0.7262\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6646 - acc: 0.6692\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5584 - acc: 0.7243\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5127 - acc: 0.7500\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5510 - acc: 0.7319\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5302 - acc: 0.7424\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5214 - acc: 0.7481\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4898 - acc: 0.7576\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4898 - acc: 0.7605\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4744 - acc: 0.7662\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4756 - acc: 0.7671\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4494 - acc: 0.7776\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4490 - acc: 0.7738\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 34us/sample - loss: 0.4470 - acc: 0.7728\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4505 - acc: 0.7804\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4395 - acc: 0.7880\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4449 - acc: 0.7861\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4176 - acc: 0.8061\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4629 - acc: 0.7804\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4145 - acc: 0.8023\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4218 - acc: 0.7975\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4181 - acc: 0.7975\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4010 - acc: 0.8137\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4031 - acc: 0.8175\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4312 - acc: 0.7937\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4036 - acc: 0.8241\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4043 - acc: 0.8175\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4102 - acc: 0.8108\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3923 - acc: 0.8241\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3990 - acc: 0.8194\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3936 - acc: 0.8279\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4050 - acc: 0.8194\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3946 - acc: 0.8194\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3889 - acc: 0.8394\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4094 - acc: 0.8070\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4037 - acc: 0.8080\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4263 - acc: 0.8070\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4258 - acc: 0.7985\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3862 - acc: 0.8298\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 35us/sample - loss: 0.3786 - acc: 0.8337\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4091 - acc: 0.8184\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3978 - acc: 0.8165\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4040 - acc: 0.8137\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3877 - acc: 0.8270\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3819 - acc: 0.8298\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3961 - acc: 0.8146\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3981 - acc: 0.8194\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3887 - acc: 0.8298\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3835 - acc: 0.8279\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4167 - acc: 0.8042\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3984 - acc: 0.8165\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4612 - acc: 0.7814\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4129 - acc: 0.8222\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3869 - acc: 0.8165\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3677 - acc: 0.8441\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3782 - acc: 0.8279\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3808 - acc: 0.8337\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3987 - acc: 0.8137\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3773 - acc: 0.8460\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3965 - acc: 0.8232\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3777 - acc: 0.8422\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4115 - acc: 0.8213\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.3974 - acc: 0.8232\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3805 - acc: 0.8260\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3797 - acc: 0.8346\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3845 - acc: 0.8327\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3753 - acc: 0.8327\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3808 - acc: 0.8375\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3798 - acc: 0.8384\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3745 - acc: 0.8346\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3778 - acc: 0.8356\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3754 - acc: 0.8317\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3636 - acc: 0.8441\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4160 - acc: 0.8127\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4128 - acc: 0.8089\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3911 - acc: 0.8156\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3998 - acc: 0.8127\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3965 - acc: 0.8213\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4249 - acc: 0.8042\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4082 - acc: 0.8184\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.3983 - acc: 0.8298\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4618 - acc: 0.7956\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3727 - acc: 0.8384\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3612 - acc: 0.8517\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3684 - acc: 0.8346\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3724 - acc: 0.8327\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01033127 1.0088183  1.01054515 1.01103426 1.0103114  0.\n",
      "  1.0031433  1.01037654 0.         1.01186871 0.         1.00911967\n",
      "  0.        ]]\n",
      "[[-3.04986572  0.85369873 -1.85369873 -0.97753906 -3.24438477  0.\n",
      "   0.14630127 -2.68328857  0.         -0.54147949  0.          1.14630127\n",
      "   0.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 149us/sample - loss: 6.0634 - acc: 0.4933\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 1.5476 - acc: 0.4819\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 1.2068 - acc: 0.5399\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 1.0549 - acc: 0.5627\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.9200 - acc: 0.5789\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.8315 - acc: 0.6122\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.7279 - acc: 0.6416\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6733 - acc: 0.6730\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6290 - acc: 0.6958\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6036 - acc: 0.6996\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5672 - acc: 0.7205\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5495 - acc: 0.7291\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5251 - acc: 0.7433\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4973 - acc: 0.7433\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4886 - acc: 0.7652\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4901 - acc: 0.7567\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4581 - acc: 0.7766\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4769 - acc: 0.7624\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4608 - acc: 0.7757\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4392 - acc: 0.7909\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4290 - acc: 0.7899\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4384 - acc: 0.7909\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4232 - acc: 0.8004\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4216 - acc: 0.8099\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4183 - acc: 0.8146\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4224 - acc: 0.7966\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4393 - acc: 0.7880\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4237 - acc: 0.7994\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4171 - acc: 0.8080\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4188 - acc: 0.8061\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4201 - acc: 0.8051\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4004 - acc: 0.8175\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4194 - acc: 0.8127\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4041 - acc: 0.8089\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4114 - acc: 0.8146\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4279 - acc: 0.8042\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4128 - acc: 0.8032\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3966 - acc: 0.8175\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3986 - acc: 0.8337\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3945 - acc: 0.8241\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4546 - acc: 0.7785\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4105 - acc: 0.8137\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3989 - acc: 0.8203\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4008 - acc: 0.8327\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3935 - acc: 0.8298\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4024 - acc: 0.8051\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3999 - acc: 0.8279\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3817 - acc: 0.8422\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4015 - acc: 0.8118\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4046 - acc: 0.8279\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3897 - acc: 0.8270\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3820 - acc: 0.8279\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3844 - acc: 0.8298\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3853 - acc: 0.8241\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3995 - acc: 0.8184\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3852 - acc: 0.8346\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3751 - acc: 0.8451\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3995 - acc: 0.8137\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3970 - acc: 0.8194\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3962 - acc: 0.8308\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3894 - acc: 0.8337\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3834 - acc: 0.8317\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3924 - acc: 0.8384\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3839 - acc: 0.8384\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3759 - acc: 0.8460\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 37us/sample - loss: 0.3827 - acc: 0.8317\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.3850 - acc: 0.8298\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4074 - acc: 0.8213\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4140 - acc: 0.8165\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3841 - acc: 0.8213\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3833 - acc: 0.8270\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3820 - acc: 0.8327\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3735 - acc: 0.8375\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3809 - acc: 0.8298\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4093 - acc: 0.8089\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4012 - acc: 0.8146\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3910 - acc: 0.8184\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3752 - acc: 0.8375\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3788 - acc: 0.8317\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4196 - acc: 0.8241\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5422 - acc: 0.7614\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4043 - acc: 0.8080\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4203 - acc: 0.8080\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4151 - acc: 0.8070\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3756 - acc: 0.8413\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3716 - acc: 0.8403\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3939 - acc: 0.8251\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3865 - acc: 0.8222\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3728 - acc: 0.8346\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3833 - acc: 0.8327\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3895 - acc: 0.8251\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3804 - acc: 0.8308\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4030 - acc: 0.8222\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4047 - acc: 0.8127\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3858 - acc: 0.8298\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3786 - acc: 0.8346\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3811 - acc: 0.8422\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3910 - acc: 0.8194\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3864 - acc: 0.8289\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4250 - acc: 0.8032\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01115649 1.0181013  1.00838137 1.00963196 1.01717408 0.\n",
      "  0.         1.00920037 0.         1.00787034 1.00202661 1.01080778\n",
      "  1.01101101]]\n",
      "[[-0.87432861 -0.12567139  0.62298584  2.74328613 -0.14178467  0.\n",
      "   0.          1.26208496  0.          0.47325439  0.12567139 -1.25134277\n",
      "  -1.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 177us/sample - loss: 25.1561 - acc: 0.4914\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 4.6927 - acc: 0.4249\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 2.6109 - acc: 0.4905\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 35us/sample - loss: 1.8887 - acc: 0.4981\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 1.1760 - acc: 0.5038\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.9307 - acc: 0.4772\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.8765 - acc: 0.4876\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.8498 - acc: 0.5143\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.8323 - acc: 0.4705\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.8189 - acc: 0.4971\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.8063 - acc: 0.4848\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.7991 - acc: 0.4667\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 34us/sample - loss: 0.7939 - acc: 0.4810\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.7843 - acc: 0.5295\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.7793 - acc: 0.4952\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.7724 - acc: 0.4810\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.7618 - acc: 0.4810\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.7528 - acc: 0.5057\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.7441 - acc: 0.5124\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.7374 - acc: 0.4715\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.7270 - acc: 0.4905\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.7184 - acc: 0.4848\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.7119 - acc: 0.5067\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.7004 - acc: 0.4895\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.6940 - acc: 0.5048\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6936 - acc: 0.5048\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6927 - acc: 0.5247\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6941 - acc: 0.5010\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6947 - acc: 0.5228\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.7015 - acc: 0.4924\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6948 - acc: 0.4924\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6926 - acc: 0.5181\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.6934 - acc: 0.5181\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6920 - acc: 0.5276\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6921 - acc: 0.5276\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6946 - acc: 0.5124\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6921 - acc: 0.5475\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6944 - acc: 0.5152\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6949 - acc: 0.5048\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6910 - acc: 0.5171\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6902 - acc: 0.5399\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6912 - acc: 0.5418\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6928 - acc: 0.5342\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6903 - acc: 0.5228\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6922 - acc: 0.5171\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6912 - acc: 0.5219\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 35us/sample - loss: 0.6905 - acc: 0.5285\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6885 - acc: 0.5551\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6872 - acc: 0.5542\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6890 - acc: 0.5352\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6862 - acc: 0.5599\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6846 - acc: 0.5656\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6843 - acc: 0.5865\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.6842 - acc: 0.5513\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.6821 - acc: 0.5646\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6800 - acc: 0.5808\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6785 - acc: 0.6008\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6766 - acc: 0.5808\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6748 - acc: 0.6055\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6739 - acc: 0.5798\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6713 - acc: 0.6122\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6697 - acc: 0.6141\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6688 - acc: 0.6122\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6663 - acc: 0.6207\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6647 - acc: 0.6217\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6636 - acc: 0.6008\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6613 - acc: 0.6331\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6598 - acc: 0.6255\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6575 - acc: 0.6226\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6556 - acc: 0.6169\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6544 - acc: 0.6245\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6533 - acc: 0.6283\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6488 - acc: 0.6245\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6456 - acc: 0.6198\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6422 - acc: 0.6264\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6396 - acc: 0.6217\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.6332 - acc: 0.6445\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6293 - acc: 0.6473\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6224 - acc: 0.6625\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6132 - acc: 0.6597\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.6060 - acc: 0.6616\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.6064 - acc: 0.6702\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 35us/sample - loss: 0.6116 - acc: 0.6692\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 36us/sample - loss: 0.5996 - acc: 0.6787\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.5965 - acc: 0.6844\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5907 - acc: 0.6939\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5923 - acc: 0.6920\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5916 - acc: 0.6930\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.5836 - acc: 0.6977\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.5872 - acc: 0.7006\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5798 - acc: 0.7006\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5808 - acc: 0.7044\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5751 - acc: 0.7101\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.5751 - acc: 0.7063\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 34us/sample - loss: 0.5702 - acc: 0.7139\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.5693 - acc: 0.7120\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5690 - acc: 0.7053\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5625 - acc: 0.7262\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5639 - acc: 0.7158\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5593 - acc: 0.7205\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[0.         0.         1.0585821  0.99628311 1.0060425  0.\n",
      "  0.         1.01290536 0.         0.75137534 1.17125984 0.88777108\n",
      "  0.        ]]\n",
      "[[ 0.          0.         -0.02178955  0.07263184  0.25421143  0.\n",
      "   0.         -0.34863281  0.          0.00290527 -0.00726318  0.00726318\n",
      "   0.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 159us/sample - loss: 3.4320 - acc: 0.6464\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 2.0358 - acc: 0.6844\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 1.1994 - acc: 0.6540\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.7951 - acc: 0.6863\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.7009 - acc: 0.6692\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.6475 - acc: 0.6759\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6428 - acc: 0.6635\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6028 - acc: 0.6939\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5858 - acc: 0.7015\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5909 - acc: 0.6806\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5866 - acc: 0.6939\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5718 - acc: 0.6958\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5784 - acc: 0.6958\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5794 - acc: 0.6844\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6129 - acc: 0.6806\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6016 - acc: 0.6778\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5617 - acc: 0.7044\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6094 - acc: 0.6683\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5652 - acc: 0.7053\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5488 - acc: 0.7101\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5670 - acc: 0.7091\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5888 - acc: 0.6863\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5356 - acc: 0.7262\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 36us/sample - loss: 0.5719 - acc: 0.7110\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5932 - acc: 0.6768\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5617 - acc: 0.7101\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5307 - acc: 0.7234\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5468 - acc: 0.7110\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5231 - acc: 0.7348\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5422 - acc: 0.7177\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5459 - acc: 0.7129\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5181 - acc: 0.7405\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5218 - acc: 0.7329\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5172 - acc: 0.7386\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5176 - acc: 0.7319\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5337 - acc: 0.7243\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5021 - acc: 0.7471\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5113 - acc: 0.7367\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.5129 - acc: 0.7405\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4917 - acc: 0.7538\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5181 - acc: 0.7272\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4891 - acc: 0.7471\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5246 - acc: 0.7196\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4919 - acc: 0.7538\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4825 - acc: 0.7614\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4785 - acc: 0.7747\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4733 - acc: 0.7652\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4727 - acc: 0.7709\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5039 - acc: 0.7529\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4883 - acc: 0.7519\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4939 - acc: 0.7500\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4679 - acc: 0.7557\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4965 - acc: 0.7433\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4720 - acc: 0.7728\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4674 - acc: 0.7719\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4536 - acc: 0.7804\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4468 - acc: 0.7785\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4901 - acc: 0.7586\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4486 - acc: 0.7861\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4526 - acc: 0.7852\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4460 - acc: 0.7738\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4452 - acc: 0.7652\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4380 - acc: 0.7814\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4419 - acc: 0.7899\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4343 - acc: 0.7947\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4230 - acc: 0.8051\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4502 - acc: 0.7766\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4354 - acc: 0.7937\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4479 - acc: 0.7804\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4180 - acc: 0.8108\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4288 - acc: 0.7975\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4320 - acc: 0.7947\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4148 - acc: 0.8099\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4258 - acc: 0.7937\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4517 - acc: 0.7852\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4396 - acc: 0.7833\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4441 - acc: 0.7852\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4082 - acc: 0.8127\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4081 - acc: 0.8099\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4082 - acc: 0.8080\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4251 - acc: 0.7947\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4051 - acc: 0.8165\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4042 - acc: 0.8222\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4118 - acc: 0.8137\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4575 - acc: 0.7738\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3999 - acc: 0.8175\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4203 - acc: 0.8146\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4196 - acc: 0.8080\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3927 - acc: 0.8175\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3903 - acc: 0.8146\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3889 - acc: 0.8260\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4065 - acc: 0.8270\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4016 - acc: 0.8213\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3871 - acc: 0.8289\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3956 - acc: 0.8213\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3969 - acc: 0.8260\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3808 - acc: 0.8337\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3798 - acc: 0.8384\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3888 - acc: 0.8213\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3887 - acc: 0.8337\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01121876 1.00819728 1.01047697 1.01029811 1.00963655 1.01101101\n",
      "  1.00899101 1.06814093 1.00819728 1.00593418 0.         0.\n",
      "  1.00819728]]\n",
      "[[-0.82971191  0.55926514 -2.11853027 -3.38897705  2.7779541  -1.\n",
      "   1.         -0.01837158  0.55926514  0.24741211  0.          0.\n",
      "   0.55926514]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 159us/sample - loss: 34.4348 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 5.5868 - acc: 0.5190\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 1.4070 - acc: 0.5485\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 1.3203 - acc: 0.5456\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.2059 - acc: 0.5608\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.1083 - acc: 0.5684\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.9788 - acc: 0.5580\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.8889 - acc: 0.5713\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.8048 - acc: 0.5856\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.7521 - acc: 0.6084\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.7092 - acc: 0.6188\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6573 - acc: 0.6236\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6333 - acc: 0.6340\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6314 - acc: 0.6549\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6072 - acc: 0.6663\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5859 - acc: 0.6882\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5730 - acc: 0.6996\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5683 - acc: 0.6911\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5530 - acc: 0.7215\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5758 - acc: 0.7025\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5431 - acc: 0.7243\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5561 - acc: 0.7110\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5457 - acc: 0.7281\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5364 - acc: 0.7215\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5270 - acc: 0.7310\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5300 - acc: 0.7357\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5237 - acc: 0.7548\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5185 - acc: 0.7357\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5179 - acc: 0.7490\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5260 - acc: 0.7357\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5202 - acc: 0.7319\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4956 - acc: 0.7643\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4937 - acc: 0.7662\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5094 - acc: 0.7424\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5094 - acc: 0.7386\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4779 - acc: 0.7728\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4737 - acc: 0.7700\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4737 - acc: 0.7909\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4642 - acc: 0.7861\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4564 - acc: 0.7909\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4637 - acc: 0.7671\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4577 - acc: 0.7785\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4574 - acc: 0.7757\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4539 - acc: 0.7766\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4487 - acc: 0.7861\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4369 - acc: 0.8070\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4488 - acc: 0.7719\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4431 - acc: 0.7956\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4221 - acc: 0.8080\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4255 - acc: 0.8099\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4141 - acc: 0.8213\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4228 - acc: 0.8070\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4227 - acc: 0.8061\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4443 - acc: 0.7833\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4071 - acc: 0.8108\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4053 - acc: 0.8260\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4112 - acc: 0.8080\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4011 - acc: 0.8099\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4156 - acc: 0.8232\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4025 - acc: 0.8203\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3938 - acc: 0.8365\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3965 - acc: 0.8279\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4113 - acc: 0.8184\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4036 - acc: 0.8146\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4236 - acc: 0.7947\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3971 - acc: 0.8241\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3818 - acc: 0.8479\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3930 - acc: 0.8298\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3889 - acc: 0.8308\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3972 - acc: 0.8241\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4041 - acc: 0.8184\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3803 - acc: 0.8346\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3818 - acc: 0.8432\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3911 - acc: 0.8270\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3772 - acc: 0.8375\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3796 - acc: 0.8403\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3783 - acc: 0.8451\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3892 - acc: 0.8175\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4165 - acc: 0.8051\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3820 - acc: 0.8403\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3974 - acc: 0.8384\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3735 - acc: 0.8327\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3848 - acc: 0.8232\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3757 - acc: 0.8479\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3895 - acc: 0.8308\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3865 - acc: 0.8365\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3770 - acc: 0.8432\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.3739 - acc: 0.8470\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3858 - acc: 0.8194\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3790 - acc: 0.8413\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.3853 - acc: 0.8375\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4139 - acc: 0.8099\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3803 - acc: 0.8403\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3715 - acc: 0.8536\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4022 - acc: 0.8165\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3787 - acc: 0.8451\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3725 - acc: 0.8451\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3665 - acc: 0.8508\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4259 - acc: 0.8032\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4548 - acc: 0.7795\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00954216 1.00680382 1.01160571 1.00839938 1.01032073 0.\n",
      "  0.         1.00981143 1.00680382 1.0086658  1.01321654 1.00839938\n",
      "  1.00893235]]\n",
      "[[ 2.20501709  0.31500244 -0.63000488  0.63000488 -3.15002441  0.\n",
      "   0.          5.3550415   0.31500244  0.75600586 -0.31500244  0.63000488\n",
      "   0.94500732]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 168us/sample - loss: 12.6702 - acc: 0.5057\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 1.6338 - acc: 0.5542\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 1.2259 - acc: 0.5770\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 1.1940 - acc: 0.6055\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 1.1888 - acc: 0.5989\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.1339 - acc: 0.6008\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 1.1239 - acc: 0.6017\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 1.0773 - acc: 0.6122\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 1.0648 - acc: 0.6141\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 1.0578 - acc: 0.6179\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.0189 - acc: 0.6198\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.9928 - acc: 0.6169\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.9764 - acc: 0.6445\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.9520 - acc: 0.6207\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.9509 - acc: 0.6359\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.9185 - acc: 0.6302\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 35us/sample - loss: 0.9072 - acc: 0.6340\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.8791 - acc: 0.6226\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.8537 - acc: 0.6369\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.8278 - acc: 0.6597\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.8358 - acc: 0.6293\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.8083 - acc: 0.6663\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.7869 - acc: 0.6540\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.7745 - acc: 0.6559\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.7541 - acc: 0.6625\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.7380 - acc: 0.6968\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.7248 - acc: 0.6797\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.7094 - acc: 0.6977\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7031 - acc: 0.6644\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6931 - acc: 0.6901\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6730 - acc: 0.6987\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6645 - acc: 0.7034\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6620 - acc: 0.7082\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6441 - acc: 0.7205\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6302 - acc: 0.7139\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6287 - acc: 0.7110\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6314 - acc: 0.7082\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6014 - acc: 0.7186\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6194 - acc: 0.7167\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6014 - acc: 0.7215\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5906 - acc: 0.7281\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5772 - acc: 0.7243\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5832 - acc: 0.7253\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5822 - acc: 0.7224\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5672 - acc: 0.7357\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5555 - acc: 0.7300\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5442 - acc: 0.7405\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5529 - acc: 0.7319\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5360 - acc: 0.7490\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5389 - acc: 0.7510\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5207 - acc: 0.7510\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5221 - acc: 0.7481\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5210 - acc: 0.7548\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5148 - acc: 0.7519\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5013 - acc: 0.7567\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4808 - acc: 0.7690\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4841 - acc: 0.7586\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4803 - acc: 0.7652\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4655 - acc: 0.7681\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4823 - acc: 0.7652\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4631 - acc: 0.7690\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4900 - acc: 0.7557\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4799 - acc: 0.7586\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4529 - acc: 0.7795\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4644 - acc: 0.7795\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4501 - acc: 0.7804\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4465 - acc: 0.7757\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4470 - acc: 0.7766\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4412 - acc: 0.7928\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4397 - acc: 0.7852\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4453 - acc: 0.7918\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4337 - acc: 0.7823\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4331 - acc: 0.7899\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4275 - acc: 0.7947\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4250 - acc: 0.7937\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4236 - acc: 0.8004\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4239 - acc: 0.8023\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4322 - acc: 0.8004\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4270 - acc: 0.7928\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4147 - acc: 0.7956\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4171 - acc: 0.8070\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4126 - acc: 0.7985\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4548 - acc: 0.7890\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4082 - acc: 0.8146\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4058 - acc: 0.8137\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4115 - acc: 0.8108\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 36us/sample - loss: 0.4013 - acc: 0.8203\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4019 - acc: 0.8346\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4013 - acc: 0.8260\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3958 - acc: 0.8213\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4011 - acc: 0.8222\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3921 - acc: 0.8346\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4042 - acc: 0.8213\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3892 - acc: 0.8327\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3981 - acc: 0.8251\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3940 - acc: 0.8327\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3907 - acc: 0.8327\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3979 - acc: 0.8241\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3949 - acc: 0.8289\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3858 - acc: 0.8298\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00928529 1.00682954 1.01159273 1.00968206 1.01065889 0.\n",
      "  1.01148217 1.00872408 1.00682954 1.00858511 1.01319049 1.00841228\n",
      "  1.00682954]]\n",
      "[[ 1.41217041  0.31756592 -0.63513184  3.17565918 -1.53387451  0.\n",
      "  -0.68243408  0.79058838  0.31756592  0.71283569 -0.31756592  0.63513184\n",
      "   0.31756592]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 172us/sample - loss: 23.2378 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 4.6820 - acc: 0.4943\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.4372 - acc: 0.5057\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.9579 - acc: 0.5067\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.7137 - acc: 0.5665\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6690 - acc: 0.5998\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6583 - acc: 0.6084\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6514 - acc: 0.6046\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6434 - acc: 0.6226\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.6379 - acc: 0.6302\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.6347 - acc: 0.6369\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6327 - acc: 0.6388\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6316 - acc: 0.6378\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6300 - acc: 0.6445\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.6280 - acc: 0.6255\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.6281 - acc: 0.6464\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6236 - acc: 0.6454\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6211 - acc: 0.6369\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6159 - acc: 0.6530\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6135 - acc: 0.6435\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.6066 - acc: 0.6464\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6006 - acc: 0.6530\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5974 - acc: 0.6673\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5940 - acc: 0.6635\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5921 - acc: 0.6635\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5912 - acc: 0.6778\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5863 - acc: 0.6683\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5837 - acc: 0.6740\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5825 - acc: 0.6616\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5825 - acc: 0.6740\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5747 - acc: 0.6892\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5710 - acc: 0.6873\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5697 - acc: 0.6968\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5703 - acc: 0.7025\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5675 - acc: 0.6920\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5614 - acc: 0.6949\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5615 - acc: 0.6873\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5515 - acc: 0.7044\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5529 - acc: 0.7025\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5505 - acc: 0.7158\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5511 - acc: 0.7072\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5503 - acc: 0.7072\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5453 - acc: 0.7129\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5397 - acc: 0.7101\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5388 - acc: 0.7101\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5365 - acc: 0.7215\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5431 - acc: 0.7196\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5358 - acc: 0.7158\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5377 - acc: 0.7224\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5345 - acc: 0.7177\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5300 - acc: 0.7243\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5282 - acc: 0.7167\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5266 - acc: 0.7139\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5241 - acc: 0.7148\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5231 - acc: 0.7367\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5220 - acc: 0.7186\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5211 - acc: 0.7272\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5224 - acc: 0.7215\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5219 - acc: 0.7291\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5122 - acc: 0.7357\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5198 - acc: 0.7291\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5118 - acc: 0.7357\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5164 - acc: 0.7424\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5144 - acc: 0.7300\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5104 - acc: 0.7319\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5075 - acc: 0.7310\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5046 - acc: 0.7348\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5054 - acc: 0.7300\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5058 - acc: 0.7386\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4972 - acc: 0.7519\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4978 - acc: 0.7481\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5011 - acc: 0.7338\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5010 - acc: 0.7386\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4934 - acc: 0.7414\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4909 - acc: 0.7557\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4890 - acc: 0.7433\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4872 - acc: 0.7471\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4844 - acc: 0.7490\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4842 - acc: 0.7367\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4773 - acc: 0.7424\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4787 - acc: 0.7490\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4776 - acc: 0.7662\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4728 - acc: 0.7624\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4722 - acc: 0.7605\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4843 - acc: 0.7548\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.4744 - acc: 0.7671\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4668 - acc: 0.7605\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4635 - acc: 0.7728\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4616 - acc: 0.7662\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4610 - acc: 0.7595\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4532 - acc: 0.7614\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4565 - acc: 0.7595\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4521 - acc: 0.7766\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4490 - acc: 0.7747\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4476 - acc: 0.7700\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4429 - acc: 0.7766\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4418 - acc: 0.7776\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4413 - acc: 0.7776\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4380 - acc: 0.7776\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4394 - acc: 0.7747\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00974664 0.         1.00833563 1.00993184 1.01035955 1.00490111\n",
      "  1.01515089 1.01014613 1.00490111 0.96122717 1.01515089 1.00974756\n",
      "  1.00490111]]\n",
      "[[ 3.9854126   0.          0.60583496 14.81750488 -2.81005859  0.19708252\n",
      "  -0.19708252 -6.91247559  0.19708252  0.01970825 -0.19708252  4.\n",
      "   0.19708252]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 170us/sample - loss: 2.8366 - acc: 0.5048\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.7318 - acc: 0.5209\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6752 - acc: 0.5219\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6754 - acc: 0.5048\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6762 - acc: 0.4952\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6744 - acc: 0.5095\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 36us/sample - loss: 0.6741 - acc: 0.5038\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6759 - acc: 0.5067\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6772 - acc: 0.5086\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6715 - acc: 0.4924\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6725 - acc: 0.5124\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.6709 - acc: 0.5352\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6706 - acc: 0.5105\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6711 - acc: 0.5418\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6714 - acc: 0.5361\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6786 - acc: 0.5019\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6802 - acc: 0.5019\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6718 - acc: 0.5209\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6727 - acc: 0.5361\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6662 - acc: 0.5494\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6676 - acc: 0.5798\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6700 - acc: 0.5409\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6665 - acc: 0.5589\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6651 - acc: 0.5646\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6693 - acc: 0.5361\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6665 - acc: 0.5570\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6606 - acc: 0.5656\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6614 - acc: 0.5542\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6678 - acc: 0.5333\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6623 - acc: 0.5637\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6596 - acc: 0.5618\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6624 - acc: 0.5856\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6586 - acc: 0.6017\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6534 - acc: 0.6150\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6623 - acc: 0.5551\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6570 - acc: 0.5760\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6593 - acc: 0.5627\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6548 - acc: 0.5779\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6447 - acc: 0.5951\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6424 - acc: 0.6236\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6378 - acc: 0.6578\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6362 - acc: 0.6511\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6321 - acc: 0.6559\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6266 - acc: 0.6635\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.6213 - acc: 0.6625\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6168 - acc: 0.6806\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6050 - acc: 0.6939\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5951 - acc: 0.7025\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5878 - acc: 0.6863\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5785 - acc: 0.6958\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5683 - acc: 0.7158\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5639 - acc: 0.7272\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5576 - acc: 0.7291\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5571 - acc: 0.7196\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5519 - acc: 0.7205\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5494 - acc: 0.7338\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5470 - acc: 0.7310\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5445 - acc: 0.7367\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5451 - acc: 0.7253\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.5406 - acc: 0.7395\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5397 - acc: 0.7367\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 37us/sample - loss: 0.5366 - acc: 0.7348\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5356 - acc: 0.7367\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5333 - acc: 0.7405\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5324 - acc: 0.7395\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5307 - acc: 0.7414\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5286 - acc: 0.7471\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5290 - acc: 0.7357\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5257 - acc: 0.7414\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5239 - acc: 0.7433\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5235 - acc: 0.7414\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5255 - acc: 0.7424\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5208 - acc: 0.7462\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5201 - acc: 0.7490\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5175 - acc: 0.7433\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5158 - acc: 0.7529\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5132 - acc: 0.7471\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5134 - acc: 0.7490\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5109 - acc: 0.7529\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5100 - acc: 0.7490\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5157 - acc: 0.7481\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.5086 - acc: 0.7462\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5067 - acc: 0.7529\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5056 - acc: 0.7529\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5024 - acc: 0.7510\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5019 - acc: 0.7529\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5025 - acc: 0.7510\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5004 - acc: 0.7605\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4995 - acc: 0.7576\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4957 - acc: 0.7576\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4943 - acc: 0.7576\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4951 - acc: 0.7624\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4920 - acc: 0.7624\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4929 - acc: 0.7586\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4908 - acc: 0.7576\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4906 - acc: 0.7595\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4891 - acc: 0.7614\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4967 - acc: 0.7614\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4942 - acc: 0.7652\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4943 - acc: 0.7595\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00985853 1.01340728 1.01170077 1.00984567 1.01030881 0.\n",
      "  1.01340728 1.01012129 0.         1.00945258 1.01170077 1.01340728\n",
      "  1.00661556]]\n",
      "[[ 7.13818359 -0.29742432 -0.59484863  6.54333496 -3.27166748  0.\n",
      "  -0.29742432 -8.32788086  0.          1.84403076 -0.59484863 -0.29742432\n",
      "   0.29742432]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 178us/sample - loss: 93.0655 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 55.3753 - acc: 0.5000\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 20.1901 - acc: 0.4449\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 6.4781 - acc: 0.4553\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 2.3673 - acc: 0.6036\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 1.9623 - acc: 0.6369\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 1.8096 - acc: 0.6331\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 1.7395 - acc: 0.6188\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 1.6009 - acc: 0.6340\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 1.4984 - acc: 0.6464\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 1.4037 - acc: 0.6397\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 1.3345 - acc: 0.6312\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 1.2575 - acc: 0.6426\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 1.2183 - acc: 0.6502\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 1.1955 - acc: 0.6416\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 1.0815 - acc: 0.6492\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 1.0285 - acc: 0.6597\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.9685 - acc: 0.6635\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.9245 - acc: 0.6702\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.9019 - acc: 0.6721\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 35us/sample - loss: 0.8608 - acc: 0.6854\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.8054 - acc: 0.6778\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.7665 - acc: 0.6759\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.7204 - acc: 0.6768\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.7183 - acc: 0.6901\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6653 - acc: 0.7034\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6328 - acc: 0.6977\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6160 - acc: 0.7072\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5991 - acc: 0.7082\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5843 - acc: 0.7224\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5963 - acc: 0.7262\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5413 - acc: 0.7338\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5482 - acc: 0.7338\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5148 - acc: 0.7452\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5128 - acc: 0.7500\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4845 - acc: 0.7595\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5109 - acc: 0.7681\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4815 - acc: 0.7795\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4748 - acc: 0.7757\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4646 - acc: 0.7709\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5013 - acc: 0.7633\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4792 - acc: 0.7776\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4543 - acc: 0.7947\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4456 - acc: 0.7890\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4473 - acc: 0.7966\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4327 - acc: 0.8051\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4332 - acc: 0.8023\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4354 - acc: 0.7985\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4231 - acc: 0.8194\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 34us/sample - loss: 0.4231 - acc: 0.7985\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4169 - acc: 0.8175\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4206 - acc: 0.8032\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4199 - acc: 0.8061\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4358 - acc: 0.7956\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4070 - acc: 0.8175\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4042 - acc: 0.8213\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4061 - acc: 0.8156\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4306 - acc: 0.7861\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4077 - acc: 0.8165\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4591 - acc: 0.7909\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4091 - acc: 0.8156\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4443 - acc: 0.7823\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3986 - acc: 0.8270\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4339 - acc: 0.8089\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4680 - acc: 0.7719\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4633 - acc: 0.7833\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4452 - acc: 0.7899\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.4476 - acc: 0.7795\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4198 - acc: 0.7985\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4115 - acc: 0.8156\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4064 - acc: 0.8023\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3987 - acc: 0.8241\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4125 - acc: 0.8156\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4167 - acc: 0.7985\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4561 - acc: 0.7871\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4020 - acc: 0.8146\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3876 - acc: 0.8346\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4401 - acc: 0.7918\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3946 - acc: 0.8327\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3831 - acc: 0.8327\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 34us/sample - loss: 0.3816 - acc: 0.8356\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3883 - acc: 0.8232\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3844 - acc: 0.8298\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3853 - acc: 0.8194\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3932 - acc: 0.8165\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3970 - acc: 0.8232\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3808 - acc: 0.8337\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3980 - acc: 0.8270\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.3796 - acc: 0.8384\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4165 - acc: 0.8165\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3940 - acc: 0.8251\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3897 - acc: 0.8317\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3943 - acc: 0.8289\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3818 - acc: 0.8317\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3829 - acc: 0.8279\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3849 - acc: 0.8279\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3924 - acc: 0.8241\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3895 - acc: 0.8270\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4033 - acc: 0.8099\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3883 - acc: 0.8251\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00864533 0.         0.         1.00906827 1.00875808 0.\n",
      "  1.02514516 1.01124498 0.99529583 1.00294421 1.02514516 1.00505057\n",
      "  0.99529583]]\n",
      "[[ 0.74456787  0.          0.          1.08300781  0.81225586  0.\n",
      "  -0.06768799 -0.81225586  0.06768799  0.14214478 -0.06768799  0.20306396\n",
      "   0.06768799]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n",
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 171us/sample - loss: 35.7630 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 13.1652 - acc: 0.4810\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 2.8175 - acc: 0.5523\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 1.4026 - acc: 0.6587\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 1.2422 - acc: 0.6721\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 1.1949 - acc: 0.6663\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 1.1113 - acc: 0.6568\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.0706 - acc: 0.6606\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 1.0201 - acc: 0.6711\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.9378 - acc: 0.6882\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.8967 - acc: 0.6806\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.8685 - acc: 0.6759\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.8313 - acc: 0.6863\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.8193 - acc: 0.6835\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7871 - acc: 0.6825\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.7458 - acc: 0.7034\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.7111 - acc: 0.7015\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6797 - acc: 0.7063\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6574 - acc: 0.7148\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6523 - acc: 0.7186\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6035 - acc: 0.7357\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5760 - acc: 0.7405\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.5403 - acc: 0.7652\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5162 - acc: 0.7652\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4961 - acc: 0.7776\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4869 - acc: 0.7766\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4634 - acc: 0.7918\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4521 - acc: 0.7956\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4374 - acc: 0.8004\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4317 - acc: 0.7966\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4166 - acc: 0.8146\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4149 - acc: 0.8127\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4151 - acc: 0.8004\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4041 - acc: 0.8241\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4118 - acc: 0.8251\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4079 - acc: 0.8108\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4185 - acc: 0.8004\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3946 - acc: 0.8232\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3904 - acc: 0.8213\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3926 - acc: 0.8156\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4099 - acc: 0.7956\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3835 - acc: 0.8413\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3807 - acc: 0.8327\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3858 - acc: 0.8279\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3868 - acc: 0.8317\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3751 - acc: 0.8327\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4244 - acc: 0.7985\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3867 - acc: 0.8289\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3754 - acc: 0.8403\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3872 - acc: 0.8165\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3831 - acc: 0.8289\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3815 - acc: 0.8213\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3736 - acc: 0.8394\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3790 - acc: 0.8308\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3743 - acc: 0.8413\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3786 - acc: 0.8298\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3763 - acc: 0.8384\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3941 - acc: 0.8222\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3888 - acc: 0.8270\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3878 - acc: 0.8432\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3664 - acc: 0.8432\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3652 - acc: 0.8413\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3741 - acc: 0.8365\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.3690 - acc: 0.8432\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3644 - acc: 0.8451\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3831 - acc: 0.8346\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3825 - acc: 0.8403\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3618 - acc: 0.8451\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3733 - acc: 0.8460\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3766 - acc: 0.8279\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3617 - acc: 0.8460\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3649 - acc: 0.8460\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3594 - acc: 0.8441\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3921 - acc: 0.8194\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3580 - acc: 0.8460\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3725 - acc: 0.8432\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3563 - acc: 0.8508\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3803 - acc: 0.8394\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3708 - acc: 0.8441\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3704 - acc: 0.8375\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3762 - acc: 0.8384\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3617 - acc: 0.8470\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3722 - acc: 0.8308\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3593 - acc: 0.8498\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3636 - acc: 0.8460\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3614 - acc: 0.8498\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3784 - acc: 0.8375\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3636 - acc: 0.8422\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3561 - acc: 0.8517\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3685 - acc: 0.8308\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3600 - acc: 0.8413\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3656 - acc: 0.8346\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3911 - acc: 0.8251\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3779 - acc: 0.8232\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3620 - acc: 0.8498\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4174 - acc: 0.8042\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3573 - acc: 0.8527\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3536 - acc: 0.8451\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3947 - acc: 0.8194\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3832 - acc: 0.8232\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00659326 0.         1.0116422  1.01110928 1.01038377 0.\n",
      "  1.0116422  1.01016836 1.00836312 0.         0.         0.\n",
      "  1.00899101]]\n",
      "[[ 0.29547119  0.         -0.61602783 -0.91149902 -2.63275146  0.\n",
      "  -0.61602783 -6.          0.61602783  0.          0.          0.\n",
      "   1.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 177us/sample - loss: 9.0547 - acc: 0.5029\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 1.0984 - acc: 0.5437\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.8477 - acc: 0.6084\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.7912 - acc: 0.6008\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.7655 - acc: 0.5922\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.7324 - acc: 0.5884\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.7079 - acc: 0.6055\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6802 - acc: 0.6036\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6498 - acc: 0.6388\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6330 - acc: 0.6483\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6180 - acc: 0.6511\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6100 - acc: 0.6759\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6064 - acc: 0.6578\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6222 - acc: 0.6502\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6169 - acc: 0.6644\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6067 - acc: 0.6473\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6149 - acc: 0.6578\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6108 - acc: 0.6721\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.6011 - acc: 0.6702\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6081 - acc: 0.6540\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6002 - acc: 0.6683\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 36us/sample - loss: 0.5951 - acc: 0.6825\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6040 - acc: 0.6606\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6009 - acc: 0.6663\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6014 - acc: 0.6644\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.6017 - acc: 0.6635\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5973 - acc: 0.6787\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5911 - acc: 0.6901\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5934 - acc: 0.6854\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5921 - acc: 0.6892\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5917 - acc: 0.6854\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5917 - acc: 0.6806\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6116 - acc: 0.6644\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5904 - acc: 0.7015\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5902 - acc: 0.6854\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5885 - acc: 0.6901\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5889 - acc: 0.6882\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5901 - acc: 0.6949\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5936 - acc: 0.6654\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5837 - acc: 0.6968\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5836 - acc: 0.6987\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5851 - acc: 0.6958\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5796 - acc: 0.6987\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5748 - acc: 0.7044\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5721 - acc: 0.7101\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5743 - acc: 0.6863\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5663 - acc: 0.6939\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5731 - acc: 0.6996\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5653 - acc: 0.7129\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5825 - acc: 0.7015\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5718 - acc: 0.6825\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5656 - acc: 0.7148\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5615 - acc: 0.7072\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5616 - acc: 0.7158\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5634 - acc: 0.7034\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5611 - acc: 0.7110\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5603 - acc: 0.7158\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5602 - acc: 0.7120\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5606 - acc: 0.7129\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5588 - acc: 0.7148\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5580 - acc: 0.7072\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5597 - acc: 0.7091\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5849 - acc: 0.7006\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5648 - acc: 0.7101\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5468 - acc: 0.7215\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5434 - acc: 0.7262\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5561 - acc: 0.7120\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5420 - acc: 0.7253\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5461 - acc: 0.7243\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5488 - acc: 0.7215\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5559 - acc: 0.7148\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5514 - acc: 0.7110\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5439 - acc: 0.7272\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5421 - acc: 0.7291\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5523 - acc: 0.7177\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5395 - acc: 0.7329\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5333 - acc: 0.7224\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5355 - acc: 0.7253\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 20us/sample - loss: 0.5304 - acc: 0.7348\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5283 - acc: 0.7253\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5263 - acc: 0.7329\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5279 - acc: 0.7262\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5314 - acc: 0.7310\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5315 - acc: 0.7395\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5231 - acc: 0.7462\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5217 - acc: 0.7376\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5184 - acc: 0.7348\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5150 - acc: 0.7443\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5155 - acc: 0.7405\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5222 - acc: 0.7348\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5179 - acc: 0.7367\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.5140 - acc: 0.7433\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5068 - acc: 0.7357\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5116 - acc: 0.7348\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5046 - acc: 0.7471\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5091 - acc: 0.7395\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4983 - acc: 0.7586\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4969 - acc: 0.7529\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4936 - acc: 0.7519\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4957 - acc: 0.7490\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01085256 0.         1.01107778 1.00994667 1.01071827 1.00785132\n",
      "  1.01215787 1.01007992 1.00785132 1.00947015 1.01066015 1.00946197\n",
      "  1.00785132]]\n",
      "[[ -1.18566895   0.          -0.93811035  18.93811035  -1.40716553\n",
      "    0.46905518  -0.46905518 -12.63842773   0.46905518   1.9052124\n",
      "   -1.53094482   1.8762207    0.46905518]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 173us/sample - loss: 21.5593 - acc: 0.5076\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 2.0271 - acc: 0.5817\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 1.1511 - acc: 0.6293\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 1.0824 - acc: 0.6378\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 1.0377 - acc: 0.6540\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 1.0148 - acc: 0.6663\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.9597 - acc: 0.6901\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.9280 - acc: 0.6949\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.9168 - acc: 0.6930\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.8865 - acc: 0.6968\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.8469 - acc: 0.7072\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.8333 - acc: 0.7110\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.8183 - acc: 0.7006\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.8080 - acc: 0.7025\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.7952 - acc: 0.6911\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.7494 - acc: 0.7205\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.7259 - acc: 0.7139\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.7107 - acc: 0.7167\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6913 - acc: 0.7167\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6637 - acc: 0.7215\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6513 - acc: 0.7262\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6456 - acc: 0.7272\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6219 - acc: 0.7224\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5958 - acc: 0.7272\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6252 - acc: 0.7196\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5801 - acc: 0.7424\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5686 - acc: 0.7338\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 34us/sample - loss: 0.5548 - acc: 0.7557\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5417 - acc: 0.7481\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5511 - acc: 0.7452\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5149 - acc: 0.7624\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.5318 - acc: 0.7529\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5126 - acc: 0.7481\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5255 - acc: 0.7443\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4875 - acc: 0.7681\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4982 - acc: 0.7652\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4746 - acc: 0.7643\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4608 - acc: 0.7690\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4560 - acc: 0.7776\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4591 - acc: 0.7719\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4621 - acc: 0.7804\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4378 - acc: 0.7842\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4406 - acc: 0.7985\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4445 - acc: 0.7795\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4303 - acc: 0.7918\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4238 - acc: 0.7956\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4205 - acc: 0.7985\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4218 - acc: 0.7918\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4284 - acc: 0.8051\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4159 - acc: 0.8089\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4134 - acc: 0.8099\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4405 - acc: 0.7747\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4178 - acc: 0.8013\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4245 - acc: 0.8013\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4118 - acc: 0.8127\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3991 - acc: 0.8194\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3961 - acc: 0.8184\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3971 - acc: 0.8260\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3991 - acc: 0.8308\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4064 - acc: 0.8013\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 34us/sample - loss: 0.3975 - acc: 0.8203\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4067 - acc: 0.8203\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4110 - acc: 0.8165\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3931 - acc: 0.8289\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3942 - acc: 0.8260\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4033 - acc: 0.8089\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3895 - acc: 0.8232\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3994 - acc: 0.8175\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4372 - acc: 0.7966\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4179 - acc: 0.7899\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4359 - acc: 0.7947\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3956 - acc: 0.8175\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3949 - acc: 0.8232\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3909 - acc: 0.8251\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4010 - acc: 0.8118\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3813 - acc: 0.8346\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3817 - acc: 0.8327\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3872 - acc: 0.8270\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3827 - acc: 0.8279\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3830 - acc: 0.8403\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3938 - acc: 0.8251\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3943 - acc: 0.8356\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3775 - acc: 0.8298\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4030 - acc: 0.8108\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3996 - acc: 0.8222\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3764 - acc: 0.8432\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3828 - acc: 0.8384\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3790 - acc: 0.8384\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4180 - acc: 0.8118\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3880 - acc: 0.8289\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3789 - acc: 0.8394\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3825 - acc: 0.8308\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3732 - acc: 0.8422\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4111 - acc: 0.8137\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3825 - acc: 0.8337\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4169 - acc: 0.8013\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3833 - acc: 0.8337\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3705 - acc: 0.8498\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3781 - acc: 0.8317\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3713 - acc: 0.8470\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01250777 1.00750462 1.01250777 1.0096874  1.00972213 0.\n",
      "  0.         1.00958324 1.00750462 1.00910737 1.01250777 0.\n",
      "  1.01250777]]\n",
      "[[-0.40374756  0.40374756 -0.40374756  3.22998047  3.63372803  0.\n",
      "   0.          2.42248535  0.40374756  1.13049316 -0.40374756  0.\n",
      "  -0.40374756]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 180us/sample - loss: 2.6584 - acc: 0.3954\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 1.0596 - acc: 0.4800\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.7457 - acc: 0.6074\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6879 - acc: 0.6350\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6660 - acc: 0.6549\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6396 - acc: 0.6787\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.6253 - acc: 0.6778\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6070 - acc: 0.6882\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5899 - acc: 0.6977\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5649 - acc: 0.7357\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5564 - acc: 0.7253\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5396 - acc: 0.7224\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5351 - acc: 0.7386\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5516 - acc: 0.7319\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5389 - acc: 0.7196\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5230 - acc: 0.7433\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5044 - acc: 0.7490\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4793 - acc: 0.7633\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4846 - acc: 0.7709\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4764 - acc: 0.7747\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4767 - acc: 0.7671\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4543 - acc: 0.7766\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4520 - acc: 0.7852\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4443 - acc: 0.8051\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4556 - acc: 0.7804\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4306 - acc: 0.8099\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4275 - acc: 0.8118\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4320 - acc: 0.7994\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4195 - acc: 0.8080\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4231 - acc: 0.8099\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4140 - acc: 0.8175\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4116 - acc: 0.8194\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4206 - acc: 0.8222\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4230 - acc: 0.7975\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4030 - acc: 0.8346\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4017 - acc: 0.8241\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3981 - acc: 0.8317\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3987 - acc: 0.8298\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3964 - acc: 0.8165\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4170 - acc: 0.8108\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4209 - acc: 0.8089\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3873 - acc: 0.8432\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3887 - acc: 0.8422\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4031 - acc: 0.8213\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3926 - acc: 0.8346\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3857 - acc: 0.8451\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3851 - acc: 0.8375\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3990 - acc: 0.8384\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3928 - acc: 0.8270\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3779 - acc: 0.8527\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3819 - acc: 0.8470\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3995 - acc: 0.8270\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3762 - acc: 0.8489\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3821 - acc: 0.8470\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3818 - acc: 0.8432\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3834 - acc: 0.8327\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3885 - acc: 0.8451\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3883 - acc: 0.8251\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3802 - acc: 0.8327\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3813 - acc: 0.8337\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3760 - acc: 0.8441\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3926 - acc: 0.8270\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4062 - acc: 0.8232\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4115 - acc: 0.8213\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3779 - acc: 0.8394\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3781 - acc: 0.8422\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3714 - acc: 0.8432\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3697 - acc: 0.8527\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4086 - acc: 0.8108\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3800 - acc: 0.8365\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3689 - acc: 0.8432\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3693 - acc: 0.8479\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3776 - acc: 0.8394\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3705 - acc: 0.8337\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3672 - acc: 0.8536\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3673 - acc: 0.8498\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3651 - acc: 0.8460\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3837 - acc: 0.8413\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3826 - acc: 0.8346\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3708 - acc: 0.8384\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3742 - acc: 0.8394\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3685 - acc: 0.8470\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3644 - acc: 0.8498\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3727 - acc: 0.8498\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3766 - acc: 0.8337\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3883 - acc: 0.8432\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3610 - acc: 0.8555\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3539 - acc: 0.8584\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3606 - acc: 0.8536\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3669 - acc: 0.8479\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3671 - acc: 0.8451\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3588 - acc: 0.8555\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3682 - acc: 0.8346\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3599 - acc: 0.8498\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3661 - acc: 0.8546\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3662 - acc: 0.8375\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3532 - acc: 0.8489\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3672 - acc: 0.8327\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3647 - acc: 0.8536\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3583 - acc: 0.8536\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01033784 1.01356434 1.00912014 1.01059896 1.01075902 1.00859064\n",
      "  0.         1.01026916 0.         1.00907869 1.01078699 1.00921423\n",
      "  0.        ]]\n",
      "[[-2.99053955 -0.28436279  1.14691162 -1.68725586 -1.33166504  0.71563721\n",
      "   0.         -3.753479    0.          1.09526978 -1.28436279  1.28436279\n",
      "   0.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 178us/sample - loss: 1.4664 - acc: 0.6369\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.9165 - acc: 0.6160\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.7668 - acc: 0.6473\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6823 - acc: 0.6435\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.6333 - acc: 0.6892\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.6099 - acc: 0.6930\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5487 - acc: 0.7471\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5234 - acc: 0.7471\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5211 - acc: 0.7357\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5195 - acc: 0.7281\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5168 - acc: 0.7500\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4688 - acc: 0.7681\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.5163 - acc: 0.7386\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4634 - acc: 0.7766\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4377 - acc: 0.7814\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4193 - acc: 0.8251\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4167 - acc: 0.8175\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4166 - acc: 0.8042\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4204 - acc: 0.8137\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4399 - acc: 0.7814\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4359 - acc: 0.7937\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4019 - acc: 0.8213\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4582 - acc: 0.7852\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4236 - acc: 0.8013\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3919 - acc: 0.8165\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4236 - acc: 0.8032\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3967 - acc: 0.8213\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3885 - acc: 0.8441\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4204 - acc: 0.8023\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3883 - acc: 0.8156\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3927 - acc: 0.8127\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3870 - acc: 0.8289\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4179 - acc: 0.8032\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4087 - acc: 0.8175\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3743 - acc: 0.8327\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3982 - acc: 0.8127\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.5092 - acc: 0.7747\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3932 - acc: 0.8232\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.4186 - acc: 0.8004\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3695 - acc: 0.8337\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3753 - acc: 0.8394\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4035 - acc: 0.8270\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4667 - acc: 0.7814\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4413 - acc: 0.7861\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3760 - acc: 0.8365\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3765 - acc: 0.8460\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3789 - acc: 0.8222\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3725 - acc: 0.8337\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3958 - acc: 0.8146\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4413 - acc: 0.7890\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3879 - acc: 0.8356\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3757 - acc: 0.8365\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3916 - acc: 0.8137\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3820 - acc: 0.8327\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3934 - acc: 0.8260\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3914 - acc: 0.8346\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3887 - acc: 0.8298\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3889 - acc: 0.8165\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 37us/sample - loss: 0.3925 - acc: 0.8375\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4250 - acc: 0.8080\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3733 - acc: 0.8308\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3949 - acc: 0.8203\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4472 - acc: 0.7985\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3950 - acc: 0.8118\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3699 - acc: 0.8365\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3657 - acc: 0.8432\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3693 - acc: 0.8460\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3633 - acc: 0.8460\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3666 - acc: 0.8394\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3922 - acc: 0.8251\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3758 - acc: 0.8308\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.4063 - acc: 0.8184\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3760 - acc: 0.8308\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3815 - acc: 0.8346\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3714 - acc: 0.8365\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4093 - acc: 0.8070\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3737 - acc: 0.8308\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3726 - acc: 0.8422\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3944 - acc: 0.8222\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3825 - acc: 0.8308\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3651 - acc: 0.8337\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3672 - acc: 0.8432\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3642 - acc: 0.8394\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3609 - acc: 0.8508\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.4385 - acc: 0.8004\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3831 - acc: 0.8232\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.4103 - acc: 0.8042\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3664 - acc: 0.8470\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3624 - acc: 0.8479\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3708 - acc: 0.8346\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3678 - acc: 0.8422\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3673 - acc: 0.8346\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3797 - acc: 0.8356\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3679 - acc: 0.8384\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3823 - acc: 0.8298\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3662 - acc: 0.8384\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3653 - acc: 0.8432\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 21us/sample - loss: 0.3879 - acc: 0.8279\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 23us/sample - loss: 0.3746 - acc: 0.8337\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 22us/sample - loss: 0.3855 - acc: 0.8251\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00937074 0.         1.01084142 1.00943237 1.0063522  0.\n",
      "  1.00915998 1.0622647  0.         1.00738992 1.00936807 1.01255738\n",
      "  1.01504105]]\n",
      "[[ 1.60406494  0.         -1.20135498  1.77832031  0.27587891  0.\n",
      "   1.20135498 -0.02032471  0.          0.38596191  1.59729004 -0.39593506\n",
      "  -0.20135498]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 222us/sample - loss: 12.6015 - acc: 0.4477\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 42us/sample - loss: 3.2504 - acc: 0.4563\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 1.8038 - acc: 0.5760\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 1.1174 - acc: 0.6359\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 35us/sample - loss: 0.9763 - acc: 0.6407\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.8609 - acc: 0.6540\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.7863 - acc: 0.6407\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.7291 - acc: 0.6540\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6963 - acc: 0.6635\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.6613 - acc: 0.6835\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.6974 - acc: 0.6740\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.6208 - acc: 0.7025\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5784 - acc: 0.7262\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 37us/sample - loss: 0.5678 - acc: 0.7205\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5485 - acc: 0.7414\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5340 - acc: 0.7490\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5343 - acc: 0.7500\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5146 - acc: 0.7481\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.6018 - acc: 0.6977\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.5385 - acc: 0.7481\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4993 - acc: 0.7595\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4780 - acc: 0.7719\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.4648 - acc: 0.7909\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4700 - acc: 0.7681\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.4847 - acc: 0.7757\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.4528 - acc: 0.7966\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4480 - acc: 0.7909\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4678 - acc: 0.7605\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4404 - acc: 0.7966\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4384 - acc: 0.7966\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4331 - acc: 0.7994\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4342 - acc: 0.7966\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 43us/sample - loss: 0.4951 - acc: 0.7700\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4352 - acc: 0.7871\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.4127 - acc: 0.8089\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4173 - acc: 0.8118\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.4331 - acc: 0.7947\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4357 - acc: 0.7975\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.4100 - acc: 0.8127\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4382 - acc: 0.8023\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4226 - acc: 0.8004\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4522 - acc: 0.7871\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4081 - acc: 0.8184\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4063 - acc: 0.8213\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4257 - acc: 0.7975\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4115 - acc: 0.8099\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3963 - acc: 0.8203\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4119 - acc: 0.8251\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4065 - acc: 0.8184\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4194 - acc: 0.7975\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4197 - acc: 0.7852\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3918 - acc: 0.8232\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3977 - acc: 0.8317\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4064 - acc: 0.8051\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.3949 - acc: 0.8184\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3956 - acc: 0.8184\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.3992 - acc: 0.8203\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4187 - acc: 0.8061\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3970 - acc: 0.8251\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3818 - acc: 0.8327\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3960 - acc: 0.8051\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4134 - acc: 0.8051\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 35us/sample - loss: 0.4040 - acc: 0.8156\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.3979 - acc: 0.8241\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4069 - acc: 0.8165\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3909 - acc: 0.8175\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4448 - acc: 0.7871\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 34us/sample - loss: 0.4050 - acc: 0.8118\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4049 - acc: 0.8032\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3800 - acc: 0.8260\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4063 - acc: 0.8156\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5237 - acc: 0.7605\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.3983 - acc: 0.8279\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3912 - acc: 0.8298\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3852 - acc: 0.8317\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3856 - acc: 0.8279\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3881 - acc: 0.8327\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3797 - acc: 0.8375\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3795 - acc: 0.8337\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3739 - acc: 0.8413\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3861 - acc: 0.8327\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3884 - acc: 0.8270\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3797 - acc: 0.8308\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3843 - acc: 0.8270\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3807 - acc: 0.8289\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3872 - acc: 0.8137\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3917 - acc: 0.8213\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4254 - acc: 0.8042\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4108 - acc: 0.8137\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4068 - acc: 0.8213\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4444 - acc: 0.7852\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4023 - acc: 0.8146\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3672 - acc: 0.8498\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 34us/sample - loss: 0.3845 - acc: 0.8156\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.3930 - acc: 0.8127\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4072 - acc: 0.8137\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3738 - acc: 0.8422\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.3758 - acc: 0.8432\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3661 - acc: 0.8489\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3807 - acc: 0.8375\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.0091458  1.01670872 1.01101101 1.0072237  1.00667873 0.\n",
      "  0.         1.00848814 0.         1.01066973 1.01670872 1.00881099\n",
      "  1.01101101]]\n",
      "[[ 1.18139648 -0.15155029 -1.          0.36279297  0.30310059  0.\n",
      "   0.          0.66705322  0.         -1.50906982 -0.15155029  0.84844971\n",
      "  -1.        ]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 213us/sample - loss: 6.5604 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 1.5446 - acc: 0.4040\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.7845 - acc: 0.5295\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.6608 - acc: 0.6502\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6207 - acc: 0.6654\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6097 - acc: 0.6806\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5946 - acc: 0.6863\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5798 - acc: 0.6844\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5758 - acc: 0.6911\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5774 - acc: 0.6911\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5840 - acc: 0.6977\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5608 - acc: 0.7015\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5630 - acc: 0.7006\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.5584 - acc: 0.6901\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5698 - acc: 0.7034\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.5439 - acc: 0.7063\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5481 - acc: 0.7120\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5517 - acc: 0.7091\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5421 - acc: 0.7082\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5360 - acc: 0.7158\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5404 - acc: 0.7234\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5341 - acc: 0.7234\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5272 - acc: 0.7281\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5301 - acc: 0.7272\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5332 - acc: 0.7310\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5284 - acc: 0.7186\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5282 - acc: 0.7376\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5216 - acc: 0.7338\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5160 - acc: 0.7338\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 34us/sample - loss: 0.5121 - acc: 0.7424\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5348 - acc: 0.7300\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5287 - acc: 0.7272\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5002 - acc: 0.7386\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4984 - acc: 0.7386\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4904 - acc: 0.7471\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4869 - acc: 0.7443\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4752 - acc: 0.7510\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4697 - acc: 0.7690\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4667 - acc: 0.7719\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4475 - acc: 0.7785\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4443 - acc: 0.7738\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4411 - acc: 0.7757\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4371 - acc: 0.7861\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4696 - acc: 0.7709\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4289 - acc: 0.7909\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4132 - acc: 0.8032\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4175 - acc: 0.8032\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 35us/sample - loss: 0.4007 - acc: 0.8203\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3985 - acc: 0.8213\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4029 - acc: 0.8165\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4491 - acc: 0.7776\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4234 - acc: 0.8099\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3922 - acc: 0.8308\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4243 - acc: 0.7880\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4125 - acc: 0.8004\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3863 - acc: 0.8356\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3986 - acc: 0.8203\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3831 - acc: 0.8346\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 38us/sample - loss: 0.3783 - acc: 0.8384\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3764 - acc: 0.8384\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3721 - acc: 0.8375\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3739 - acc: 0.8479\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3750 - acc: 0.8441\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3793 - acc: 0.8432\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3769 - acc: 0.8279\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3880 - acc: 0.8289\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4054 - acc: 0.8156\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3761 - acc: 0.8346\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3882 - acc: 0.8346\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3766 - acc: 0.8327\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3722 - acc: 0.8403\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3684 - acc: 0.8470\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3629 - acc: 0.8517\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3704 - acc: 0.8451\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3915 - acc: 0.8203\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3778 - acc: 0.8241\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3658 - acc: 0.8422\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3642 - acc: 0.8432\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3651 - acc: 0.8422\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3669 - acc: 0.8432\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3770 - acc: 0.8213\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3684 - acc: 0.8470\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3579 - acc: 0.8498\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3879 - acc: 0.8298\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3747 - acc: 0.8308\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3732 - acc: 0.8298\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3716 - acc: 0.8394\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 37us/sample - loss: 0.3651 - acc: 0.8517\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.3688 - acc: 0.8460\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3674 - acc: 0.8555\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3552 - acc: 0.8555\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3676 - acc: 0.8489\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3678 - acc: 0.8365\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3678 - acc: 0.8546\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3635 - acc: 0.8479\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3560 - acc: 0.8546\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3644 - acc: 0.8432\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3968 - acc: 0.8365\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3685 - acc: 0.8403\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3609 - acc: 0.8536\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01013391 0.         0.         1.0090712  1.0080083  0.\n",
      "  1.00123239 1.01046638 1.00899101 1.00268308 1.01892252 1.00123239\n",
      "  1.00123239]]\n",
      "[[-7.54321289  0.          0.          1.08642578  0.50610352  0.\n",
      "   0.11419678 -2.16662598  1.          0.13703613 -0.11419678  0.11419678\n",
      "   0.11419678]]\n",
      "Class counts:\n",
      " target\n",
      "0    526\n",
      "1    526\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 1052 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_33972\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1052/1052 [==============================] - 0s 204us/sample - loss: 4.3785 - acc: 0.5789\n",
      "Epoch 2/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 1.1021 - acc: 0.5143\n",
      "Epoch 3/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.8315 - acc: 0.5637\n",
      "Epoch 4/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.7628 - acc: 0.5656\n",
      "Epoch 5/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.7276 - acc: 0.5837\n",
      "Epoch 6/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6993 - acc: 0.5998\n",
      "Epoch 7/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.6864 - acc: 0.6055\n",
      "Epoch 8/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6744 - acc: 0.5941\n",
      "Epoch 9/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.6560 - acc: 0.6255\n",
      "Epoch 10/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.6542 - acc: 0.6283\n",
      "Epoch 11/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.6468 - acc: 0.6302\n",
      "Epoch 12/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6311 - acc: 0.6369\n",
      "Epoch 13/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6243 - acc: 0.6312\n",
      "Epoch 14/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6154 - acc: 0.6483\n",
      "Epoch 15/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6105 - acc: 0.6892\n",
      "Epoch 16/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.6089 - acc: 0.6768\n",
      "Epoch 17/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.6033 - acc: 0.6711\n",
      "Epoch 18/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5937 - acc: 0.6711\n",
      "Epoch 19/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.5902 - acc: 0.6854\n",
      "Epoch 20/100\n",
      "1052/1052 [==============================] - 0s 36us/sample - loss: 0.5849 - acc: 0.6797\n",
      "Epoch 21/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.5798 - acc: 0.6863\n",
      "Epoch 22/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5690 - acc: 0.6977\n",
      "Epoch 23/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5671 - acc: 0.6911\n",
      "Epoch 24/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.5704 - acc: 0.6844\n",
      "Epoch 25/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5635 - acc: 0.7063\n",
      "Epoch 26/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.5555 - acc: 0.7101\n",
      "Epoch 27/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5504 - acc: 0.7034\n",
      "Epoch 28/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.5411 - acc: 0.7234\n",
      "Epoch 29/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5395 - acc: 0.7224\n",
      "Epoch 30/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5390 - acc: 0.7253\n",
      "Epoch 31/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5343 - acc: 0.7329\n",
      "Epoch 32/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5176 - acc: 0.7490\n",
      "Epoch 33/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.5130 - acc: 0.7367\n",
      "Epoch 34/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.5149 - acc: 0.7510\n",
      "Epoch 35/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.5022 - acc: 0.7357\n",
      "Epoch 36/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4970 - acc: 0.7500\n",
      "Epoch 37/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4945 - acc: 0.7681\n",
      "Epoch 38/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4968 - acc: 0.7643\n",
      "Epoch 39/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4762 - acc: 0.7690\n",
      "Epoch 40/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4770 - acc: 0.7890\n",
      "Epoch 41/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4727 - acc: 0.7890\n",
      "Epoch 42/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4724 - acc: 0.7719\n",
      "Epoch 43/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.4627 - acc: 0.7814\n",
      "Epoch 44/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4501 - acc: 0.8070\n",
      "Epoch 45/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4453 - acc: 0.7890\n",
      "Epoch 46/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4370 - acc: 0.7975\n",
      "Epoch 47/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4352 - acc: 0.8089\n",
      "Epoch 48/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4293 - acc: 0.8042\n",
      "Epoch 49/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4341 - acc: 0.7937\n",
      "Epoch 50/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.4358 - acc: 0.8089\n",
      "Epoch 51/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4422 - acc: 0.7909\n",
      "Epoch 52/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.4250 - acc: 0.8165\n",
      "Epoch 53/100\n",
      "1052/1052 [==============================] - 0s 34us/sample - loss: 0.4145 - acc: 0.8232\n",
      "Epoch 54/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4170 - acc: 0.8175\n",
      "Epoch 55/100\n",
      "1052/1052 [==============================] - 0s 32us/sample - loss: 0.4189 - acc: 0.8089\n",
      "Epoch 56/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.4015 - acc: 0.8251\n",
      "Epoch 57/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.4114 - acc: 0.8213\n",
      "Epoch 58/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.4083 - acc: 0.8260\n",
      "Epoch 59/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4132 - acc: 0.8232\n",
      "Epoch 60/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3912 - acc: 0.8441\n",
      "Epoch 61/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.4001 - acc: 0.8279\n",
      "Epoch 62/100\n",
      "1052/1052 [==============================] - 0s 33us/sample - loss: 0.3986 - acc: 0.8251\n",
      "Epoch 63/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3852 - acc: 0.8346\n",
      "Epoch 64/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3928 - acc: 0.8384\n",
      "Epoch 65/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3825 - acc: 0.8403\n",
      "Epoch 66/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3985 - acc: 0.8270\n",
      "Epoch 67/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3805 - acc: 0.8317\n",
      "Epoch 68/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3824 - acc: 0.8441\n",
      "Epoch 69/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3801 - acc: 0.8384\n",
      "Epoch 70/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3761 - acc: 0.8422\n",
      "Epoch 71/100\n",
      "1052/1052 [==============================] - 0s 34us/sample - loss: 0.3726 - acc: 0.8413\n",
      "Epoch 72/100\n",
      "1052/1052 [==============================] - 0s 31us/sample - loss: 0.3886 - acc: 0.8298\n",
      "Epoch 73/100\n",
      "1052/1052 [==============================] - 0s 36us/sample - loss: 0.3736 - acc: 0.8413\n",
      "Epoch 74/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3742 - acc: 0.8422\n",
      "Epoch 75/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3726 - acc: 0.8422\n",
      "Epoch 76/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3686 - acc: 0.8432\n",
      "Epoch 77/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3672 - acc: 0.8460\n",
      "Epoch 78/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3835 - acc: 0.8356\n",
      "Epoch 79/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3773 - acc: 0.8317\n",
      "Epoch 80/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3746 - acc: 0.8460\n",
      "Epoch 81/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3856 - acc: 0.8403\n",
      "Epoch 82/100\n",
      "1052/1052 [==============================] - 0s 24us/sample - loss: 0.3707 - acc: 0.8422\n",
      "Epoch 83/100\n",
      "1052/1052 [==============================] - 0s 38us/sample - loss: 0.3736 - acc: 0.8346\n",
      "Epoch 84/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3721 - acc: 0.8375\n",
      "Epoch 85/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3622 - acc: 0.8546\n",
      "Epoch 86/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3639 - acc: 0.8517\n",
      "Epoch 87/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3598 - acc: 0.8489\n",
      "Epoch 88/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3589 - acc: 0.8508\n",
      "Epoch 89/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3704 - acc: 0.8365\n",
      "Epoch 90/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3658 - acc: 0.8479\n",
      "Epoch 91/100\n",
      "1052/1052 [==============================] - 0s 29us/sample - loss: 0.3679 - acc: 0.8413\n",
      "Epoch 92/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3724 - acc: 0.8403\n",
      "Epoch 93/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3569 - acc: 0.8517\n",
      "Epoch 94/100\n",
      "1052/1052 [==============================] - 0s 27us/sample - loss: 0.3528 - acc: 0.8498\n",
      "Epoch 95/100\n",
      "1052/1052 [==============================] - 0s 30us/sample - loss: 0.3740 - acc: 0.8432\n",
      "Epoch 96/100\n",
      "1052/1052 [==============================] - 0s 25us/sample - loss: 0.3863 - acc: 0.8337\n",
      "Epoch 97/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3576 - acc: 0.8498\n",
      "Epoch 98/100\n",
      "1052/1052 [==============================] - 0s 26us/sample - loss: 0.3508 - acc: 0.8517\n",
      "Epoch 99/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3527 - acc: 0.8508\n",
      "Epoch 100/100\n",
      "1052/1052 [==============================] - 0s 28us/sample - loss: 0.3549 - acc: 0.8489\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 13)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00978586 0.         1.00853913 1.0098116  1.01019742 1.00853913\n",
      "  1.00853913 1.00611861 1.01146511 1.01043576 1.00853913 1.00891385\n",
      "  1.00899101]]\n",
      "[[ 4.71557617  0.          0.69036865  5.36004639 -5.11700439  0.69036865\n",
      "   0.69036865  0.25921631 -0.69036865 -2.31881104  0.69036865  0.92889404\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimal_dists, wachter_dists = [], []\n",
    "optimal_probs,  wachter_probs = [], [] \n",
    "sub_dataset = heart_disease[heart_disease['target'] == 1]\n",
    "random_integers = random.sample(range(0, sub_dataset.shape[0]-1), 50)\n",
    "\n",
    "for i in random_integers:\n",
    "        try:\n",
    "            real_idx = sub_dataset.index[i]\n",
    "            X_point = heart_disease.iloc[real_idx,:-1]\n",
    "            nn=nn_model()\n",
    "\n",
    "            nn, optimal_datapt = optimal_point(heart_disease, nn, desired_class=1, original_class=0, threshold=10000, chosen_row=real_idx, point_epsilon=1e-3, epsilon=1e-2)\n",
    "\n",
    "            target_class=1\n",
    "            explainer2 = Counterfactual(nn, shape=shape, target_proba=target_proba, tol=tol,\n",
    "                                    target_class=target_class)\n",
    "            #print(np.reshape(X_point, (1,-1)).shape)\n",
    "            cf = explainer2.explain(np.reshape(X_point, (1,-1)))\n",
    "            cf_point = cf.data['cf']['X'] \n",
    "            cf_pt_probs = nn.predict(cf_point)\n",
    "            opt_pt_probs = nn.predict(optimal_datapt)\n",
    "            optimal_probs.append(opt_pt_probs)\n",
    "            wachter_probs.append(cf_pt_probs)\n",
    "            optimal_dists.append(euclidean_distance(X_point, optimal_datapt))\n",
    "            wachter_dists.append(euclidean_distance(X_point, cf_point))\n",
    "        except TypeError: \n",
    "              continue\n",
    "\n",
    "    # print(cf_point)\n",
    "    # print(income_nn.predict(np.reshape(X_point, (1,-1))))\n",
    "    # print(\"DISTANCE:\", euclidean_distance(X_point, cf_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e2471a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(optimal_dists)),print(len(wachter_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b6a6aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.205593716876526 1.2972854974584487\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(optimal_dists), np.mean(wachter_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae484c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.50873667, 0.49126333]], dtype=float32), array([[0.50789434, 0.49210566]], dtype=float32), array([[0.5065979 , 0.49340215]], dtype=float32), array([[0.50514966, 0.49485034]], dtype=float32), array([[0.5046538 , 0.49534622]], dtype=float32), array([[0.50450695, 0.49549305]], dtype=float32), array([[0.505019, 0.494981]], dtype=float32), array([[0.5045947 , 0.49540532]], dtype=float32), array([[0.5022173 , 0.49778274]], dtype=float32), array([[0.50331074, 0.49668926]], dtype=float32), array([[0.49597177, 0.50402826]], dtype=float32), array([[0.5023011 , 0.49769893]], dtype=float32), array([[0.5051381, 0.4948619]], dtype=float32), array([[0.5071063, 0.4928937]], dtype=float32), array([[0.50537264, 0.4946273 ]], dtype=float32), array([[0.5041484 , 0.49585164]], dtype=float32), array([[0.49912834, 0.50087166]], dtype=float32), array([[0.50861186, 0.49138805]], dtype=float32), array([[0.50651205, 0.49348795]], dtype=float32), array([[0.504751 , 0.4952489]], dtype=float32), array([[0.49764684, 0.5023532 ]], dtype=float32), array([[0.5049893 , 0.49501064]], dtype=float32), array([[0.5027571, 0.497243 ]], dtype=float32), array([[0.50330687, 0.49669322]], dtype=float32), array([[0.5060981, 0.4939019]], dtype=float32), array([[0.49948755, 0.5005124 ]], dtype=float32), array([[0.50607556, 0.49392444]], dtype=float32), array([[0.50665057, 0.49334952]], dtype=float32), array([[0.5070572 , 0.49294278]], dtype=float32), array([[0.50514776, 0.49485227]], dtype=float32), array([[0.50530845, 0.4946916 ]], dtype=float32), array([[0.50459945, 0.49540058]], dtype=float32), array([[0.5058825, 0.4941176]], dtype=float32), array([[0.5035575, 0.4964425]], dtype=float32), array([[0.500494, 0.499506]], dtype=float32), array([[0.5048893 , 0.49511066]], dtype=float32), array([[0.5025633 , 0.49743664]], dtype=float32), array([[0.49886703, 0.50113297]], dtype=float32), array([[0.4991696, 0.5008304]], dtype=float32), array([[0.5031729, 0.4968272]], dtype=float32), array([[0.49551642, 0.5044836 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(optimal_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d74558ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.4999206, 0.5000794]], dtype=float32), array([[0.500005, 0.499995]], dtype=float32), array([[0.49995852, 0.5000415 ]], dtype=float32), array([[0.49990177, 0.5000982 ]], dtype=float32), array([[0.50006676, 0.49993324]], dtype=float32), array([[0.50009346, 0.49990654]], dtype=float32), array([[0.49996853, 0.5000315 ]], dtype=float32), array([[0.5000038, 0.4999962]], dtype=float32), array([[0.500041, 0.499959]], dtype=float32), array([[0.49998748, 0.5000125 ]], dtype=float32), array([[0.49993992, 0.5000601 ]], dtype=float32), array([[0.49993122, 0.5000688 ]], dtype=float32), array([[0.50009644, 0.49990356]], dtype=float32), array([[0.4999647, 0.5000353]], dtype=float32), array([[0.49993265, 0.5000673 ]], dtype=float32), array([[0.49992085, 0.50007915]], dtype=float32), array([[0.4999441, 0.5000559]], dtype=float32), array([[0.4999175, 0.5000825]], dtype=float32), array([[0.5000491, 0.4999509]], dtype=float32), array([[0.49990082, 0.5000992 ]], dtype=float32), array([[0.4999566, 0.5000434]], dtype=float32), array([[0.49997926, 0.50002074]], dtype=float32), array([[0.49999046, 0.50000954]], dtype=float32), array([[0.49999857, 0.50000143]], dtype=float32), array([[0.4999112, 0.5000888]], dtype=float32), array([[0.5000925, 0.4999075]], dtype=float32), array([[0.49993038, 0.5000696 ]], dtype=float32), array([[0.4999733, 0.5000267]], dtype=float32), array([[0.49997807, 0.50002193]], dtype=float32), array([[0.49998474, 0.50001526]], dtype=float32), array([[0.50009346, 0.49990654]], dtype=float32), array([[0.50002   , 0.49997997]], dtype=float32), array([[0.49992037, 0.50007963]], dtype=float32), array([[0.49990308, 0.5000969 ]], dtype=float32), array([[0.5000143, 0.4999857]], dtype=float32), array([[0.49990845, 0.50009155]], dtype=float32), array([[0.4999014, 0.5000986]], dtype=float32), array([[0.49992466, 0.50007534]], dtype=float32), array([[0.49999523, 0.50000477]], dtype=float32), array([[0.50005865, 0.49994135]], dtype=float32), array([[0.5000433 , 0.49995673]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(wachter_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b2a9948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    x_in = Input(shape=(10,))\n",
    "\n",
    "    x = Flatten()(x_in)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = Dense(10, activation='relu')(x) \n",
    "    probs = Dense(2, activation='softmax')(x)\n",
    "    nn = Model(inputs=x_in, outputs=probs)\n",
    "    nn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1af6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1742\n",
      "Class counts:\n",
      " y\n",
      "1    1005\n",
      "0    1005\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 2010 samples\n",
      "Epoch 1/100\n",
      "2010/2010 [==============================] - 0s 25us/sample - loss: 0.8285 - acc: 0.4851\n",
      "Epoch 2/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.6761 - acc: 0.5886\n",
      "Epoch 3/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.5944 - acc: 0.7075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_27540\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.4971 - acc: 0.8020\n",
      "Epoch 5/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.4071 - acc: 0.8522\n",
      "Epoch 6/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.3459 - acc: 0.8731\n",
      "Epoch 7/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3067 - acc: 0.8826\n",
      "Epoch 8/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2787 - acc: 0.8965\n",
      "Epoch 9/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.2552 - acc: 0.9055\n",
      "Epoch 10/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2351 - acc: 0.9129\n",
      "Epoch 11/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2177 - acc: 0.9174\n",
      "Epoch 12/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2032 - acc: 0.9194\n",
      "Epoch 13/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1909 - acc: 0.9254\n",
      "Epoch 14/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1815 - acc: 0.9313\n",
      "Epoch 15/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1729 - acc: 0.9333\n",
      "Epoch 16/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1662 - acc: 0.9363\n",
      "Epoch 17/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1608 - acc: 0.9408\n",
      "Epoch 18/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1556 - acc: 0.9448\n",
      "Epoch 19/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1517 - acc: 0.9428\n",
      "Epoch 20/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1473 - acc: 0.9473\n",
      "Epoch 21/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1432 - acc: 0.9512\n",
      "Epoch 22/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1397 - acc: 0.9507\n",
      "Epoch 23/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1367 - acc: 0.9527\n",
      "Epoch 24/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1345 - acc: 0.9522\n",
      "Epoch 25/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1306 - acc: 0.9522\n",
      "Epoch 26/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1286 - acc: 0.9532\n",
      "Epoch 27/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1261 - acc: 0.9532\n",
      "Epoch 28/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1237 - acc: 0.9557\n",
      "Epoch 29/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1215 - acc: 0.9567\n",
      "Epoch 30/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1199 - acc: 0.9567\n",
      "Epoch 31/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1181 - acc: 0.9572\n",
      "Epoch 32/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1169 - acc: 0.9547\n",
      "Epoch 33/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1148 - acc: 0.9587\n",
      "Epoch 34/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1130 - acc: 0.9592\n",
      "Epoch 35/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1121 - acc: 0.9597\n",
      "Epoch 36/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1110 - acc: 0.9572\n",
      "Epoch 37/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1104 - acc: 0.9592\n",
      "Epoch 38/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1092 - acc: 0.9587\n",
      "Epoch 39/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1077 - acc: 0.9602\n",
      "Epoch 40/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1079 - acc: 0.9582\n",
      "Epoch 41/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1047 - acc: 0.9592\n",
      "Epoch 42/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1044 - acc: 0.9592\n",
      "Epoch 43/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1030 - acc: 0.9622\n",
      "Epoch 44/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1015 - acc: 0.9622\n",
      "Epoch 45/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1012 - acc: 0.9612\n",
      "Epoch 46/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0998 - acc: 0.9622\n",
      "Epoch 47/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0988 - acc: 0.9627\n",
      "Epoch 48/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0976 - acc: 0.9612\n",
      "Epoch 49/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0963 - acc: 0.9632\n",
      "Epoch 50/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0958 - acc: 0.9622\n",
      "Epoch 51/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0954 - acc: 0.9637\n",
      "Epoch 52/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0937 - acc: 0.9622\n",
      "Epoch 53/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0941 - acc: 0.9622\n",
      "Epoch 54/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0925 - acc: 0.9642\n",
      "Epoch 55/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0914 - acc: 0.9632\n",
      "Epoch 56/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0906 - acc: 0.9652\n",
      "Epoch 57/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0916 - acc: 0.9632\n",
      "Epoch 58/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0898 - acc: 0.9642\n",
      "Epoch 59/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0885 - acc: 0.9667\n",
      "Epoch 60/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0877 - acc: 0.9662\n",
      "Epoch 61/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0869 - acc: 0.9677\n",
      "Epoch 62/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0861 - acc: 0.9667\n",
      "Epoch 63/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0860 - acc: 0.9672\n",
      "Epoch 64/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0850 - acc: 0.9662\n",
      "Epoch 65/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0847 - acc: 0.9652\n",
      "Epoch 66/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0847 - acc: 0.9692\n",
      "Epoch 67/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0840 - acc: 0.9692\n",
      "Epoch 68/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0824 - acc: 0.9672\n",
      "Epoch 69/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0819 - acc: 0.9682\n",
      "Epoch 70/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0816 - acc: 0.9662\n",
      "Epoch 71/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0809 - acc: 0.9687\n",
      "Epoch 72/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0806 - acc: 0.9692\n",
      "Epoch 73/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0803 - acc: 0.9667\n",
      "Epoch 74/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0795 - acc: 0.9672\n",
      "Epoch 75/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0783 - acc: 0.9672\n",
      "Epoch 76/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0779 - acc: 0.9692\n",
      "Epoch 77/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0771 - acc: 0.9677\n",
      "Epoch 78/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0768 - acc: 0.9697\n",
      "Epoch 79/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0753 - acc: 0.9706\n",
      "Epoch 80/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0744 - acc: 0.9711\n",
      "Epoch 81/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0740 - acc: 0.9706\n",
      "Epoch 82/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0747 - acc: 0.9697\n",
      "Epoch 83/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0738 - acc: 0.9706\n",
      "Epoch 84/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0728 - acc: 0.9721\n",
      "Epoch 85/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0720 - acc: 0.9716\n",
      "Epoch 86/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0719 - acc: 0.9711\n",
      "Epoch 87/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0710 - acc: 0.9721\n",
      "Epoch 88/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0702 - acc: 0.9711\n",
      "Epoch 89/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0696 - acc: 0.9736\n",
      "Epoch 90/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0696 - acc: 0.9721\n",
      "Epoch 91/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0689 - acc: 0.9736\n",
      "Epoch 92/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0684 - acc: 0.9731\n",
      "Epoch 93/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0680 - acc: 0.9731\n",
      "Epoch 94/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0668 - acc: 0.9746\n",
      "Epoch 95/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0663 - acc: 0.9746\n",
      "Epoch 96/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0667 - acc: 0.9721\n",
      "Epoch 97/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0663 - acc: 0.9736\n",
      "Epoch 98/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0650 - acc: 0.9741\n",
      "Epoch 99/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0650 - acc: 0.9741\n",
      "Epoch 100/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0639 - acc: 0.9746\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 10)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00014918 0.99517278 0.96155096 1.00956563 0.98725723 1.00912162\n",
      "  1.02035642 1.00975636 1.01053628 1.01177967]]\n",
      "[[ 0.10152957  0.06711795  0.01984665  2.32422763  0.04340971  1.14884743\n",
      "  -0.09852405  4.14445371 -1.88435666 -0.56852188]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No appropriate lambda range found, try decreasing lam_init\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n",
      "Class counts:\n",
      " y\n",
      "1    1005\n",
      "0    1005\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 2010 samples\n",
      "Epoch 1/100\n",
      "2010/2010 [==============================] - 0s 25us/sample - loss: 0.8123 - acc: 0.5920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_27540\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.5858 - acc: 0.6985\n",
      "Epoch 3/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.4789 - acc: 0.7821\n",
      "Epoch 4/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.4030 - acc: 0.8289\n",
      "Epoch 5/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.3492 - acc: 0.8488\n",
      "Epoch 6/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3129 - acc: 0.8652\n",
      "Epoch 7/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.2849 - acc: 0.8786\n",
      "Epoch 8/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.2647 - acc: 0.8905\n",
      "Epoch 9/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2474 - acc: 0.8955\n",
      "Epoch 10/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2337 - acc: 0.9035\n",
      "Epoch 11/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2215 - acc: 0.9114\n",
      "Epoch 12/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2110 - acc: 0.9164\n",
      "Epoch 13/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2018 - acc: 0.9239\n",
      "Epoch 14/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1949 - acc: 0.9274\n",
      "Epoch 15/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1884 - acc: 0.9303\n",
      "Epoch 16/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1826 - acc: 0.9328\n",
      "Epoch 17/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1778 - acc: 0.9343\n",
      "Epoch 18/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1727 - acc: 0.9353\n",
      "Epoch 19/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1683 - acc: 0.9343\n",
      "Epoch 20/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1643 - acc: 0.9373\n",
      "Epoch 21/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1612 - acc: 0.9383\n",
      "Epoch 22/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1579 - acc: 0.9403\n",
      "Epoch 23/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1554 - acc: 0.9408\n",
      "Epoch 24/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1524 - acc: 0.9403\n",
      "Epoch 25/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1496 - acc: 0.9418\n",
      "Epoch 26/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1481 - acc: 0.9413\n",
      "Epoch 27/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1452 - acc: 0.9438\n",
      "Epoch 28/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1423 - acc: 0.9448\n",
      "Epoch 29/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1403 - acc: 0.9473\n",
      "Epoch 30/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1383 - acc: 0.9458\n",
      "Epoch 31/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1371 - acc: 0.9478\n",
      "Epoch 32/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1347 - acc: 0.9488\n",
      "Epoch 33/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1336 - acc: 0.9512\n",
      "Epoch 34/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1306 - acc: 0.9483\n",
      "Epoch 35/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1292 - acc: 0.9493\n",
      "Epoch 36/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1274 - acc: 0.9502\n",
      "Epoch 37/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1262 - acc: 0.9512\n",
      "Epoch 38/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1245 - acc: 0.9502\n",
      "Epoch 39/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1238 - acc: 0.9498\n",
      "Epoch 40/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1220 - acc: 0.9512\n",
      "Epoch 41/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1209 - acc: 0.9527\n",
      "Epoch 42/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1200 - acc: 0.9512\n",
      "Epoch 43/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1183 - acc: 0.9517\n",
      "Epoch 44/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1178 - acc: 0.9537\n",
      "Epoch 45/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1163 - acc: 0.9552\n",
      "Epoch 46/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1154 - acc: 0.9532\n",
      "Epoch 47/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1142 - acc: 0.9567\n",
      "Epoch 48/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1132 - acc: 0.9552\n",
      "Epoch 49/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1126 - acc: 0.9567\n",
      "Epoch 50/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1120 - acc: 0.9562\n",
      "Epoch 51/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1108 - acc: 0.9577\n",
      "Epoch 52/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1099 - acc: 0.9562\n",
      "Epoch 53/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1094 - acc: 0.9572\n",
      "Epoch 54/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1083 - acc: 0.9577\n",
      "Epoch 55/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1070 - acc: 0.9602\n",
      "Epoch 56/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1068 - acc: 0.9592\n",
      "Epoch 57/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1057 - acc: 0.9607\n",
      "Epoch 58/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1047 - acc: 0.9582\n",
      "Epoch 59/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1044 - acc: 0.9612\n",
      "Epoch 60/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1037 - acc: 0.9612\n",
      "Epoch 61/100\n",
      "2010/2010 [==============================] - 0s 17us/sample - loss: 0.1030 - acc: 0.9612\n",
      "Epoch 62/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1028 - acc: 0.9622\n",
      "Epoch 63/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1020 - acc: 0.9607\n",
      "Epoch 64/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1008 - acc: 0.9617\n",
      "Epoch 65/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1002 - acc: 0.9622\n",
      "Epoch 66/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0993 - acc: 0.9617\n",
      "Epoch 67/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.0984 - acc: 0.9652\n",
      "Epoch 68/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0976 - acc: 0.9627\n",
      "Epoch 69/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0978 - acc: 0.9637\n",
      "Epoch 70/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0970 - acc: 0.9642\n",
      "Epoch 71/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0958 - acc: 0.9632\n",
      "Epoch 72/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0952 - acc: 0.9642\n",
      "Epoch 73/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0955 - acc: 0.9652\n",
      "Epoch 74/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0939 - acc: 0.9652\n",
      "Epoch 75/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0926 - acc: 0.9652\n",
      "Epoch 76/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0929 - acc: 0.9652\n",
      "Epoch 77/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0923 - acc: 0.9647\n",
      "Epoch 78/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0907 - acc: 0.9652\n",
      "Epoch 79/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0901 - acc: 0.9677\n",
      "Epoch 80/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.0893 - acc: 0.9652\n",
      "Epoch 81/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0890 - acc: 0.9672\n",
      "Epoch 82/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0891 - acc: 0.9647\n",
      "Epoch 83/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0887 - acc: 0.9672\n",
      "Epoch 84/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0876 - acc: 0.9677\n",
      "Epoch 85/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0860 - acc: 0.9692\n",
      "Epoch 86/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0860 - acc: 0.9667\n",
      "Epoch 87/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0852 - acc: 0.9662\n",
      "Epoch 88/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0842 - acc: 0.9677\n",
      "Epoch 89/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0834 - acc: 0.9692\n",
      "Epoch 90/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0826 - acc: 0.9692\n",
      "Epoch 91/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0822 - acc: 0.9692\n",
      "Epoch 92/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0813 - acc: 0.9682\n",
      "Epoch 93/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0806 - acc: 0.9687\n",
      "Epoch 94/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0800 - acc: 0.9711\n",
      "Epoch 95/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0794 - acc: 0.9682\n",
      "Epoch 96/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0786 - acc: 0.9706\n",
      "Epoch 97/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0773 - acc: 0.9716\n",
      "Epoch 98/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0775 - acc: 0.9716\n",
      "Epoch 99/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0756 - acc: 0.9716\n",
      "Epoch 100/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0749 - acc: 0.9721\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 10)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01143916 1.00753587 1.0071147  1.01976551 1.01065279 1.01644547\n",
      "  1.0145389  1.00475361 1.00901248 1.01102255]]\n",
      "[[-0.70279621  0.40888137  0.34905077 -0.10442521 -1.54821387 -0.15769911\n",
      "  -0.22352105  0.19151341  1.02176115 -0.98873151]]\n",
      "1524\n",
      "Class counts:\n",
      " y\n",
      "1    1005\n",
      "0    1005\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 2010 samples\n",
      "Epoch 1/100\n",
      "2010/2010 [==============================] - 0s 25us/sample - loss: 0.5970 - acc: 0.6209\n",
      "Epoch 2/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.5287 - acc: 0.7060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_27540\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.4717 - acc: 0.8005\n",
      "Epoch 4/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.4080 - acc: 0.8373\n",
      "Epoch 5/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.3520 - acc: 0.8597\n",
      "Epoch 6/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.3111 - acc: 0.8761\n",
      "Epoch 7/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2867 - acc: 0.8776\n",
      "Epoch 8/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2690 - acc: 0.8841\n",
      "Epoch 9/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2545 - acc: 0.8930\n",
      "Epoch 10/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2431 - acc: 0.9000\n",
      "Epoch 11/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2318 - acc: 0.9080\n",
      "Epoch 12/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2236 - acc: 0.9139\n",
      "Epoch 13/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2159 - acc: 0.9149\n",
      "Epoch 14/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2088 - acc: 0.9179\n",
      "Epoch 15/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.2029 - acc: 0.9224\n",
      "Epoch 16/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1972 - acc: 0.9289\n",
      "Epoch 17/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1930 - acc: 0.9294\n",
      "Epoch 18/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1874 - acc: 0.9308\n",
      "Epoch 19/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1840 - acc: 0.9294\n",
      "Epoch 20/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1805 - acc: 0.9323\n",
      "Epoch 21/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1766 - acc: 0.9333\n",
      "Epoch 22/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1757 - acc: 0.9294\n",
      "Epoch 23/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1719 - acc: 0.9333\n",
      "Epoch 24/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1707 - acc: 0.9313\n",
      "Epoch 25/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1686 - acc: 0.9308\n",
      "Epoch 26/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1652 - acc: 0.9308\n",
      "Epoch 27/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1635 - acc: 0.9343\n",
      "Epoch 28/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1612 - acc: 0.9333\n",
      "Epoch 29/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1587 - acc: 0.9368\n",
      "Epoch 30/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1576 - acc: 0.9338\n",
      "Epoch 31/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1548 - acc: 0.9393\n",
      "Epoch 32/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1518 - acc: 0.9398\n",
      "Epoch 33/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1498 - acc: 0.9378\n",
      "Epoch 34/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1481 - acc: 0.9428\n",
      "Epoch 35/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1455 - acc: 0.9423\n",
      "Epoch 36/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1438 - acc: 0.9433\n",
      "Epoch 37/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1414 - acc: 0.9453\n",
      "Epoch 38/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1401 - acc: 0.9418\n",
      "Epoch 39/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1387 - acc: 0.9473\n",
      "Epoch 40/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1362 - acc: 0.9488\n",
      "Epoch 41/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1345 - acc: 0.9453\n",
      "Epoch 42/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1317 - acc: 0.9478\n",
      "Epoch 43/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1310 - acc: 0.9478\n",
      "Epoch 44/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1293 - acc: 0.9493\n",
      "Epoch 45/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1276 - acc: 0.9483\n",
      "Epoch 46/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1264 - acc: 0.9507\n",
      "Epoch 47/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1243 - acc: 0.9488\n",
      "Epoch 48/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1244 - acc: 0.9517\n",
      "Epoch 49/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1217 - acc: 0.9517\n",
      "Epoch 50/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1200 - acc: 0.9527\n",
      "Epoch 51/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1193 - acc: 0.9532\n",
      "Epoch 52/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1183 - acc: 0.9547\n",
      "Epoch 53/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1175 - acc: 0.9542\n",
      "Epoch 54/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1154 - acc: 0.9577\n",
      "Epoch 55/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1147 - acc: 0.9547\n",
      "Epoch 56/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1136 - acc: 0.9592\n",
      "Epoch 57/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1123 - acc: 0.9562\n",
      "Epoch 58/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1117 - acc: 0.9552\n",
      "Epoch 59/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1110 - acc: 0.9552\n",
      "Epoch 60/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1107 - acc: 0.9572\n",
      "Epoch 61/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1088 - acc: 0.9592\n",
      "Epoch 62/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1082 - acc: 0.9567\n",
      "Epoch 63/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1063 - acc: 0.9597\n",
      "Epoch 64/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1057 - acc: 0.9567\n",
      "Epoch 65/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1048 - acc: 0.9612\n",
      "Epoch 66/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1036 - acc: 0.9597\n",
      "Epoch 67/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1026 - acc: 0.9597\n",
      "Epoch 68/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1014 - acc: 0.9597\n",
      "Epoch 69/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1007 - acc: 0.9587\n",
      "Epoch 70/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1002 - acc: 0.9597\n",
      "Epoch 71/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0985 - acc: 0.9597\n",
      "Epoch 72/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0967 - acc: 0.9627\n",
      "Epoch 73/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0961 - acc: 0.9622\n",
      "Epoch 74/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0955 - acc: 0.9617\n",
      "Epoch 75/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0940 - acc: 0.9647\n",
      "Epoch 76/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0926 - acc: 0.9662\n",
      "Epoch 77/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0919 - acc: 0.9642\n",
      "Epoch 78/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0908 - acc: 0.9657\n",
      "Epoch 79/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0901 - acc: 0.9657\n",
      "Epoch 80/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0888 - acc: 0.9667\n",
      "Epoch 81/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0877 - acc: 0.9687\n",
      "Epoch 82/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0861 - acc: 0.9662\n",
      "Epoch 83/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0855 - acc: 0.9677\n",
      "Epoch 84/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0848 - acc: 0.9692\n",
      "Epoch 85/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0844 - acc: 0.9701\n",
      "Epoch 86/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0836 - acc: 0.9682\n",
      "Epoch 87/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0832 - acc: 0.9687\n",
      "Epoch 88/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0818 - acc: 0.9721\n",
      "Epoch 89/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0810 - acc: 0.9716\n",
      "Epoch 90/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0806 - acc: 0.9731\n",
      "Epoch 91/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0808 - acc: 0.9706\n",
      "Epoch 92/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0794 - acc: 0.9706\n",
      "Epoch 93/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0799 - acc: 0.9711\n",
      "Epoch 94/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0778 - acc: 0.9726\n",
      "Epoch 95/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0776 - acc: 0.9731\n",
      "Epoch 96/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0771 - acc: 0.9736\n",
      "Epoch 97/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0766 - acc: 0.9736\n",
      "Epoch 98/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0752 - acc: 0.9761\n",
      "Epoch 99/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0749 - acc: 0.9756\n",
      "Epoch 100/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0746 - acc: 0.9741\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 10)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01047172 0.89482517 1.0117536  1.00903415 1.01057966 1.02234564\n",
      "  1.01055643 0.98679417 1.00133457 1.01125221]]\n",
      "[[-2.1420913   0.00776928 -0.57695742  1.04470734 -1.74340766 -0.08281029\n",
      "  -1.81615854  0.04252354  0.11555506 -0.80757628]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No appropriate lambda range found, try decreasing lam_init\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n",
      "Class counts:\n",
      " y\n",
      "1    1005\n",
      "0    1005\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 2010 samples\n",
      "Epoch 1/100\n",
      "  32/2010 [..............................] - ETA: 1s - loss: 0.8529 - acc: 0.5312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_27540\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010/2010 [==============================] - 0s 26us/sample - loss: 0.7879 - acc: 0.5701\n",
      "Epoch 2/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.6110 - acc: 0.6667\n",
      "Epoch 3/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.5346 - acc: 0.7488\n",
      "Epoch 4/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.4779 - acc: 0.7960\n",
      "Epoch 5/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.4228 - acc: 0.8328\n",
      "Epoch 6/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3678 - acc: 0.8607\n",
      "Epoch 7/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3235 - acc: 0.8706\n",
      "Epoch 8/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2888 - acc: 0.8950\n",
      "Epoch 9/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2641 - acc: 0.9055\n",
      "Epoch 10/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2454 - acc: 0.9119\n",
      "Epoch 11/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2315 - acc: 0.9179\n",
      "Epoch 12/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.2196 - acc: 0.9199\n",
      "Epoch 13/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2087 - acc: 0.9274\n",
      "Epoch 14/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2010 - acc: 0.9234\n",
      "Epoch 15/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1928 - acc: 0.9303\n",
      "Epoch 16/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1851 - acc: 0.9328\n",
      "Epoch 17/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1800 - acc: 0.9348\n",
      "Epoch 18/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1746 - acc: 0.9348\n",
      "Epoch 19/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1701 - acc: 0.9388\n",
      "Epoch 20/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1655 - acc: 0.9388\n",
      "Epoch 21/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1619 - acc: 0.9403\n",
      "Epoch 22/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1577 - acc: 0.9388\n",
      "Epoch 23/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1545 - acc: 0.9433\n",
      "Epoch 24/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1519 - acc: 0.9428\n",
      "Epoch 25/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1484 - acc: 0.9438\n",
      "Epoch 26/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1454 - acc: 0.9443\n",
      "Epoch 27/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1426 - acc: 0.9448\n",
      "Epoch 28/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1398 - acc: 0.9458\n",
      "Epoch 29/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1386 - acc: 0.9493\n",
      "Epoch 30/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1356 - acc: 0.9478\n",
      "Epoch 31/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1334 - acc: 0.9502\n",
      "Epoch 32/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1315 - acc: 0.9562\n",
      "Epoch 33/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1293 - acc: 0.9557\n",
      "Epoch 34/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1283 - acc: 0.9562\n",
      "Epoch 35/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1263 - acc: 0.9547\n",
      "Epoch 36/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1242 - acc: 0.9577\n",
      "Epoch 37/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1221 - acc: 0.9592\n",
      "Epoch 38/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1221 - acc: 0.9587\n",
      "Epoch 39/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1192 - acc: 0.9597\n",
      "Epoch 40/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1179 - acc: 0.9597\n",
      "Epoch 41/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1168 - acc: 0.9602\n",
      "Epoch 42/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1161 - acc: 0.9617\n",
      "Epoch 43/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1142 - acc: 0.9637\n",
      "Epoch 44/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1132 - acc: 0.9567\n",
      "Epoch 45/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1119 - acc: 0.9612\n",
      "Epoch 46/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1101 - acc: 0.9652\n",
      "Epoch 47/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1095 - acc: 0.9632\n",
      "Epoch 48/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1076 - acc: 0.9667\n",
      "Epoch 49/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1060 - acc: 0.9677\n",
      "Epoch 50/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1052 - acc: 0.9687\n",
      "Epoch 51/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1041 - acc: 0.9682\n",
      "Epoch 52/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1033 - acc: 0.9692\n",
      "Epoch 53/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1016 - acc: 0.9706\n",
      "Epoch 54/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1008 - acc: 0.9701\n",
      "Epoch 55/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1002 - acc: 0.9682\n",
      "Epoch 56/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0985 - acc: 0.9701\n",
      "Epoch 57/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0978 - acc: 0.9687\n",
      "Epoch 58/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0966 - acc: 0.9697\n",
      "Epoch 59/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0960 - acc: 0.9687\n",
      "Epoch 60/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0947 - acc: 0.9706\n",
      "Epoch 61/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0933 - acc: 0.9711\n",
      "Epoch 62/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0932 - acc: 0.9716\n",
      "Epoch 63/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0920 - acc: 0.9726\n",
      "Epoch 64/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0910 - acc: 0.9731\n",
      "Epoch 65/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0905 - acc: 0.9741\n",
      "Epoch 66/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0890 - acc: 0.9746\n",
      "Epoch 67/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0886 - acc: 0.9741\n",
      "Epoch 68/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0878 - acc: 0.9766\n",
      "Epoch 69/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0873 - acc: 0.9746\n",
      "Epoch 70/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0870 - acc: 0.9776\n",
      "Epoch 71/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0858 - acc: 0.9761\n",
      "Epoch 72/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0845 - acc: 0.9776\n",
      "Epoch 73/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0851 - acc: 0.9721\n",
      "Epoch 74/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0834 - acc: 0.9771\n",
      "Epoch 75/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0830 - acc: 0.9771\n",
      "Epoch 76/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0826 - acc: 0.9781\n",
      "Epoch 77/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0816 - acc: 0.9771\n",
      "Epoch 78/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0812 - acc: 0.9781\n",
      "Epoch 79/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0809 - acc: 0.9786\n",
      "Epoch 80/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0808 - acc: 0.9766\n",
      "Epoch 81/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0796 - acc: 0.9776\n",
      "Epoch 82/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0793 - acc: 0.9781\n",
      "Epoch 83/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0779 - acc: 0.9791\n",
      "Epoch 84/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0777 - acc: 0.9791\n",
      "Epoch 85/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0766 - acc: 0.9781\n",
      "Epoch 86/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0760 - acc: 0.9801\n",
      "Epoch 87/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0759 - acc: 0.9781\n",
      "Epoch 88/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0759 - acc: 0.9791\n",
      "Epoch 89/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0754 - acc: 0.9776\n",
      "Epoch 90/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0746 - acc: 0.9816\n",
      "Epoch 91/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0738 - acc: 0.9811\n",
      "Epoch 92/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0740 - acc: 0.9801\n",
      "Epoch 93/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0731 - acc: 0.9791\n",
      "Epoch 94/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0719 - acc: 0.9821\n",
      "Epoch 95/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0713 - acc: 0.9801\n",
      "Epoch 96/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0715 - acc: 0.9796\n",
      "Epoch 97/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0714 - acc: 0.9806\n",
      "Epoch 98/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0705 - acc: 0.9816\n",
      "Epoch 99/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0697 - acc: 0.9801\n",
      "Epoch 100/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0692 - acc: 0.9821\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 10)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01136372 1.00949321 1.0035892  1.00901806 1.01230825 1.00889485\n",
      "  1.01095762 1.00896515 1.00949672 1.01103753]]\n",
      "[[-0.74162104  1.99194846  0.15654668  1.02758008 -0.43856078  0.91290348\n",
      "  -1.05569944  0.97498294  2.00584295 -0.97446914]]\n",
      "787\n",
      "Class counts:\n",
      " y\n",
      "1    1005\n",
      "0    1005\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 2010 samples\n",
      "Epoch 1/100\n",
      "2010/2010 [==============================] - 0s 25us/sample - loss: 0.8561 - acc: 0.5224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_27540\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.6492 - acc: 0.6030\n",
      "Epoch 3/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.5618 - acc: 0.6841\n",
      "Epoch 4/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.5023 - acc: 0.7408\n",
      "Epoch 5/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.4468 - acc: 0.7915\n",
      "Epoch 6/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3920 - acc: 0.8333\n",
      "Epoch 7/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3425 - acc: 0.8592\n",
      "Epoch 8/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3003 - acc: 0.8806\n",
      "Epoch 9/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2659 - acc: 0.9005\n",
      "Epoch 10/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.2385 - acc: 0.9095\n",
      "Epoch 11/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.2163 - acc: 0.9214\n",
      "Epoch 12/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2005 - acc: 0.9303\n",
      "Epoch 13/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1873 - acc: 0.9353\n",
      "Epoch 14/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1771 - acc: 0.9418\n",
      "Epoch 15/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1690 - acc: 0.9453\n",
      "Epoch 16/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1617 - acc: 0.9483\n",
      "Epoch 17/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1565 - acc: 0.9488\n",
      "Epoch 18/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1510 - acc: 0.9517\n",
      "Epoch 19/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1461 - acc: 0.9532\n",
      "Epoch 20/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1419 - acc: 0.9542\n",
      "Epoch 21/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1386 - acc: 0.9537\n",
      "Epoch 22/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1352 - acc: 0.9557\n",
      "Epoch 23/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1330 - acc: 0.9577\n",
      "Epoch 24/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1300 - acc: 0.9572\n",
      "Epoch 25/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1275 - acc: 0.9602\n",
      "Epoch 26/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1257 - acc: 0.9572\n",
      "Epoch 27/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1232 - acc: 0.9582\n",
      "Epoch 28/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1203 - acc: 0.9597\n",
      "Epoch 29/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1182 - acc: 0.9592\n",
      "Epoch 30/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1164 - acc: 0.9602\n",
      "Epoch 31/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1145 - acc: 0.9632\n",
      "Epoch 32/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1118 - acc: 0.9627\n",
      "Epoch 33/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1100 - acc: 0.9632\n",
      "Epoch 34/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1085 - acc: 0.9647\n",
      "Epoch 35/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1065 - acc: 0.9647\n",
      "Epoch 36/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1050 - acc: 0.9662\n",
      "Epoch 37/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1037 - acc: 0.9657\n",
      "Epoch 38/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1018 - acc: 0.9687\n",
      "Epoch 39/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1008 - acc: 0.9657\n",
      "Epoch 40/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0995 - acc: 0.9687\n",
      "Epoch 41/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0976 - acc: 0.9687\n",
      "Epoch 42/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0959 - acc: 0.9687\n",
      "Epoch 43/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0951 - acc: 0.9701\n",
      "Epoch 44/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0930 - acc: 0.9726\n",
      "Epoch 45/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0922 - acc: 0.9711\n",
      "Epoch 46/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0909 - acc: 0.9711\n",
      "Epoch 47/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0905 - acc: 0.9701\n",
      "Epoch 48/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0899 - acc: 0.9731\n",
      "Epoch 49/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0883 - acc: 0.9697\n",
      "Epoch 50/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0871 - acc: 0.9726\n",
      "Epoch 51/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0860 - acc: 0.9706\n",
      "Epoch 52/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0853 - acc: 0.9721\n",
      "Epoch 53/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0845 - acc: 0.9731\n",
      "Epoch 54/100\n",
      "2010/2010 [==============================] - 0s 17us/sample - loss: 0.0836 - acc: 0.9731\n",
      "Epoch 55/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0830 - acc: 0.9701\n",
      "Epoch 56/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0817 - acc: 0.9726\n",
      "Epoch 57/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0810 - acc: 0.9726\n",
      "Epoch 58/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0800 - acc: 0.9736\n",
      "Epoch 59/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0791 - acc: 0.9736\n",
      "Epoch 60/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0798 - acc: 0.9711\n",
      "Epoch 61/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0780 - acc: 0.9731\n",
      "Epoch 62/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0770 - acc: 0.9736\n",
      "Epoch 63/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0773 - acc: 0.9736\n",
      "Epoch 64/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0763 - acc: 0.9741\n",
      "Epoch 65/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0752 - acc: 0.9746\n",
      "Epoch 66/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0750 - acc: 0.9736\n",
      "Epoch 67/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0744 - acc: 0.9761\n",
      "Epoch 68/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0730 - acc: 0.9751\n",
      "Epoch 69/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0725 - acc: 0.9771\n",
      "Epoch 70/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0720 - acc: 0.9766\n",
      "Epoch 71/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0722 - acc: 0.9761\n",
      "Epoch 72/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0709 - acc: 0.9766\n",
      "Epoch 73/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0705 - acc: 0.9766\n",
      "Epoch 74/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0703 - acc: 0.9781\n",
      "Epoch 75/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0701 - acc: 0.9761\n",
      "Epoch 76/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0692 - acc: 0.9761\n",
      "Epoch 77/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0684 - acc: 0.9786\n",
      "Epoch 78/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0683 - acc: 0.9786\n",
      "Epoch 79/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0679 - acc: 0.9776\n",
      "Epoch 80/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0674 - acc: 0.9771\n",
      "Epoch 81/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0665 - acc: 0.9791\n",
      "Epoch 82/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0665 - acc: 0.9786\n",
      "Epoch 83/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0653 - acc: 0.9791\n",
      "Epoch 84/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0648 - acc: 0.9796\n",
      "Epoch 85/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0647 - acc: 0.9791\n",
      "Epoch 86/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0647 - acc: 0.9811\n",
      "Epoch 87/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0635 - acc: 0.9776\n",
      "Epoch 88/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0637 - acc: 0.9796\n",
      "Epoch 89/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0644 - acc: 0.9776\n",
      "Epoch 90/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0629 - acc: 0.9811\n",
      "Epoch 91/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0619 - acc: 0.9806\n",
      "Epoch 92/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0620 - acc: 0.9806\n",
      "Epoch 93/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0615 - acc: 0.9796\n",
      "Epoch 94/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0614 - acc: 0.9791\n",
      "Epoch 95/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0607 - acc: 0.9796\n",
      "Epoch 96/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0604 - acc: 0.9806\n",
      "Epoch 97/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0598 - acc: 0.9806\n",
      "Epoch 98/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0592 - acc: 0.9821\n",
      "Epoch 99/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0589 - acc: 0.9811\n",
      "Epoch 100/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0596 - acc: 0.9796\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 10)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01237703 1.00860855 1.01073236 1.01577924 1.01136516 1.01084406\n",
      "  1.00903404 0.89831586 1.00907699 1.01048425]]\n",
      "[[-0.42589932  0.72485984 -1.38010782 -0.17576341 -0.74084226 -1.19760399\n",
      "   1.04458656  0.00804336  1.09325165 -2.08667918]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No appropriate lambda range found, try decreasing lam_init\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408\n",
      "Class counts:\n",
      " y\n",
      "1    1005\n",
      "0    1005\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 2010 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_27540\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010/2010 [==============================] - 0s 28us/sample - loss: 0.6532 - acc: 0.5975\n",
      "Epoch 2/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.5347 - acc: 0.7294\n",
      "Epoch 3/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.4448 - acc: 0.8090\n",
      "Epoch 4/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.3654 - acc: 0.8552\n",
      "Epoch 5/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.3059 - acc: 0.8766\n",
      "Epoch 6/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2672 - acc: 0.8955\n",
      "Epoch 7/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2424 - acc: 0.9035\n",
      "Epoch 8/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2262 - acc: 0.9129\n",
      "Epoch 9/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2155 - acc: 0.9134\n",
      "Epoch 10/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2056 - acc: 0.9204\n",
      "Epoch 11/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1981 - acc: 0.9254\n",
      "Epoch 12/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1915 - acc: 0.9259\n",
      "Epoch 13/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1866 - acc: 0.9294\n",
      "Epoch 14/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1813 - acc: 0.9353\n",
      "Epoch 15/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1771 - acc: 0.9378\n",
      "Epoch 16/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1727 - acc: 0.9388\n",
      "Epoch 17/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1688 - acc: 0.9418\n",
      "Epoch 18/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1662 - acc: 0.9393\n",
      "Epoch 19/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1627 - acc: 0.9418\n",
      "Epoch 20/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1602 - acc: 0.9433\n",
      "Epoch 21/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1573 - acc: 0.9448\n",
      "Epoch 22/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1552 - acc: 0.9453\n",
      "Epoch 23/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1530 - acc: 0.9463\n",
      "Epoch 24/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1501 - acc: 0.9498\n",
      "Epoch 25/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1478 - acc: 0.9478\n",
      "Epoch 26/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1460 - acc: 0.9488\n",
      "Epoch 27/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1436 - acc: 0.9498\n",
      "Epoch 28/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1411 - acc: 0.9502\n",
      "Epoch 29/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1384 - acc: 0.9512\n",
      "Epoch 30/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1360 - acc: 0.9498\n",
      "Epoch 31/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1346 - acc: 0.9502\n",
      "Epoch 32/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1325 - acc: 0.9517\n",
      "Epoch 33/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1308 - acc: 0.9517\n",
      "Epoch 34/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1288 - acc: 0.9527\n",
      "Epoch 35/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1269 - acc: 0.9532\n",
      "Epoch 36/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1259 - acc: 0.9522\n",
      "Epoch 37/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1228 - acc: 0.9542\n",
      "Epoch 38/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1217 - acc: 0.9527\n",
      "Epoch 39/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1192 - acc: 0.9527\n",
      "Epoch 40/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1172 - acc: 0.9557\n",
      "Epoch 41/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1159 - acc: 0.9547\n",
      "Epoch 42/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1144 - acc: 0.9557\n",
      "Epoch 43/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1132 - acc: 0.9582\n",
      "Epoch 44/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1115 - acc: 0.9572\n",
      "Epoch 45/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1096 - acc: 0.9592\n",
      "Epoch 46/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1092 - acc: 0.9562\n",
      "Epoch 47/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1068 - acc: 0.9587\n",
      "Epoch 48/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1059 - acc: 0.9617\n",
      "Epoch 49/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1050 - acc: 0.9607\n",
      "Epoch 50/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1045 - acc: 0.9597\n",
      "Epoch 51/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1029 - acc: 0.9592\n",
      "Epoch 52/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1016 - acc: 0.9622\n",
      "Epoch 53/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.1010 - acc: 0.9632\n",
      "Epoch 54/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1001 - acc: 0.9612\n",
      "Epoch 55/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0987 - acc: 0.9622\n",
      "Epoch 56/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0994 - acc: 0.9627\n",
      "Epoch 57/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0978 - acc: 0.9622\n",
      "Epoch 58/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0965 - acc: 0.9627\n",
      "Epoch 59/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0949 - acc: 0.9627\n",
      "Epoch 60/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0955 - acc: 0.9647\n",
      "Epoch 61/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0940 - acc: 0.9627\n",
      "Epoch 62/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0927 - acc: 0.9637\n",
      "Epoch 63/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0923 - acc: 0.9647\n",
      "Epoch 64/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0918 - acc: 0.9652\n",
      "Epoch 65/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0908 - acc: 0.9632\n",
      "Epoch 66/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0913 - acc: 0.9662\n",
      "Epoch 67/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0896 - acc: 0.9657\n",
      "Epoch 68/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0885 - acc: 0.9657\n",
      "Epoch 69/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0880 - acc: 0.9662\n",
      "Epoch 70/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0875 - acc: 0.9667\n",
      "Epoch 71/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0868 - acc: 0.9692\n",
      "Epoch 72/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0858 - acc: 0.9697\n",
      "Epoch 73/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0850 - acc: 0.9692\n",
      "Epoch 74/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0844 - acc: 0.9697\n",
      "Epoch 75/100\n",
      "2010/2010 [==============================] - 0s 18us/sample - loss: 0.0841 - acc: 0.9687\n",
      "Epoch 76/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0841 - acc: 0.9716\n",
      "Epoch 77/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0835 - acc: 0.9711\n",
      "Epoch 78/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0826 - acc: 0.9716\n",
      "Epoch 79/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0814 - acc: 0.9721\n",
      "Epoch 80/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0813 - acc: 0.9726\n",
      "Epoch 81/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0805 - acc: 0.9711\n",
      "Epoch 82/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0806 - acc: 0.9721\n",
      "Epoch 83/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0799 - acc: 0.9726\n",
      "Epoch 84/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0804 - acc: 0.9711\n",
      "Epoch 85/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0791 - acc: 0.9731\n",
      "Epoch 86/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0787 - acc: 0.9731\n",
      "Epoch 87/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0779 - acc: 0.9741\n",
      "Epoch 88/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0772 - acc: 0.9746\n",
      "Epoch 89/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0767 - acc: 0.9706\n",
      "Epoch 90/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0758 - acc: 0.9746\n",
      "Epoch 91/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0764 - acc: 0.9726\n",
      "Epoch 92/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0757 - acc: 0.9741\n",
      "Epoch 93/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0747 - acc: 0.9771\n",
      "Epoch 94/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0748 - acc: 0.9741\n",
      "Epoch 95/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0740 - acc: 0.9746\n",
      "Epoch 96/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0740 - acc: 0.9756\n",
      "Epoch 97/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0738 - acc: 0.9751\n",
      "Epoch 98/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0730 - acc: 0.9761\n",
      "Epoch 99/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0730 - acc: 0.9756\n",
      "Epoch 100/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0726 - acc: 0.9771\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 10)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00883943 1.01578443 1.01240857 1.00611837 1.01171225 1.01216194\n",
      "  1.0158541  1.00885176 1.00912348 1.01150047]]\n",
      "[[ 0.86925914 -0.17560654 -0.42033615  0.25920027 -0.5908669  -0.46817353\n",
      "  -0.1735286   0.87861079  1.15128734 -0.67412339]]\n",
      "408\n",
      "Class counts:\n",
      " y\n",
      "1    1005\n",
      "0    1005\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 2010 samples\n",
      "Epoch 1/100\n",
      "  32/2010 [..............................] - ETA: 2s - loss: 0.7629 - acc: 0.5938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_27540\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010/2010 [==============================] - 0s 30us/sample - loss: 0.6698 - acc: 0.5836\n",
      "Epoch 2/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.5173 - acc: 0.7493\n",
      "Epoch 3/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.4240 - acc: 0.8060\n",
      "Epoch 4/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.3520 - acc: 0.8458\n",
      "Epoch 5/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2992 - acc: 0.8701\n",
      "Epoch 6/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2642 - acc: 0.8846\n",
      "Epoch 7/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2391 - acc: 0.8985\n",
      "Epoch 8/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2225 - acc: 0.9109\n",
      "Epoch 9/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.2100 - acc: 0.9174\n",
      "Epoch 10/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.2010 - acc: 0.9224\n",
      "Epoch 11/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1945 - acc: 0.9249\n",
      "Epoch 12/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1884 - acc: 0.9274\n",
      "Epoch 13/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1832 - acc: 0.9303\n",
      "Epoch 14/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1789 - acc: 0.9333\n",
      "Epoch 15/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1757 - acc: 0.9363\n",
      "Epoch 16/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1718 - acc: 0.9393\n",
      "Epoch 17/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1684 - acc: 0.9423\n",
      "Epoch 18/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1653 - acc: 0.9418\n",
      "Epoch 19/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1625 - acc: 0.9443\n",
      "Epoch 20/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1597 - acc: 0.9448\n",
      "Epoch 21/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1579 - acc: 0.9458\n",
      "Epoch 22/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1550 - acc: 0.9463\n",
      "Epoch 23/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1525 - acc: 0.9483\n",
      "Epoch 24/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1500 - acc: 0.9493\n",
      "Epoch 25/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1480 - acc: 0.9483\n",
      "Epoch 26/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1456 - acc: 0.9478\n",
      "Epoch 27/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1434 - acc: 0.9493\n",
      "Epoch 28/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1422 - acc: 0.9478\n",
      "Epoch 29/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1392 - acc: 0.9463\n",
      "Epoch 30/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1371 - acc: 0.9488\n",
      "Epoch 31/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1356 - acc: 0.9493\n",
      "Epoch 32/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1335 - acc: 0.9507\n",
      "Epoch 33/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1312 - acc: 0.9517\n",
      "Epoch 34/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1302 - acc: 0.9512\n",
      "Epoch 35/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1284 - acc: 0.9502\n",
      "Epoch 36/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1272 - acc: 0.9517\n",
      "Epoch 37/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1252 - acc: 0.9507\n",
      "Epoch 38/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1241 - acc: 0.9547\n",
      "Epoch 39/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1233 - acc: 0.9512\n",
      "Epoch 40/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1209 - acc: 0.9532\n",
      "Epoch 41/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1204 - acc: 0.9552\n",
      "Epoch 42/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1184 - acc: 0.9552\n",
      "Epoch 43/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1171 - acc: 0.9552\n",
      "Epoch 44/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1166 - acc: 0.9542\n",
      "Epoch 45/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1150 - acc: 0.9547\n",
      "Epoch 46/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1137 - acc: 0.9557\n",
      "Epoch 47/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1129 - acc: 0.9557\n",
      "Epoch 48/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1110 - acc: 0.9557\n",
      "Epoch 49/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1104 - acc: 0.9572\n",
      "Epoch 50/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1103 - acc: 0.9572\n",
      "Epoch 51/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1085 - acc: 0.9567\n",
      "Epoch 52/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1072 - acc: 0.9592\n",
      "Epoch 53/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1066 - acc: 0.9577\n",
      "Epoch 54/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1046 - acc: 0.9597\n",
      "Epoch 55/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1044 - acc: 0.9582\n",
      "Epoch 56/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1027 - acc: 0.9592\n",
      "Epoch 57/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1016 - acc: 0.9582\n",
      "Epoch 58/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1010 - acc: 0.9592\n",
      "Epoch 59/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1000 - acc: 0.9577\n",
      "Epoch 60/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0994 - acc: 0.9592\n",
      "Epoch 61/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0981 - acc: 0.9622\n",
      "Epoch 62/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0979 - acc: 0.9617\n",
      "Epoch 63/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0974 - acc: 0.9602\n",
      "Epoch 64/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0963 - acc: 0.9627\n",
      "Epoch 65/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0950 - acc: 0.9617\n",
      "Epoch 66/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.0954 - acc: 0.9617\n",
      "Epoch 67/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0942 - acc: 0.9637\n",
      "Epoch 68/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0933 - acc: 0.9617\n",
      "Epoch 69/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0927 - acc: 0.9622\n",
      "Epoch 70/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0925 - acc: 0.9647\n",
      "Epoch 71/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0923 - acc: 0.9642\n",
      "Epoch 72/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0909 - acc: 0.9652\n",
      "Epoch 73/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0907 - acc: 0.9652\n",
      "Epoch 74/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0901 - acc: 0.9662\n",
      "Epoch 75/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0892 - acc: 0.9667\n",
      "Epoch 76/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0895 - acc: 0.9637\n",
      "Epoch 77/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0883 - acc: 0.9647\n",
      "Epoch 78/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0880 - acc: 0.9662\n",
      "Epoch 79/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0877 - acc: 0.9672\n",
      "Epoch 80/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0875 - acc: 0.9657\n",
      "Epoch 81/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0870 - acc: 0.9667\n",
      "Epoch 82/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0863 - acc: 0.9692\n",
      "Epoch 83/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0856 - acc: 0.9657\n",
      "Epoch 84/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0859 - acc: 0.9657\n",
      "Epoch 85/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0855 - acc: 0.9667\n",
      "Epoch 86/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0846 - acc: 0.9662\n",
      "Epoch 87/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0842 - acc: 0.9682\n",
      "Epoch 88/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0837 - acc: 0.9687\n",
      "Epoch 89/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0836 - acc: 0.9682\n",
      "Epoch 90/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0829 - acc: 0.9682\n",
      "Epoch 91/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0828 - acc: 0.9701\n",
      "Epoch 92/100\n",
      "2010/2010 [==============================] - 0s 17us/sample - loss: 0.0820 - acc: 0.9682\n",
      "Epoch 93/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0817 - acc: 0.9662\n",
      "Epoch 94/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0817 - acc: 0.9697\n",
      "Epoch 95/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0808 - acc: 0.9672\n",
      "Epoch 96/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0805 - acc: 0.9701\n",
      "Epoch 97/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0800 - acc: 0.9701\n",
      "Epoch 98/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0799 - acc: 0.9682\n",
      "Epoch 99/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0806 - acc: 0.9697\n",
      "Epoch 100/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0791 - acc: 0.9701\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 10)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00103292 1.02348791 1.00769417 1.03818369 1.01208989 1.00506792\n",
      "  1.00809453 1.01223327 1.012729   1.00862354]]\n",
      "[[ 0.11163419 -0.07588187  0.43702053 -0.03683634 -0.48427796  0.20378164\n",
      "   0.52905372 -0.45325132 -0.37109892  0.73276817]]\n",
      "147\n",
      "Class counts:\n",
      " y\n",
      "1    1005\n",
      "0    1005\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 2010 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_27540\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010/2010 [==============================] - 0s 29us/sample - loss: 0.6827 - acc: 0.5746\n",
      "Epoch 2/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.5949 - acc: 0.6816\n",
      "Epoch 3/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.5184 - acc: 0.7532\n",
      "Epoch 4/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.4497 - acc: 0.8010\n",
      "Epoch 5/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3923 - acc: 0.8443\n",
      "Epoch 6/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3425 - acc: 0.8711\n",
      "Epoch 7/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3054 - acc: 0.8841\n",
      "Epoch 8/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2777 - acc: 0.8970\n",
      "Epoch 9/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2560 - acc: 0.9055\n",
      "Epoch 10/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2392 - acc: 0.9129\n",
      "Epoch 11/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.2253 - acc: 0.9179\n",
      "Epoch 12/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2138 - acc: 0.9179\n",
      "Epoch 13/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2043 - acc: 0.9204\n",
      "Epoch 14/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1964 - acc: 0.9244\n",
      "Epoch 15/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1890 - acc: 0.9264\n",
      "Epoch 16/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1837 - acc: 0.9269\n",
      "Epoch 17/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1788 - acc: 0.9313\n",
      "Epoch 18/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1733 - acc: 0.9343\n",
      "Epoch 19/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1697 - acc: 0.9338\n",
      "Epoch 20/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1658 - acc: 0.9393\n",
      "Epoch 21/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1630 - acc: 0.9398\n",
      "Epoch 22/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1598 - acc: 0.9408\n",
      "Epoch 23/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1582 - acc: 0.9438\n",
      "Epoch 24/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1551 - acc: 0.9453\n",
      "Epoch 25/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1529 - acc: 0.9428\n",
      "Epoch 26/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1507 - acc: 0.9473\n",
      "Epoch 27/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1494 - acc: 0.9473\n",
      "Epoch 28/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1459 - acc: 0.9527\n",
      "Epoch 29/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1449 - acc: 0.9522\n",
      "Epoch 30/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1430 - acc: 0.9527\n",
      "Epoch 31/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1412 - acc: 0.9542\n",
      "Epoch 32/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1413 - acc: 0.9527\n",
      "Epoch 33/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1384 - acc: 0.9547\n",
      "Epoch 34/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1368 - acc: 0.9527\n",
      "Epoch 35/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1350 - acc: 0.9577\n",
      "Epoch 36/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1339 - acc: 0.9542\n",
      "Epoch 37/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1320 - acc: 0.9542\n",
      "Epoch 38/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1300 - acc: 0.9567\n",
      "Epoch 39/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1281 - acc: 0.9557\n",
      "Epoch 40/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1272 - acc: 0.9547\n",
      "Epoch 41/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1261 - acc: 0.9577\n",
      "Epoch 42/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1242 - acc: 0.9567\n",
      "Epoch 43/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1226 - acc: 0.9572\n",
      "Epoch 44/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1210 - acc: 0.9572\n",
      "Epoch 45/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1199 - acc: 0.9577\n",
      "Epoch 46/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1184 - acc: 0.9577\n",
      "Epoch 47/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1166 - acc: 0.9607\n",
      "Epoch 48/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1149 - acc: 0.9602\n",
      "Epoch 49/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1132 - acc: 0.9622\n",
      "Epoch 50/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1114 - acc: 0.9607\n",
      "Epoch 51/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1104 - acc: 0.9632\n",
      "Epoch 52/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1083 - acc: 0.9637\n",
      "Epoch 53/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1075 - acc: 0.9642\n",
      "Epoch 54/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1060 - acc: 0.9642\n",
      "Epoch 55/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1050 - acc: 0.9617\n",
      "Epoch 56/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1033 - acc: 0.9667\n",
      "Epoch 57/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1027 - acc: 0.9637\n",
      "Epoch 58/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1009 - acc: 0.9667\n",
      "Epoch 59/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0995 - acc: 0.9657\n",
      "Epoch 60/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0989 - acc: 0.9647\n",
      "Epoch 61/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0976 - acc: 0.9662\n",
      "Epoch 62/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0961 - acc: 0.9652\n",
      "Epoch 63/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0947 - acc: 0.9672\n",
      "Epoch 64/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0940 - acc: 0.9672\n",
      "Epoch 65/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0919 - acc: 0.9667\n",
      "Epoch 66/100\n",
      "2010/2010 [==============================] - 0s 11us/sample - loss: 0.0924 - acc: 0.9667\n",
      "Epoch 67/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0906 - acc: 0.9652\n",
      "Epoch 68/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0892 - acc: 0.9687\n",
      "Epoch 69/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0888 - acc: 0.9677\n",
      "Epoch 70/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0882 - acc: 0.9692\n",
      "Epoch 71/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0869 - acc: 0.9692\n",
      "Epoch 72/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0861 - acc: 0.9706\n",
      "Epoch 73/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0852 - acc: 0.9716\n",
      "Epoch 74/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0847 - acc: 0.9701\n",
      "Epoch 75/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0837 - acc: 0.9701\n",
      "Epoch 76/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0830 - acc: 0.9706\n",
      "Epoch 77/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0819 - acc: 0.9726\n",
      "Epoch 78/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0814 - acc: 0.9736\n",
      "Epoch 79/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0805 - acc: 0.9731\n",
      "Epoch 80/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0806 - acc: 0.9721\n",
      "Epoch 81/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0798 - acc: 0.9716\n",
      "Epoch 82/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0781 - acc: 0.9746\n",
      "Epoch 83/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0780 - acc: 0.9731\n",
      "Epoch 84/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0768 - acc: 0.9751\n",
      "Epoch 85/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0761 - acc: 0.9736\n",
      "Epoch 86/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0763 - acc: 0.9731\n",
      "Epoch 87/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0754 - acc: 0.9736\n",
      "Epoch 88/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0764 - acc: 0.9731\n",
      "Epoch 89/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0742 - acc: 0.9741\n",
      "Epoch 90/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0735 - acc: 0.9741\n",
      "Epoch 91/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0730 - acc: 0.9741\n",
      "Epoch 92/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0719 - acc: 0.9766\n",
      "Epoch 93/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0726 - acc: 0.9746\n",
      "Epoch 94/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0725 - acc: 0.9756\n",
      "Epoch 95/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0706 - acc: 0.9756\n",
      "Epoch 96/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0695 - acc: 0.9761\n",
      "Epoch 97/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0694 - acc: 0.9746\n",
      "Epoch 98/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0692 - acc: 0.9746\n",
      "Epoch 99/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0677 - acc: 0.9751\n",
      "Epoch 100/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.0675 - acc: 0.9756\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 10)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01238517 1.00814776 1.02326038 1.00866812 1.02697524 1.00892637\n",
      "  1.01067087 1.00810988 0.92492421 1.01102104]]\n",
      "[[-0.42445011  0.54428706 -0.07716672  0.75732483 -0.06049843  0.93973192\n",
      "  -1.50651867  0.5333562   0.01087177 -0.99018347]]\n",
      "1382\n",
      "Class counts:\n",
      " y\n",
      "1    1005\n",
      "0    1005\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 2010 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_27540\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2010/2010 [==============================] - 0s 33us/sample - loss: 0.7167 - acc: 0.5831\n",
      "Epoch 2/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.5856 - acc: 0.7104\n",
      "Epoch 3/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.4931 - acc: 0.7836\n",
      "Epoch 4/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.4158 - acc: 0.8299\n",
      "Epoch 5/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.3565 - acc: 0.8597\n",
      "Epoch 6/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.3097 - acc: 0.8826\n",
      "Epoch 7/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2714 - acc: 0.9005\n",
      "Epoch 8/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2442 - acc: 0.9100\n",
      "Epoch 9/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2254 - acc: 0.9159\n",
      "Epoch 10/100\n",
      "2010/2010 [==============================] - 0s 17us/sample - loss: 0.2103 - acc: 0.9234\n",
      "Epoch 11/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1982 - acc: 0.9284\n",
      "Epoch 12/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1879 - acc: 0.9308\n",
      "Epoch 13/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1797 - acc: 0.9363\n",
      "Epoch 14/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1713 - acc: 0.9383\n",
      "Epoch 15/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1657 - acc: 0.9413\n",
      "Epoch 16/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1609 - acc: 0.9463\n",
      "Epoch 17/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1564 - acc: 0.9463\n",
      "Epoch 18/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1527 - acc: 0.9448\n",
      "Epoch 19/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1504 - acc: 0.9498\n",
      "Epoch 20/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1475 - acc: 0.9512\n",
      "Epoch 21/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1449 - acc: 0.9512\n",
      "Epoch 22/100\n",
      "2010/2010 [==============================] - 0s 17us/sample - loss: 0.1429 - acc: 0.9547\n",
      "Epoch 23/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1401 - acc: 0.9537\n",
      "Epoch 24/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1376 - acc: 0.9557\n",
      "Epoch 25/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1352 - acc: 0.9562\n",
      "Epoch 26/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1325 - acc: 0.9592\n",
      "Epoch 27/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1302 - acc: 0.9572\n",
      "Epoch 28/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1285 - acc: 0.9552\n",
      "Epoch 29/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1257 - acc: 0.9587\n",
      "Epoch 30/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1242 - acc: 0.9587\n",
      "Epoch 31/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1233 - acc: 0.9577\n",
      "Epoch 32/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1205 - acc: 0.9617\n",
      "Epoch 33/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1203 - acc: 0.9622\n",
      "Epoch 34/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1186 - acc: 0.9602\n",
      "Epoch 35/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1173 - acc: 0.9677\n",
      "Epoch 36/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1165 - acc: 0.9632\n",
      "Epoch 37/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1151 - acc: 0.9642\n",
      "Epoch 38/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1138 - acc: 0.9657\n",
      "Epoch 39/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1129 - acc: 0.9652\n",
      "Epoch 40/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1126 - acc: 0.9662\n",
      "Epoch 41/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1111 - acc: 0.9677\n",
      "Epoch 42/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1100 - acc: 0.9657\n",
      "Epoch 43/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1092 - acc: 0.9701\n",
      "Epoch 44/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1080 - acc: 0.9697\n",
      "Epoch 45/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1072 - acc: 0.9682\n",
      "Epoch 46/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1065 - acc: 0.9687\n",
      "Epoch 47/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1057 - acc: 0.9692\n",
      "Epoch 48/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1044 - acc: 0.9697\n",
      "Epoch 49/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1039 - acc: 0.9711\n",
      "Epoch 50/100\n",
      "2010/2010 [==============================] - 0s 19us/sample - loss: 0.1029 - acc: 0.9682\n",
      "Epoch 51/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1018 - acc: 0.9701\n",
      "Epoch 52/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1009 - acc: 0.9711\n",
      "Epoch 53/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1005 - acc: 0.9711\n",
      "Epoch 54/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0995 - acc: 0.9706\n",
      "Epoch 55/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0997 - acc: 0.9687\n",
      "Epoch 56/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0977 - acc: 0.9711\n",
      "Epoch 57/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0970 - acc: 0.9721\n",
      "Epoch 58/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0964 - acc: 0.9701\n",
      "Epoch 59/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0954 - acc: 0.9726\n",
      "Epoch 60/100\n",
      "2010/2010 [==============================] - 0s 18us/sample - loss: 0.0946 - acc: 0.9716\n",
      "Epoch 61/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0942 - acc: 0.9706\n",
      "Epoch 62/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0933 - acc: 0.9736\n",
      "Epoch 63/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0932 - acc: 0.9716\n",
      "Epoch 64/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0920 - acc: 0.9721\n",
      "Epoch 65/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0918 - acc: 0.9726\n",
      "Epoch 66/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0908 - acc: 0.9746\n",
      "Epoch 67/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0901 - acc: 0.9731\n",
      "Epoch 68/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0895 - acc: 0.9751\n",
      "Epoch 69/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0882 - acc: 0.9741\n",
      "Epoch 70/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0879 - acc: 0.9746\n",
      "Epoch 71/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0875 - acc: 0.9756\n",
      "Epoch 72/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0873 - acc: 0.9741\n",
      "Epoch 73/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0850 - acc: 0.9751\n",
      "Epoch 74/100\n",
      "2010/2010 [==============================] - 0s 17us/sample - loss: 0.0847 - acc: 0.9756\n",
      "Epoch 75/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0840 - acc: 0.9746\n",
      "Epoch 76/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0840 - acc: 0.9756\n",
      "Epoch 77/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0835 - acc: 0.9751\n",
      "Epoch 78/100\n",
      "2010/2010 [==============================] - 0s 17us/sample - loss: 0.0831 - acc: 0.9736\n",
      "Epoch 79/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.0816 - acc: 0.9771\n",
      "Epoch 80/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0831 - acc: 0.9746\n",
      "Epoch 81/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0816 - acc: 0.9766\n",
      "Epoch 82/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0808 - acc: 0.9756\n",
      "Epoch 83/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0802 - acc: 0.9751\n",
      "Epoch 84/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0796 - acc: 0.9761\n",
      "Epoch 85/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0791 - acc: 0.9756\n",
      "Epoch 86/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0785 - acc: 0.9771\n",
      "Epoch 87/100\n",
      "2010/2010 [==============================] - 0s 17us/sample - loss: 0.0780 - acc: 0.9771\n",
      "Epoch 88/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0774 - acc: 0.9766\n",
      "Epoch 89/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0775 - acc: 0.9786\n",
      "Epoch 90/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0770 - acc: 0.9776\n",
      "Epoch 91/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0757 - acc: 0.9786\n",
      "Epoch 92/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0757 - acc: 0.9786\n",
      "Epoch 93/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0751 - acc: 0.9771\n",
      "Epoch 94/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0754 - acc: 0.9761\n",
      "Epoch 95/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0751 - acc: 0.9776\n",
      "Epoch 96/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0741 - acc: 0.9786\n",
      "Epoch 97/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0740 - acc: 0.9761\n",
      "Epoch 98/100\n",
      "2010/2010 [==============================] - 0s 18us/sample - loss: 0.0735 - acc: 0.9786\n",
      "Epoch 99/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0726 - acc: 0.9786\n",
      "Epoch 100/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0719 - acc: 0.9771\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 10)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.01180928 1.00967009 1.01099213 1.0116115  1.01181698 1.01049733\n",
      "  1.00922852 1.0108847  1.0095183  1.0096412 ]]\n",
      "[[-0.55923436  3.06044097 -1.01900765 -0.62774334 -0.55686873 -2.03186122\n",
      "   1.30816987 -1.14262485  2.09573005  2.81395396]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No appropriate lambda range found, try decreasing lam_init\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "Class counts:\n",
      " y\n",
      "1    1005\n",
      "0    1005\n",
      "Name: count, dtype: int64\n",
      "Fitting model...\n",
      "Train on 2010 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Compuworld\\AppData\\Local\\Temp\\ipykernel_27540\\2537515542.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  balanced_dataset = pd.concat([balanced_dataset, upsampled_class], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2010/2010 [==============================] - 0s 34us/sample - loss: 0.6854 - acc: 0.6119\n",
      "Epoch 2/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.5174 - acc: 0.7567\n",
      "Epoch 3/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.4331 - acc: 0.8234\n",
      "Epoch 4/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3736 - acc: 0.8443\n",
      "Epoch 5/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3354 - acc: 0.8562\n",
      "Epoch 6/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.3103 - acc: 0.8701\n",
      "Epoch 7/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2924 - acc: 0.8796\n",
      "Epoch 8/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.2766 - acc: 0.8846\n",
      "Epoch 9/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.2620 - acc: 0.8900\n",
      "Epoch 10/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.2492 - acc: 0.8970\n",
      "Epoch 11/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2363 - acc: 0.9035\n",
      "Epoch 12/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2263 - acc: 0.9065\n",
      "Epoch 13/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.2147 - acc: 0.9124\n",
      "Epoch 14/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.2063 - acc: 0.9199\n",
      "Epoch 15/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1983 - acc: 0.9244\n",
      "Epoch 16/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1927 - acc: 0.9269\n",
      "Epoch 17/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1874 - acc: 0.9313\n",
      "Epoch 18/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1822 - acc: 0.9348\n",
      "Epoch 19/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1773 - acc: 0.9378\n",
      "Epoch 20/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1723 - acc: 0.9398\n",
      "Epoch 21/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1687 - acc: 0.9428\n",
      "Epoch 22/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1643 - acc: 0.9453\n",
      "Epoch 23/100\n",
      "2010/2010 [==============================] - 0s 17us/sample - loss: 0.1613 - acc: 0.9458\n",
      "Epoch 24/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1571 - acc: 0.9463\n",
      "Epoch 25/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1542 - acc: 0.9473\n",
      "Epoch 26/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1513 - acc: 0.9522\n",
      "Epoch 27/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1492 - acc: 0.9507\n",
      "Epoch 28/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1463 - acc: 0.9512\n",
      "Epoch 29/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1441 - acc: 0.9517\n",
      "Epoch 30/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1426 - acc: 0.9502\n",
      "Epoch 31/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1407 - acc: 0.9517\n",
      "Epoch 32/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1387 - acc: 0.9527\n",
      "Epoch 33/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1368 - acc: 0.9552\n",
      "Epoch 34/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1354 - acc: 0.9557\n",
      "Epoch 35/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1340 - acc: 0.9507\n",
      "Epoch 36/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1330 - acc: 0.9547\n",
      "Epoch 37/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1323 - acc: 0.9547\n",
      "Epoch 38/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1301 - acc: 0.9562\n",
      "Epoch 39/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1292 - acc: 0.9567\n",
      "Epoch 40/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1282 - acc: 0.9552\n",
      "Epoch 41/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1276 - acc: 0.9572\n",
      "Epoch 42/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1263 - acc: 0.9577\n",
      "Epoch 43/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1258 - acc: 0.9562\n",
      "Epoch 44/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1246 - acc: 0.9587\n",
      "Epoch 45/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1238 - acc: 0.9582\n",
      "Epoch 46/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1225 - acc: 0.9572\n",
      "Epoch 47/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1218 - acc: 0.9607\n",
      "Epoch 48/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1207 - acc: 0.9577\n",
      "Epoch 49/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1203 - acc: 0.9607\n",
      "Epoch 50/100\n",
      "2010/2010 [==============================] - 0s 18us/sample - loss: 0.1185 - acc: 0.9602\n",
      "Epoch 51/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1177 - acc: 0.9612\n",
      "Epoch 52/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1171 - acc: 0.9627\n",
      "Epoch 53/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1164 - acc: 0.9617\n",
      "Epoch 54/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1159 - acc: 0.9627\n",
      "Epoch 55/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1151 - acc: 0.9602\n",
      "Epoch 56/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1142 - acc: 0.9647\n",
      "Epoch 57/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1140 - acc: 0.9612\n",
      "Epoch 58/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1122 - acc: 0.9642\n",
      "Epoch 59/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.1116 - acc: 0.9627\n",
      "Epoch 60/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1112 - acc: 0.9617\n",
      "Epoch 61/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1104 - acc: 0.9637\n",
      "Epoch 62/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1091 - acc: 0.9632\n",
      "Epoch 63/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1098 - acc: 0.9632\n",
      "Epoch 64/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1085 - acc: 0.9632\n",
      "Epoch 65/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1072 - acc: 0.9642\n",
      "Epoch 66/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1074 - acc: 0.9642\n",
      "Epoch 67/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1055 - acc: 0.9637\n",
      "Epoch 68/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1052 - acc: 0.9642\n",
      "Epoch 69/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.1047 - acc: 0.9667\n",
      "Epoch 70/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1037 - acc: 0.9637\n",
      "Epoch 71/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1037 - acc: 0.9672\n",
      "Epoch 72/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1028 - acc: 0.9652\n",
      "Epoch 73/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1021 - acc: 0.9692\n",
      "Epoch 74/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.1023 - acc: 0.9682\n",
      "Epoch 75/100\n",
      "2010/2010 [==============================] - 0s 16us/sample - loss: 0.1004 - acc: 0.9667\n",
      "Epoch 76/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.1004 - acc: 0.9682\n",
      "Epoch 77/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0998 - acc: 0.9682\n",
      "Epoch 78/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0989 - acc: 0.9692\n",
      "Epoch 79/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0982 - acc: 0.9701\n",
      "Epoch 80/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0977 - acc: 0.9682\n",
      "Epoch 81/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0973 - acc: 0.9701\n",
      "Epoch 82/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0960 - acc: 0.9701\n",
      "Epoch 83/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0965 - acc: 0.9667\n",
      "Epoch 84/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0954 - acc: 0.9677\n",
      "Epoch 85/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0949 - acc: 0.9711\n",
      "Epoch 86/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0940 - acc: 0.9711\n",
      "Epoch 87/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0938 - acc: 0.9706\n",
      "Epoch 88/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0937 - acc: 0.9692\n",
      "Epoch 89/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0924 - acc: 0.9716\n",
      "Epoch 90/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0915 - acc: 0.9721\n",
      "Epoch 91/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0913 - acc: 0.9701\n",
      "Epoch 92/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0909 - acc: 0.9711\n",
      "Epoch 93/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0916 - acc: 0.9716\n",
      "Epoch 94/100\n",
      "2010/2010 [==============================] - 0s 13us/sample - loss: 0.0892 - acc: 0.9721\n",
      "Epoch 95/100\n",
      "2010/2010 [==============================] - 0s 12us/sample - loss: 0.0896 - acc: 0.9721\n",
      "Epoch 96/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0890 - acc: 0.9692\n",
      "Epoch 97/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0893 - acc: 0.9716\n",
      "Epoch 98/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0875 - acc: 0.9726\n",
      "Epoch 99/100\n",
      "2010/2010 [==============================] - 0s 15us/sample - loss: 0.0878 - acc: 0.9721\n",
      "Epoch 100/100\n",
      "2010/2010 [==============================] - 0s 14us/sample - loss: 0.0866 - acc: 0.9726\n",
      "Model training complete.\n",
      "boundary points started generation...\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Compuworld\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary points finished.\n",
      "(10000, 10)\n",
      "Finding the closest point from the contour line to the point...\n",
      "Finding the closest point from the contour line to the point.\n",
      "[[1.00425072 1.00971263 1.01169996 1.02728395 1.01074463 1.01054941\n",
      "  1.013104   0.98607232 1.00957153 1.01137604]]\n",
      "[[ 0.17467428  3.51357442 -0.59513217 -0.05943571 -1.35738382 -1.83932125\n",
      "  -0.32638645  0.04121052  2.35625017 -0.73498945]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No appropriate lambda range found, try decreasing lam_init\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=2000, n_features=10, n_informative=10, n_redundant=0, random_state=42, n_classes=2)\n",
    "model = LogisticRegression()\n",
    "y = y.reshape(-1,1)\n",
    "target = 'y'\n",
    "columns = [\"x\"+str(i) for i in range(1, X.shape[1]+1)] \n",
    "columns.append('y')\n",
    "dataset = pd.DataFrame(data=np.hstack((X,y)), columns=columns)\n",
    "sub_dataset = dataset[dataset[target] == 0]\n",
    "random_integers = random.sample(range(1, sub_dataset.shape[0]), 10)\n",
    "optimal_dists, wachter_dists = [], []\n",
    "optimal_probs,  wachter_probs = [], [] \n",
    "alibi_runtime = [] \n",
    "shape = (1,dataset.shape[1]-1)\n",
    "target_proba = 0.5\n",
    "tol = 0.0001 # want counterfactuals with p(class)>0.99\n",
    "target_class = 'other' # any class other than 7 will do\n",
    "max_iter = 1000\n",
    "lam_init = 1e-1\n",
    "max_lam_steps = 10\n",
    "learning_rate_init = 0.1\n",
    "\n",
    "for i in random_integers:\n",
    "    real_idx = sub_dataset.index[i]\n",
    "    X_point = dataset.iloc[real_idx,:-1]\n",
    "    idx = dataset.index[real_idx]\n",
    "    print(idx)\n",
    "    nn=nn_model()\n",
    "\n",
    "    nn, optimal_datapt = optimal_point(dataset, nn, desired_class=1, original_class=0, threshold=10000, chosen_row=idx, point_epsilon=1e-3, epsilon=1e-2)\n",
    "    try: \n",
    "        start = datetime.now()\n",
    "        target_class=1\n",
    "        explainer2 = Counterfactual(nn, shape=shape, target_proba=target_proba, tol=tol,\n",
    "                                target_class=target_class)\n",
    "        #print(np.reshape(X_point, (1,-1)).shape)\n",
    "        cf = explainer2.explain(np.reshape(X_point, (1,-1)))\n",
    "        cf_point = cf.data['cf']['X'] \n",
    "        end = datetime.now() \n",
    "        diff = end - start\n",
    "        alibi_runtime.append(diff.total_seconds())\n",
    "        cf_pt_probs = nn.predict(cf_point)\n",
    "        opt_pt_probs = nn.predict(optimal_datapt)\n",
    "        optimal_probs.append(opt_pt_probs)\n",
    "        wachter_probs.append(cf_pt_probs)\n",
    "        optimal_dists.append(euclidean_distance(X_point, optimal_datapt))\n",
    "        wachter_dists.append(euclidean_distance(X_point, cf_point))\n",
    "    except TypeError: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce22172",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(alibi_runtime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
